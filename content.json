{"meta":{"title":"Proverbs's Blog","subtitle":"Keep Calm and Carry On","description":"share what I think about","author":"Proverbs Xu","url":"https://proverbs.github.io","root":"/"},"pages":[{"title":"About","date":"2021-05-30T16:25:43.056Z","updated":"2021-05-30T16:25:43.056Z","comments":false,"path":"index.html","permalink":"https://proverbs.github.io/index.html","excerpt":"","text":""},{"title":"About","date":"2021-05-30T16:25:43.056Z","updated":"2021-05-30T16:25:43.056Z","comments":false,"path":"about/index.html","permalink":"https://proverbs.github.io/about/index.html","excerpt":"","text":"I am now a graduate student at Carnegie Mellon University. I love to code and do whatever challengeable, such as programming contests and gorgeous combo in games. My mother language is Chinese, but I am trying to practice my English, not only about writing but also for speaking. And that is the reason why I began to write my blog using English. Most time, I write ideas or inspiration rather than the solutions or implementations, because when I review my blogs I can still keep thinking. However, it could be quite inconvenient for you to read my blogs and I think I should say sorry for this. Anyway, hope you lean more and have a good time!"},{"title":"categories","date":"2021-05-30T16:25:43.056Z","updated":"2021-05-30T16:25:43.056Z","comments":false,"path":"categories/index.html","permalink":"https://proverbs.github.io/categories/index.html","excerpt":"","text":""},{"title":"标签","date":"2021-05-30T16:25:43.056Z","updated":"2021-05-30T16:25:43.056Z","comments":false,"path":"tags/index.html","permalink":"https://proverbs.github.io/tags/index.html","excerpt":"","text":""},{"title":"Repositories","date":"2021-05-30T16:25:43.056Z","updated":"2021-05-30T16:25:43.056Z","comments":false,"path":"repository/index.html","permalink":"https://proverbs.github.io/repository/index.html","excerpt":"","text":""},{"title":"Links","date":"2021-05-30T16:25:43.056Z","updated":"2021-05-30T16:25:43.056Z","comments":true,"path":"links/index.html","permalink":"https://proverbs.github.io/links/index.html","excerpt":"","text":""}],"posts":[{"title":"[Reading]How to Win Friends and Influence People","slug":"Reading-How-to-Win-Friends-and-Influence-People","date":"2021-05-30T16:51:45.000Z","updated":"2021-05-30T18:04:31.486Z","comments":true,"path":"2021/05/30/Reading-How-to-Win-Friends-and-Influence-People/","link":"","permalink":"https://proverbs.github.io/2021/05/30/Reading-How-to-Win-Friends-and-Influence-People/","excerpt":"[Reading]How to Win Friends and Influence People 这本书我读的是中文版 ——《人性的弱点》。不得不说，这个中文书名真的很“符合”这个浮躁的时代，很能吸引大家的眼球。 个人认为这个标题存在一定的误导性：本书列举了一些人际交往中的“技巧”，而这些技巧正是利用了人性的“弱点”已达到某种特定的目的，如赢得友情，提升对他人的影响力。这就是这个书名，搭配书的章节总结给人的印象，看上去像是本PUA学的著作。考虑到这本书出版于上世纪30年代，都可以称为是PUA学鼻祖了。 然而，我想说这本书完全不是这个目的。书中不止一次强调，这本书所列举的不是虚伪的“技巧”，而是要发自真心的态度。或者说是一种价值观：真诚，尊重和积极的态度。","text":"[Reading]How to Win Friends and Influence People 这本书我读的是中文版 ——《人性的弱点》。不得不说，这个中文书名真的很“符合”这个浮躁的时代，很能吸引大家的眼球。 个人认为这个标题存在一定的误导性：本书列举了一些人际交往中的“技巧”，而这些技巧正是利用了人性的“弱点”已达到某种特定的目的，如赢得友情，提升对他人的影响力。这就是这个书名，搭配书的章节总结给人的印象，看上去像是本PUA学的著作。考虑到这本书出版于上世纪30年代，都可以称为是PUA学鼻祖了。 然而，我想说这本书完全不是这个目的。书中不止一次强调，这本书所列举的不是虚伪的“技巧”，而是要发自真心的态度。或者说是一种价值观：真诚，尊重和积极的态度。 真诚：称赞他人并不是为了希望别人帮自己的忙，或者让别人更能接受接下来的批评，因为这样反而让人觉得虚伪。 尊重：每个人都希望得到尊重，因为受到尊重能给予对人生价值的满足，感觉心情愉悦。换位思考，你也不希望在和别人的交往中被别人坏了心情。所以说话前要换位思考，反问自己，别人这么对我说我想说的话，我的感觉会如何？ 积极的态度：这个可以帮助我们在潜意识里做到真诚，我们需要有发现别人优点的眼睛，而不是一直盯着别人的不足，这样我们说起话来自然而然就不是指责，而是表扬和建议了。 就这本书所传递的价值观，总体而言我个人是十分赞成的，但是可能是因为年代gap的原因，这本书中列举的例子总让我觉得有种小时候看“鸡汤文”的感觉：上小学的时候，学校组织买书，一整套十几本的《心灵鸡汤》系列只要30块（如果没记错的话），所以鸡汤真的就成了当时日常阅读很重要的一部分。说实话，至少从对人的影响上，我并不觉得鸡汤有什么不好的，相反，鸡汤的故事简单易懂，却又非常鼓舞人心（对于那个年纪的我来说）。在情绪低落时，喝上两口鸡汤真的能让人斗志满满。随着年龄的增长，发现很多的鸡汤故事都是一个套路，甚至很大一部分都是人为编造出的故事，就是为了去印证作者的观点，就开始对鸡汤产生了不信任，觉得故事索然无味。现在喝鸡汤就和喝水一样，完全吸收不到营养了。 说回到本书，有些观点我就不赞成，比如作者提到要无私为他人着想。我一直坚信，每个人都是相对自私的。我不否认生活中，尤其是亲情中存在很多的无私付出，但对于素不相识的陌生人，或者刚刚认识的人，甚至同事，真的能做到完全的无私为他人着想？当然也有可能是我对作者或者译者所说的“无私”给予了太严苛的定义，但我想表达的观点是，即使我们是自私的，并不影响最起码的礼仪与尊重（或者你称其为“虚伪”）。比如，同事因为种种原因，拿到了本来属于你的机会，有做的很好，得到了领导的表扬，你还是不应该吝啬自己的赞美。尽管你无法做到完全的真诚，但至少不会让别人觉得你非常的狭隘。 说实话，我非常厌恶“虚伪”这个词 —— “我不高兴就是不高兴，为什么非要摆好脸色给你看？”。但人是社会动物，只要和其他人有接触，那就需要一定程度的违心与虚伪。既然无法改变社会，那就只能去适应它。但无论如何，都不能利用这点去伤害别人，做些“阳奉阴违”的事情，这可能就是虚伪的底线了吧。","categories":[],"tags":[{"name":"reading","slug":"reading","permalink":"https://proverbs.github.io/tags/reading/"}]},{"title":"Arc of a Scythe - Scythe","slug":"Arc-of-a-Scythe-Scythe","date":"2021-01-09T07:02:11.000Z","updated":"2021-05-30T16:25:43.046Z","comments":true,"path":"2021/01/08/Arc-of-a-Scythe-Scythe/","link":"","permalink":"https://proverbs.github.io/2021/01/08/Arc-of-a-Scythe-Scythe/","excerpt":"Scythe (Arc of a Scythe Series - Book 1) Review 2021年读的第一本书，第一本英文书，也是Arc of a Scythe系列的第一本，还是挺有纪念意义的。 这本书主要讲的在未来社会，人工智能Thunderhead控制着社会的运行，人类拥有了无限寿命，且即使死亡也可以被revive（除非被烧成炭）。但与此同时，人类会面临人口膨胀的问题，所以就有了不受Thunderhead管理的工会组织Scythedom（因为Thunderhead想把人类自己的生存问题交给人类自己），以及scythe这个职业：scythe和普通人类没有不同，但是scythe可以合法glean人类，且被glean的人类是不能被revive的。每个scythe都拥有一个戒指，人类亲吻戒指可以被赋予一年的immunity（无法被任何scythe glean）。也正因为此，scythe在社会中的地位非常高，也产生了众多flatterer。","text":"Scythe (Arc of a Scythe Series - Book 1) Review 2021年读的第一本书，第一本英文书，也是Arc of a Scythe系列的第一本，还是挺有纪念意义的。 这本书主要讲的在未来社会，人工智能Thunderhead控制着社会的运行，人类拥有了无限寿命，且即使死亡也可以被revive（除非被烧成炭）。但与此同时，人类会面临人口膨胀的问题，所以就有了不受Thunderhead管理的工会组织Scythedom（因为Thunderhead想把人类自己的生存问题交给人类自己），以及scythe这个职业：scythe和普通人类没有不同，但是scythe可以合法glean人类，且被glean的人类是不能被revive的。每个scythe都拥有一个戒指，人类亲吻戒指可以被赋予一年的immunity（无法被任何scythe glean）。也正因为此，scythe在社会中的地位非常高，也产生了众多flatterer。 以上就是故事背景（游戏规则），而这本小说就是在这样背景下，讲述了一男一女两人从scythe的apprentice开始，历经考验，相爱相杀（可能用词不太准确），最终成为scythe的故事。个人觉得这本书在情感和内心活动方面描写简洁而生动，没有很难的单词或句子，但却很容易让读者带入其中。情节也比较紧凑，总是能给读者留下一些悬念，整体的阅读体验是非常轻松愉快的。当然，作为青少年小说，这是最基本的要求，否则当代年轻人哪里会有耐心看呢（手动狗头）。 我读这本书的目的当然不是为了看小说，一如往常，主要目的还是为了增加英文阅读，学习英语，虽然没有看英文blog学习的东西多，但是作为下班后的消遣，还是很有趣味性的。 当然，我个人认为这本书并不只是想要讲故事这么简单：从书中每一节前都有一个scythe的笔记可以看出，作者希望表达一些跟深层次的思考。在人工智能的管理下，在没有生老病死的社会中，我们想象中这应该是人类所期盼的大同社会。然而，人类的本性就是趋利避害。就为了求得一年的immunity，普通人变得sycophantic；而Scythedom更是党派斗争的缩影（小说中做了理想化处理，存在明显的好坏之分，但现实中很难存在）。小说通过不同scythe gleaning/killing过程的对比，利用杀人的话题讨论了人性的善良：对即将被glean的人的尊重，对自我compassion和conscience的要求，等等。 但我觉得比较遗憾的地方是scythe的笔记，笔记里有时候会写一些看似很“深奥”的东西，或者是scythe每天在humanity中挣扎的工作中的体会。我个人觉得，这个笔记写的“深奥”不是问题，我反而认为，这个笔记就是要“深奥”，让读者第一次看的时候觉得云里雾里。然后在接下来一节里，作者可以通过故事去呼应这个笔记，让读者有种回过头来看恍然大悟的感觉。可是，也许是我水平有限，我没有能读出这种感觉，我反而觉得这个笔记真的只是故事情节的简单补充，帮助我们理解书中人物的性格。当然这也是很好的，只是我可能对一部青少年作品太过苛求了。 总的来说，作为消遣我还是很推荐这本书的，读起来没什么压力，剧情也很有趣。这本书是系列的第一本，希望之后的两本能有更多的思考和对社会的反思。","categories":[],"tags":[{"name":"reading","slug":"reading","permalink":"https://proverbs.github.io/tags/reading/"},{"name":"novel","slug":"novel","permalink":"https://proverbs.github.io/tags/novel/"}]},{"title":"My 2020 End-of-Year Review","slug":"My-2020-End-of-Year-Review","date":"2021-01-01T17:49:27.000Z","updated":"2021-05-30T16:25:43.056Z","comments":true,"path":"2021/01/01/My-2020-End-of-Year-Review/","link":"","permalink":"https://proverbs.github.io/2021/01/01/My-2020-End-of-Year-Review/","excerpt":"My 2020 End-of-Year Review Prologue 我是在一次road trip中迎来2020的：Bay Area -&gt; SF -&gt; LA -&gt; San Diego -&gt; Las Vegas -&gt; the Grand Canyon -&gt; Bay Area。这是我第一次road trip，也是目前唯一一次。但一个happy start并没有持续多久：在CMU最后一学期刚开始就隐约有了对covid的担忧。起初只是戴口罩上课，然后没过多久就开始了无限期的stay-at-home，这也让本就没有什么学习状态的我更加放肆颓废。直到毕业典礼，covid已经日渐严重，毕业典礼取消了，同时也宣告了一个残酷的事实：我不仅错过了undergraduate的毕业典礼，也错过了master的毕业典礼——我已经没有机会再参加自己的毕业典礼了，这也可能成为这辈子的一个遗憾吧。","text":"My 2020 End-of-Year Review Prologue 我是在一次road trip中迎来2020的：Bay Area -&gt; SF -&gt; LA -&gt; San Diego -&gt; Las Vegas -&gt; the Grand Canyon -&gt; Bay Area。这是我第一次road trip，也是目前唯一一次。但一个happy start并没有持续多久：在CMU最后一学期刚开始就隐约有了对covid的担忧。起初只是戴口罩上课，然后没过多久就开始了无限期的stay-at-home，这也让本就没有什么学习状态的我更加放肆颓废。直到毕业典礼，covid已经日渐严重，毕业典礼取消了，同时也宣告了一个残酷的事实：我不仅错过了undergraduate的毕业典礼，也错过了master的毕业典礼——我已经没有机会再参加自己的毕业典礼了，这也可能成为这辈子的一个遗憾吧。 Chapter One: Divergency 毕业季的假期总是令人向往：没有任何学业压力，还能拥有更长的假期。作为告别学生时代，真正走向社会的过渡期，从过程上来说我并没有荒废这段时间。我拓展/找回了很多新的/旧的兴趣爱好，也尝试做着一些改变。 健身——我重回了大一大二时坚持锻炼的状态，并且一直持续到了现在。虽然没有每天铁打不动的坚持，但至少也有80%的出勤率。体重也在拔牙前降了15lb，明显感觉小肚子在变小（在牙齿恢复后，有些放肆了，最近体重有点小增）。现在唯一的问题是没能保持足量的时间，假期的时候能保证每天40分钟，上下午各一次，而现在只剩下每天15-20分钟了。【坑1：健身计划】 绘画——这应该是我最早的爱好了吧。我相信至少在我小学一二年级的时候我是真的喜欢画画，我经常在家自己画一些“乱七八糟”的。从最初的简笔画，到水彩，水粉，到最后的线描，素描。我有过很多绘画老师，虽然我已经记不得他们是谁了，但我记得他们都是非常好的老师，经常带我做新的尝试：国画，版画，油画，印象里还有雕刻。后来随着年级升高，学习压力开始变大了，也就只有周末上兴趣班的时候会画了。可能也就是那时候，我已经不那么热爱绘画了——因为我已经不会在我的课余时间画画了。我想那时候我最爱的应该是篮球吧，哈哈。大学时期虽然有很多时间，但是那会真的很浮躁，沉迷于游戏和直播无法自拔。直到这个假期，才真的有欲望重新找回之前的爱好。显然我已经回不去背着画板和带着一堆颜料/铅笔去画画的时代了。利用ipad+apple pencil+procreate，二次元人物成为了我的切入点，我跟着b站的up主画了不少纸片人（老婆）。曾经的水平不在了，但我还是乐在其中，也小有成就感。但我画画有个“毛病”：我需要非常专注，一气呵成，隔时间太久我就很难回到之前的状态了。也出于这个原因，开始工作后，我发现自己很难抽出大块的时间画画了。但其实这只是借口，我知道自己只是懒惰了，周中没有时间，但是周末总是可以有3-4个小时可以用来画画的，甚至画一些简单的一个小时内能完成的总是可以的，但我却很少画。但也不是说必须要坚持画画，但我认为是时候思考我画画是为了什么这个问题了。当然不止画画，还有其他的所谓爱好。【坑2：爱好与坚持】 练字——我从小就很羡慕女同学写的字，但也只是羡慕，从未有过真正的行动。大学时买过一箱字帖和练字纸，最后潦草的胡乱描完一本就弃了。这次，更详细的在知乎上看了建议，看了推荐，甚至都选好了字体目标，但最终还是没有开始就夭折了。【坑2：爱好与坚持】 看书——主要看的是英文原版书，目的是提高英语水平。由于水平实在有限，而且又要避免内容过于无聊导致没有动力坚持，我选择了没什么“营养”的英文的青少年小说。刚开始的时候有些吃力，但是慢慢进入状态后看的也不慢，一个假期也读了好几本书。但在读完了几本后，我突然意识到我又一次陷入了为了读完书而读书的状态。我读英文书最终目的是提升英文水平，但是我并没有很好的整理阅读中遇到的单词、短语和句子表达，所以基本上是无用功。然后我停止了阅读，转头开始整理读书的笔记（我做笔记的习惯还是不错的，就是不爱review，所以等于白做）。笔记的整理和复习持续到了工作开始，之后就没有时间做了，因为真的很耗时间：整理相关短语，例句。还有更严重的问题就是，整理完，每天虽然会复习，但是没有输出自己所学知识的途径，不能真正应用掌握，而且没什么成就感，很难坚持。【坑4：英语；坑5：阅读】 Blog——我已经很久没有写过技术型blog了，可能因为我越发觉得自己的渺小，自己的技术水平的薄弱。所以这次重启blog的主要目的是记录生活，锻炼自己的英文（没错，我强迫自己用蹩脚的英文写）和思考总结能力。我给大部分我读的小说写了读后感，给我玩过的有意思的游戏写了游戏感想，给我读的技术型书籍写了总结。但是，从目的上讲，这又是一次失败。我在用英文写作的过程中，还是摆脱不了自己的comfort zone：我总尝试用自己会的词和句型去表达，而不去确认这是否是最准确的，最自然的表达方式。结果就是，我的表达方式还是只限于那几种我熟悉的，没有学到任何新的东西。我觉得是时候增加对别人blog的阅读量，学习别人是怎么写blog的，怎么使用句子的。至于总结思考能力，由于心思都在英文上，这已经不是我的重点了，所以一般我只是简单表达我内心最直观的想法。【坑4：英语；坑6：思考，总结与表达】 总体而言，最后的一个假期虽然收获不大，但是起码有所尝试，也没有浪费太多时间在视频、游戏上。 Chapter Two: Convergency 随后，便正式开始了自己的SWE生涯（WFH），拥有了稳定的收入（如果不被fire的话）。当然，开始工作的生活就单调了很多： 投资——开始炒股。虽然常和朋友们吐槽股市行情，羡慕别人的收益率，看着tesla，nio飞涨，满嘴血亏，但我其实还是比较佛系的，没有指望说靠着炒股能一夜暴富。对我来说，炒股只是防止存在银行的钱因为通货膨胀而贬值罢了。所以我大部分的钱都存到401k里了，买了etf吃吃大盘红利，只有一小部分在robinhood里，买一手“梦想”，亏了也不心疼。 车——买了人生第一辆车：白色Camry（本想买accord，但dealer因为covid库存少，还提价让我十分不爽，一气之下投奔了toyota，所以买到camry也是巧合啦）。虽然不是什么好车，也背上了“巨额”债务，但还是很激动，毕竟人生中第一个“大额”资产。一开始基本把前两个月的工资都用来还贷了，想尽快pay off。但后来想了想，APR也不多，留着投资或者慢慢还款刷信用也都很香，便开始只付月供了。这样每个月也不会有那种压力了。 工作——ramp-up很快，毕竟我是return回的原组。每天基本上就是在senior的lead下，做一些projects。收获不能说没有：代码更规范了，业务逻辑理解的更多了，也成为了某个proj/feature的go-to person，但是没有我想象的多，oncall基本上还是处于懵逼状态。在年末放假前，我收到了前manager在跳槽前给我的review，我觉得非常好准确。结合一些我自己的总结，我的主要问题有：（1）communication and collaboration：我不是一个爱发言的人，尤其是在开会的时候。当然也存在客观原因，比如我并不很了解业务逻辑，或者不是很熟悉。还有一些主观原因就是，主要的精力在“听懂”英语上，而不能做到边听边思考。（2）tech skills vs. Business logic：我不能把所有的决策都交给PM，而自己只是单纯的implementation。相反，我们应该积极和PM沟通，提出自己的见解，当然这同样需要有较深的对技术和业务的理解。我记得很清楚有一次我问manager对于一个new grad，最应该优先掌握的是什么，他说是对业务的理解（business logic and work flow），不只是组里的业务，还有跨组的，甚至整个公司的。（3）readership and code review：就像manager说的，首先从对组里的业务逻辑有所理解。尽管standup里大家会汇报自己的工作情况，但是缺乏context，所以最简单有效的方法就是review别人的代码，比如每天上班/吃午饭回来/晚上下班前查看PR。就算现在没有readership，但至少可以学习别人的代码，理解别人在做什么。当然，说了这么多问题，我也不是一无是处嘛，我个人认为做得比较好的是，我非常专注，也总能自己尝试解决问题。对于实在无法解决的问题，至少在麻烦别人之前会自己花些时间研究，这是对别人起码的尊重。 生活——相对非常规律。每天早上基本上7:30-8:00起床—锻炼—吃饭—洗漱，然后9:00开始上午的工作。午饭基本上就是顿顿鲜虾云吞面，因为真的没时间做饭，也不喜欢外卖，觉得油太重不健康（默默流下了贫穷的泪水）。然后开始下午的工作，直到6:00。晚饭我和舍友会一起认真做，一人一道菜，顺便吹吹B，吃饭的时候看看电视剧或者综艺。吃完饭如果工作上事情比较多就再工作一个小时，写写daily summary。最后就是练习吉他—看会视频—洗澡，洗漱—11:00睡觉。周末也会早起（生物钟已形成），半天用来买菜，半天用来躺尸放空自己，剩下的一天和朋友出去hiking或者做一些我也不知道是什么的事情（就是混），总之时间就过去了。从前的我如果有周末的空闲时间，肯定会掏出游戏来打，但是不知道因为什么，（可能是因为年纪大了，精力跟不上了？）买游戏倒是勤快了，但是从来没有下载下来玩过，新游戏主机也吃灰好几个月了。 亲情——因为疫情，已经一年半没有回家/回国了。说实话，我没有我想象中那么想家，我唯一担心的是父母的健康。他们在这一年里相继做了一个小手术，然而他们都是在他们要康复的时候才会告诉我。我能理解他们不想让我担心，但是我还是很惭愧。这也加剧了我对回国与留美工作的纠结。我在出国前就给自己定了目标，我一定会回国的，大概也就是在美国工作2-3年，至少把这两年在美国上学的学费挣回来。但真正工作后，虽然公司的wlb相对较差，但是比起国内仍然是一个天上一个地下，加上又侥幸抽到了H1b，默默的将期待留美工作的时间增加到了5-6年，等升到senior再回国。我没有和父母说，也不知道怎么和父母说。父母也好像知道这是个禁忌话题，所以从没有正面问过我打算什么时候回国。但是从他们开始催婚，开始让我关注国内的公司和岗位早做打算，甚至已经开始在上海帮我物色房子了，我明白，他们想让我回去了。但我还是有些舍不得湾区惬意丰富的生活。在接下来的一年里，我可能还会出于纠结之中，但希望疫情早日好转，回国的时候可能能有时间和父母深入沟通一下，早日定下职业规划。 友情——我不是个social king，相反我比较喜欢小圈子的生活。每天和舍友吹B扯皮做饭看电视，周末和其他不同的朋友去hiking，过节小聚一下，或者出去road trip、滑雪之类的，我已经很满足了，谢谢你们的陪伴。 Epilogue 现在每天生活过得不紧不慢，但也没有很多可支配时间。阅读，练字，绘画，网课（非专业，比如finance，musical theory等等），写作，英语，甚至“第九艺术”都不能善始善终。但是发现了生活的精彩之后，欲望也开始膨胀，想学的无论是专业知识还是兴趣还好都太多了，很多由于时间缘故，只能浅尝辄止，无法精进。但无论是练字，绘画，滑雪，英语，不精进却享受不到乐趣，实在让人烦恼。 我想，我需要首先回答一个问题：我的目标（用父母的话说：一年规划/三年规划/五年规划）是什么（而不是我每天要做什么）。有了目标，按照目标的优先级选择时间应该如何分配，时间不够用就砍掉优先级低的。人生不可能完美，所以抓住最重要的事情去做才能不后悔。【坑7：规划】 最后，我想给用一个词定义2020：自识；再用一个词作为2021的目标：取舍。希望我能在2021年的年末总结里再用这个词定义2021吧！01/01永远不会是新的开始，它的意义也许只是提醒那些迷失的我们去进行总结与改进，因为只有真正开始改变才是真的开始！","categories":[],"tags":[{"name":"life","slug":"life","permalink":"https://proverbs.github.io/tags/life/"},{"name":"reflection","slug":"reflection","permalink":"https://proverbs.github.io/tags/reflection/"}]},{"title":"Design Pattern Tour: A Summary","slug":"Design-Pattern-Tour-A-Summary","date":"2020-07-05T17:39:40.000Z","updated":"2021-05-30T16:25:43.046Z","comments":true,"path":"2020/07/05/Design-Pattern-Tour-A-Summary/","link":"","permalink":"https://proverbs.github.io/2020/07/05/Design-Pattern-Tour-A-Summary/","excerpt":"Design Pattern Tour: A Summary After learning all these design patterns, I feel the design patterns themselves don’t really matter. Instead, the intent of separation(or decouple, or Single Responsibility Principle) and the idea of delegating(or composite) are the kernel. These design patterns are just some common solutions for some popular use cases in development and their ultimate goal is still to decouple the code and then to achieve a high usability and extendability.","text":"Design Pattern Tour: A Summary After learning all these design patterns, I feel the design patterns themselves don’t really matter. Instead, the intent of separation(or decouple, or Single Responsibility Principle) and the idea of delegating(or composite) are the kernel. These design patterns are just some common solutions for some popular use cases in development and their ultimate goal is still to decouple the code and then to achieve a high usability and extendability. To summarize the series, I think there are three levels of understanding design patterns: The lowest level: You should at least know which design patterns it’s using when you are reading source code. The intermediate level: You should be capable of figuring out design flaws of the project when you are reading its source code and coming up with some sketchy ideas for better design(which follows Single Responsibility Principle and Open/Closed Principle). The highest level: You can design a complete project from the requirements, while maintaining usability and extendability. Of course, a level can be harder to achieve than its next level when you are dealing with a more complicated project. For myself, I think I’m still at the transition phase from the lowest level to the intermediate level. This might last long because it requires an extensive reading of source code. But I will keep thinking in the design pattern way while I’m exploring the source code. Also, I will strictly apply design patterns to my own projects. Hereby, I made a resolution. And let’s see if I can do better a year later!","categories":[],"tags":[{"name":"design pattern","slug":"design-pattern","permalink":"https://proverbs.github.io/tags/design-pattern/"},{"name":"tech","slug":"tech","permalink":"https://proverbs.github.io/tags/tech/"}]},{"title":"Design Pattern Tour: Behavioral Patterns","slug":"Design-Pattern-Tour-Behavioral-Patterns","date":"2020-07-04T23:51:38.000Z","updated":"2021-05-30T16:25:43.046Z","comments":true,"path":"2020/07/04/Design-Pattern-Tour-Behavioral-Patterns/","link":"","permalink":"https://proverbs.github.io/2020/07/04/Design-Pattern-Tour-Behavioral-Patterns/","excerpt":"Design Pattern Tour: Behavioral Patterns Iterator Readings: https://refactoring.guru/design-patterns/iterator Iterator is an approach to provide collections(or containers) a common way to traverse, while hiding the inner structure of the collections. The application of it is obvious: Java and CPP both use this pattern. For the structure of this pattern, the collection class normally provides an interface of getIterator(), the iterator class, on the other hand, offers interfaces of hasNext() and getNext(). In the concrete iterator class, we usually need to add a variable as a reference to the collection instance. Concrete iterators can implement different kinds of traversal methods(e.x. DFS, BFS, etc.) easily, which makes it quite convenient to add new collections and iterators, or to replace current collections and iterators with new one in the client code. This design is not only good for extensibility but also Open/Closed Principle. The separation of collections and iterators decouples the traversal from business logics, embodying Single Responsibility Principle. However, it sometimes might make things more complicated.","text":"Design Pattern Tour: Behavioral Patterns Iterator Readings: https://refactoring.guru/design-patterns/iterator Iterator is an approach to provide collections(or containers) a common way to traverse, while hiding the inner structure of the collections. The application of it is obvious: Java and CPP both use this pattern. For the structure of this pattern, the collection class normally provides an interface of getIterator(), the iterator class, on the other hand, offers interfaces of hasNext() and getNext(). In the concrete iterator class, we usually need to add a variable as a reference to the collection instance. Concrete iterators can implement different kinds of traversal methods(e.x. DFS, BFS, etc.) easily, which makes it quite convenient to add new collections and iterators, or to replace current collections and iterators with new one in the client code. This design is not only good for extensibility but also Open/Closed Principle. The separation of collections and iterators decouples the traversal from business logics, embodying Single Responsibility Principle. However, it sometimes might make things more complicated. Chain of Responsibility(CoR) vs. Decorator Readings: https://refactoring.guru/design-patterns/chain-of-responsibility The intent of CoR is to deal with requests: A request can be passed through a bunch of bandlers and each of the handlers can decide if it wants to handle the request or just to pass it on to the next handler. It looks very similar to Decorator, because both of them have something passing through a chain structure. However, Decorator, as a structural pattern, has a fundamental functionality, which anyhow must be executed. And the other decorators are just working to improve this functionality. On the other hand, CoR, as a behavioral pattern, doesn’t have a basic function. All handlers can decide to jump out of the chain without passing the request to the following handlers. A typical use case is sequential access filter, including login authentication(checking if the username/password is correct, the user has access permission, etc.). Another example is event bubbling(https://www.jianshu.com/p/1f45f5fae39e). As for advantages, it, first, follows the Single Responsibility Principle, making logic more clear. And it follows the Open/Closed Principle, so not only we or the client can easily add handlers(by extending the handler interface). What’s more, the client can decide which handlers she wants to use and the order of them in the chain(which is similar to Decorator). The implementation usually requires an abstract class of handler, consisting of a reference to the next handler(nextHandler), a function handleRequest() and a function handle()😦https://www.jianshu.com/p/1f45f5fae39e) 123456Handler handler1=new Handler1();Handler handler2=new Handler2();Handler handler3=new Handler3();handler1.nextHandler=handler2;handler2.nextHandler=handler3;handler1.handleRequest(request); Command Readings: https://refactoring.guru/design-patterns/command The kernel of Command is to turn the requests(or method call) to stand-alone objects. Some typical applications include delayed execution(e.x. To add requests to a queue because of the long execution time) and undo/redo(e.x. In editor or painting). A generic application is GUI, where we can add a layer of Command to decouple UI layer and business logic layer. Without the Command layer, the UI layer has to know all the method calls in the business logic layer. However, with the help of the Command layer, the UI layer only needs to parameterize(abstract) the method calls to command objects, so that command objects can interact with business logic instead. The critical part of the implementation is the function executeCommand(new CutCommand(editor)) and the function command.execute(). (https://refactoring.guru/design-patterns/command/java/example#example-0--editor-Editor-java) A more generic application is to parameterize method calls and delegate the function calls from the sender to the receiver(unidirectional). Mediator Readings: https://refactoring.guru/design-patterns/mediator https://design-patterns.readthedocs.io/zh_CN/latest/behavioral_patterns/mediator.html https://www.cnblogs.com/gaochundong/p/design_pattern_mediator.html Mediator is to use an intermediate object to encapsulate interactions between a series of objects(e.x. components). From the communication structure of the system aspect, using Mediator reshapes the structure to a star from a net. In other words, a mediator works as a transportation hub. Mediator is similar to generic Command. But Mediator allows bidirectional communication between senders and receivers. And compared to Command, Mediator doesn’t stress the conversion from method calls to objects. From the intent aspect, both Mediator and Facade are trying to simplify APIs(or decouple). But Mediator, from my understanding, is more like a bidirectional Facade. Facade is aiming to simplify function calls from the client to subsystems, which don’t realize the existence of Facade. However, all senders/receivers are at equal positions and they all know Mediator exists. The advantages of Mediator is to extract the communication(interaction) from the sender/receiver classes (following the Single Responsibility Principle) and manage them in a single class. From the aspect of senders/receivers, the communication interface is simplified(probably to a single function notify()). However, there’s a huge problem: To manage the communication between many objects, Mediator has to reference all the related objects(to delegate functionalities), making Mediator class too bulky and operations much more complicated. Observer Readings: https://refactoring.guru/design-patterns/observer http://design-patterns.readthedocs.io/zh_CN/latest/behavioral_patterns/observer.html Observer is the subscription(or listener) mechanism: Objects can subscribe/unsubscribe an event(or a kind of events) to a publisher(an object). And the event occurs, the publisher will notify all subscribers, updating the states of the subscribers. From the aspect of communication structure, Observer and Mediator are the same, which both have a star structure. However, all edges in Mediator all bidirectional, while all edges in Observer are from the center to the outside. So, I think Observer is a specialized Mediator for Sub/Pub scenarios. There are many use cases, including forums, video websites and reading websites, applying this pattern. Strategy Readings: https://refactoring.guru/design-patterns/strategy The intent of Strategy is to move different algorithms of the same functionality(using the same interface) to different classes, making them interchangeable. Normally, it references an instance of the algorithm class as a member variable. (the variable delegates the functionality in the context class) To implement the same pattern, we can also extend concrete context classes and override the algorithm interface(this is actually Template Method pattern, which I will talk about later). So, applying Strategy is just for Single Responsibility Principle and separate algorithms with the logics in the context, and as well, using composite instead of inheritance. Of course, if the programming language supports function as arguments, then we can simply pass function names (or using anonymous functions) as arguments, instead of adding complexity. State Readings: https://refactoring.guru/design-patterns/state State’s intent is to change the member variable(composite variable, which is always an object implementing a specific interface) to perform different functionalities(behaviors). I think State is a special case of Strategy. Though they both try to change their own behaviors by changing the delegating variable, delegating objects in State are always interdependent, because they need to transfer from one to another within their own logic, like automaton. In Strategy, however, delegating variables are invisible to each other. It will work as long as they implement the same interface. It can be used when the behavior of a class relies on different states and all the states have transferrable mechanisms among them. Actually, I have met a similar use case where I was implementing TCP in my Computer Networks course. I was using an enum to represent the state and using switch for different behaviors, which follows neither Single Responsibility Principle nor Open/Closed Principle because I had to change the code snippet of switch when I changed the behavior or added new states. Template method Readings: https://refactoring.guru/design-patterns/template-method Template Method is aiming to solve the code reuse problem where two concrete have the same structure, but some of the detailed implementations are different. Usually, Template Method is inheritance from an abstract class. I’ve already mentioned it in the section of Strategy. And I think using Template Method or Strategy is determined by whether it follows Single Responsibility Principle. Visitor Readings: https://refactoring.guru/design-patterns/visitor https://refactoring.guru/design-patterns/visitor/java/example#example-0--shapes-Shape-java When you want to add the same operation to all elements of a complicated object(e.x. Hierarchy and tree) and you want to change as little code as possible, You can apply Visitor pattern with the help of Double Dispatch. Actually, when I see the intent for the first time, my first idea is to add a new interface and all the classes then can extend this interface, like Composite pattern. However, This violates the Single Responsibility Principle. As for Open/Closed Principle, I think they both follow it(or they neither follow it. It depends.) at the same level because both of them modify the classes(adding new functions). BUT, if I’ve already added an operation and now I want to add another. Then, using Visitor pattern will be a better choice, because we can reuse accept() without modifying the classes this time. The only thing we need to do will be to implement a new concrete visitor(from Visitor interface) ConcreteVisitor2 and to call object.accept(new ConcreteVisitor2()). This is why all materials on the Internet say one of Visitor’s advantages is following the Open/Closed Principle. Memento Readings: https://refactoring.guru/design-patterns/memento The intent of Memento is to create snapshots of objects and to allow restore from snapshots without knowing the details of the objects(or even cannot directly access the object’s fields/getters/setters). A typical application is serialization, such as Serializable interface in Java. The client doesn’t have to know what member variables an object has, but she can serialize/deserialize it as long as the class implements the Serializable interface. Now, I want to mention Visitor. Because if we can directly access the object’s fields/getters/setters, then we can create snapshots and restore from snapshots using Visitor pattern. Finally, I’d like to tell the difference between Prototype(Creational pattern) and Memento(Behavioral pattern): Prototype is to solve the issue of copying objects, which happens in RAM, while Memento is to persist objects, usually to external devices, such as HD or networks.","categories":[],"tags":[{"name":"design pattern","slug":"design-pattern","permalink":"https://proverbs.github.io/tags/design-pattern/"},{"name":"tech","slug":"tech","permalink":"https://proverbs.github.io/tags/tech/"}]},{"title":"Design Pattern Tour: Structural Patterns","slug":"Design-Pattern-Tour-Structural-Patterns","date":"2020-07-03T06:01:07.000Z","updated":"2021-05-30T16:25:43.046Z","comments":true,"path":"2020/07/02/Design-Pattern-Tour-Structural-Patterns/","link":"","permalink":"https://proverbs.github.io/2020/07/02/Design-Pattern-Tour-Structural-Patterns/","excerpt":"Design Pattern Tour: Structural Patterns Adapter vs. Proxy vs. Decorator Adapter Readings: https://refactoring.guru/design-patterns/adapter https://blog.csdn.net/carson_ho/article/details/54910430 I think Delegate is the core idea of all structural patterns, as well as some creational patterns, such as Factory and Builder. Adapter, as the name indicates, is a way to connect incompatible interfaces. There are a variety of implementations, as long as the adapter can provide the client with all target interfaces(interfaces required by the client). There are mainly two kinds of implementations: Class adapter: The adapter class should inherit from the service class and implement the target interface. But it sometimes requires multiple inheritance, which is not supported in some programming language(e.x. Java). Object adapter: The adapter class, as a wrapper, only needs to implement the target interface, and the service will reside within as a wrappee(adaptee), following the Object Composition Principle. Personally speaking, I would prefer this approach, because it’s more flexible and doesn’t involve the annoying multiple inheritance.","text":"Design Pattern Tour: Structural Patterns Adapter vs. Proxy vs. Decorator Adapter Readings: https://refactoring.guru/design-patterns/adapter https://blog.csdn.net/carson_ho/article/details/54910430 I think Delegate is the core idea of all structural patterns, as well as some creational patterns, such as Factory and Builder. Adapter, as the name indicates, is a way to connect incompatible interfaces. There are a variety of implementations, as long as the adapter can provide the client with all target interfaces(interfaces required by the client). There are mainly two kinds of implementations: Class adapter: The adapter class should inherit from the service class and implement the target interface. But it sometimes requires multiple inheritance, which is not supported in some programming language(e.x. Java). Object adapter: The adapter class, as a wrapper, only needs to implement the target interface, and the service will reside within as a wrappee(adaptee), following the Object Composition Principle. Personally speaking, I would prefer this approach, because it’s more flexible and doesn’t involve the annoying multiple inheritance. The design of adapter follows the Single Responsibility Principle: The function calls and arguments(data) are converted in the adapter class, instead of in the client code. It also follows the Open/Closed Principle: If you want to change the backend service or change the frontend APIs while you still want to reuse your existing service, the only thing the client needs to do is to replace her current service with the adapter class. As for the advantages, I still cannot agree with the opinions of decoupling. I think it’s just a convenient way for code reuse. So, here comes a problem: Can an adapter adapt to multiple services? Technically, it definitely can. We can simply add more services as adaptees. However, from the aspect of the intent, to add multiple services is to simplify(aka. We just want to use part of the functionalities) while Adapter is focusing on changes(aka. We want to reuse the code with different target interfaces and implement the same functionalities). Thus, to adapt multiple services can be defined as another structural pattern: Facade. And this website(https://refactoring.guru/design-patterns/adapter) also mentions this difference: “Facade defines a new interface for existing objects, whereas Adapter tries to make the existing interface usable. Adapter usually wraps just one object, while Facade works with an entire subsystem of objects.” Proxy Readings: https://refactoring.guru/design-patterns/proxy Proxy looks quite similar to Object Adapter from the code aspect, but the goals are different. Adapter just wants to have the same(existing) functionalities, but the target interfaces are not compatible. However, Proxy wants to enhance current functionalities or add new functionalities while the interfaces remain the same. For Proxy, new functionalities involve logging, cache, RPC, access control, lazy initialization, etc. Decorator https://refactoring.guru/design-patterns/decorator https://blog.csdn.net/small_june/article/details/28631369 The implementations of Decorator, Proxy and Adapter are similar, which are all based on the Object Composition Principle and wrap a wrappee to delegate. Decorator and Proxy are both to enhance the functionalities and their difference is slight. From the reading materials, I prefer this explanation, although it’s not very strict: “Decorator focuses on adding new functionalities dynamically, while Proxy underscore the access control over objects. In other words, proxy class can hide detailed information from the client. Therefore, we always create an instance of a class(a wrappee) within the proxy class. However, we usually pass the original instance of a class to the constructor of the decorator class as an argument while applying the decorator pattern.” And “pass the original instance of a class to the constructor of the decorator class as an argument” also explains why decorators are always implemented recursively, because we can add a bunch of decorators to the same class(or a method in the class). Actually, this explanation is still not very clear. So, if I’m asked to tell the difference, I’d like to say, if there’s only one new functionality and the client can decide whether she wants to use it or not, I will use Proxy. However, if there are N functionalities, and the client can select K(0&lt;=0&lt;=N) of them to add, I will use Decorator. Another thing I want to mention here is the difference between Java Annotation and Python Decorator. They look the same, like @xxx. However, they are completely two different things. Java Annotation is just an annotation(a marker). And it by itself just stores metadata and you must have something that inspects it to add behaviors. And Python Decorator is a syntactic sugar for passing a function to another function and replacing the first function with the result. (But of course, Python Decorator can decorate classes: https://foofish.net/python-decorator.html)(https://stackoverflow.com/questions/15347136/is-a-python-decorator-the-same-as-java-annotation-or-java-with-aspects) Bridge vs. Strategy Bridge Readings: https://refactoring.guru/design-patterns/bridge Bridge’s intent is to split a monolithic class, meaning to avoid a class being too big. Of course, it should still follow the Single Responsibility Principle. Thus, the normal idea is to split it by Abstraction and Implementation. Abstraction, from my understanding, is business logics, while Implementation means the implementation details. And both Abstraction and Implementation, as an interface, are able to be extended. In practice, the Implementation will serve as a member variable(in composite way) to delegate the details. I want to take the remote(Abstraction) and TV(Implementation) as an example:The client only cares if she is able to switch channels and turn up/down the voice, but doesn’t care how the remote does those, which is the responsibility of the TV. Therefore, the Abstraction and the Implementation get separated.Remotes of the same brand should have the same interface for different TVs, so they should be able to pair any of these TVs. For the use cases, I think Bridge gives me a sense of “2D orthogonal”. Strategy(or State) Strategy is a behavioral pattern. Although the implementation of Strategy is similar to Bridge, Bridge, as a structural pattern, is focusing on simplifying the code structure. However, behavioral patterns usually consider the convenience of functionalities. You should find there are only a few ways of design pattern implementation(e.x. delegate, composite), although there are a lot of design patterns. So, I don’t think we should remember all these concrete patterns. Instead, we should learn what problems they are trying to solve(aka. intent) and their core ideas, and then we can say we have truly understood design patterns. Adapter vs. Facade Facade Readings: https://refactoring.guru/design-patterns/facade I think I’ve mentioned Facade in the section of Adapter before: Facade is aiming to simplify the interfaces for multiple classes(or subsystems) as a coordinator, whose implementation is just like an adapter with many services embedded. Practically, when the logics become so complicated that the client feels uncomfortable using the framework(e.x. The client finds she is writing more code for a single logic), we should abstract a simple interface for the commonly used logics and probably can apply Facade if we still want to reuse current code. For example, I really like this example of MVC(https://zhuanlan.zhihu.com/p/26036733) that the Controller becomes too bulky to be maintained(probably because I had a similar experience). And for Facade, I think it’s safe to say it decouples the client code, because the client only needs to interact with Facade rather than with all kinds of subsystems(Because all couplings are moved into Facade class). There’s a small detail that Facade is usually implemented in the Singleton way because a single instance is enough for a coordinator. Others Composite Readings: https://refactoring.guru/design-patterns/composite https://www.cnblogs.com/peida/archive/2008/09/09/1284686.html If the object we are designing is of a tree structure and all the nodes in the tree(both leaf nodes and top nodes) have the same interface, then we can apply composite.A widely used case is UI components. Of course, the leaf nodes and top nodes always have some not in common. So, here comes the trade-off between safety and transparency. To add APIs which are supported by top nodes but not by the leaf nodes to the common interface increases transparency, but it undermines the safety because it’s apparently unsafe to be able to call some functions incompatible with leaf nodes. Otherwise, it improves safety but loses transparency because the client should check if a node is a top node or a leaf node before she calls the APIs. Thus, it’s one of the issues we need to consider while designing. Personally, I prefer the safer way. Although it breaches the intent of consistent interfaces of Composite, the logics are more reasonable. There’s an optimization of the implementation: Because of the tree structure, it always involves a lot of aggregation and traversal, which can be optimized using cache to make the program faster. Flyweight Readings: https://refactoring.guru/design-patterns/flyweight http://design-patterns.readthedocs.io/zh_CN/latest/structural_patterns/flyweight.html Flyweight is a method to save memory(RAM). It extracts a frequently used part from many objects of the same class(called Intrinsic State) as a class(or enum) and leaves the other part(called Extrinsic State) and then shares the frequently used part. Usually, it is combined with Factory Method because Factory can maintain a Flyweight pool of frequently used objects implicitly.","categories":[],"tags":[{"name":"design pattern","slug":"design-pattern","permalink":"https://proverbs.github.io/tags/design-pattern/"},{"name":"tech","slug":"tech","permalink":"https://proverbs.github.io/tags/tech/"}]},{"title":"Design Pattern Tour: Creational Patterns","slug":"Design-Pattern-Tour-Creational-Patterns","date":"2020-07-01T04:27:37.000Z","updated":"2021-05-30T16:25:43.046Z","comments":true,"path":"2020/06/30/Design-Pattern-Tour-Creational-Patterns/","link":"","permalink":"https://proverbs.github.io/2020/06/30/Design-Pattern-Tour-Creational-Patterns/","excerpt":"Design Pattern Tour: Creational Patterns Factory Readings: https://juejin.im/entry/58f5e080b123db2fa2b3c4c6 https://www.liaoxuefeng.com/wiki/1252599548343744/1281319170474017 https://refactoring.guru/design-patterns/factory-method https://refactoring.guru/design-patterns/abstract-factory First, I’d like to clarify the difference between all kinds of factory patterns. Simple factory: A single factory class; product is determined by the parameter passing to the factory class(or using Java reflection). Factory method: all products have their own specialized factory classes. Abstract factory method: based on factory method, but each of the factories will provide a set of methods for returning different kinds of products. Static factory method: there will be no factory class, instead, the functionality is implemented in the product class as a static function. To sum up, Factory can work as either a class or a function. Therefore, it’s just a design idea, instead of a concrete implementation. (this works for all the design patterns)","text":"Design Pattern Tour: Creational Patterns Factory Readings: https://juejin.im/entry/58f5e080b123db2fa2b3c4c6 https://www.liaoxuefeng.com/wiki/1252599548343744/1281319170474017 https://refactoring.guru/design-patterns/factory-method https://refactoring.guru/design-patterns/abstract-factory First, I’d like to clarify the difference between all kinds of factory patterns. Simple factory: A single factory class; product is determined by the parameter passing to the factory class(or using Java reflection). Factory method: all products have their own specialized factory classes. Abstract factory method: based on factory method, but each of the factories will provide a set of methods for returning different kinds of products. Static factory method: there will be no factory class, instead, the functionality is implemented in the product class as a static function. To sum up, Factory can work as either a class or a function. Therefore, it’s just a design idea, instead of a concrete implementation. (this works for all the design patterns) If you are new to Factory, you will probably be wondering if there’s any difference between using it and creating an instance using a constructor. Cannot polymorphism do the same thing? Personally speaking, I think we should find our new orientation(what we are doing): We are learning design patterns, because we want to design something good so others can use it easily. For example, we are developing a framework, and we hope our clients(developers who are using our framework) will feel comfortable using and customizing(extending) our framework. So here comes a design principle: Open/Closed Principle, meaning our design should be open to extension, but closed to modification. In other words, we only want to add more to code, but not to modify our current code(or modify as little as possible). This should be followed by both of us and clients. Ps. Simple factory doesn’t follow this principle, because it requires modification of the existing factory when we want to add a new product class. Thus, our goal is that we adding new features will not influence(or influence as little as possible) the code from the client, which means the client doesn’t need to change their code, and it still works. And Factory is designed for this goal: the client doesn’t need to know the creation of a product(because it could be quite complicated if it’s a bulky class). Instead, she can just ask the factory for that product. For instance, the client wants a computer for exploring webpages. She doesn’t care if it has a 4k screen, or if its CPU is Intel. As long as it makes her feel comfortable exploring webpages, it’s fine. So, as a factory, even if I’m changing Intel to AMD, I don’t need to tell you, and you will not notice it, because you will be still having fun surfing the Internet. While I was learning the Factory pattern, almost all materials mentioned this pattern was good because it decoupled the code. However, I think there’s no REAL decoupling, because as long as two classes are related, they are coupled. We eliminate the coupling between the client code and the product code, but we bring in coupling between client and factory and that between factory and product. I think decoupling is mostly achieved using abstraction (as well as Liskov Substitution Principle, LSP). Thus, I’d like to say the advantage of Factory is to hide the details of the product creation, instead of decoupling.Of course, if you insist on decoupling, I would prefer this explanation of “coupling”(https://www.zhihu.com/question/21386172/answer/54501456 ): The essence of code decoupling is that one makes some assumptions about the other one. In other words, the more one assumes, the more coupling between them. And it’s very common that one couples many others. Also, you have to admit that product creation and product itself are two separate things(according to the Single Responsibility Principle). Then, using constructor with some default arguments or read arguments from configuration files will not be under our consideration. Thus, with this understanding, I think it’s safe to say Factory can decouple the code. Because without Factory, the client should assume how to use both the factory and product APIs. However, with Factory, the client only needs to know product APIs(the interface of Factory method is relatively stable, so to change products, the only thing we need to do is to change the Factory class). In conclusion, I think there are two main advantages/applications for Factory: To use Factory class to reuse cached instances instead of creating a new instance if the class is bulky. E.x. connection pool. To simplify the creation from the client side if the constructor requires many arguments. Factory class can load these arguments from configuration files, thereby separating the product and product creation and hiding the details of creation, making client code more clear. E.x. DB URL, DB username, DB password. Builder Readings: https://refactoring.guru/design-patterns/builder I think Builder is a better choice than Factory for understanding creational patterns, because it highlights the separation of creation and product and it doesn’t bring us questions of Factory like “why not use new to create instances directly”. Builder has two characteristics: stey-by-step(a sense of assembling) and hiding creation of complicated objects(from bulky class).As for Director, it’s just an encapsulation of the building process. Although it’s not a necessary part of Builder, I would recommend using it since it’s good design. I think Build shares the same advantages as Factory: To make client code focus on product interfaces. And it’s easy to extend: The client can extend a new concrete builder from the builder interface and replace the class name in her code without changing the logics. However, I don’t like the examples on the website. So I’d like to take another example.Suppose CarBuilder is the interface, which is extended by BMWCarBuilder and AudiCarBuilder. Then, the usage will be as follows. 1234CarBuilder cb = new BMWCarBuilder(); // CarBuilder cb = new AudiCarBuilder(); Director d = new Director(cb);d.buildSUV();Car c = cb.getResult(); If the client wants to build Audi, she just changes the first line and replaces the concrete builder with AudiCarBuilder. Prototype Readings: https://refactoring.guru/design-patterns/prototype Prototype is much easier and we can simply find an analogy in Java: Cloneable interface, which requires an implementation of the function clone(). Prototype is aiming to let us create a copy of an object without knowing what its class is. To use copy constructor we can do the same thing, but we would rely on the class, meaning we are creating a new object using CLASS, while we are creating objects from an object with the help of Cloneable. That’s their main difference. But usually we will call the copy constructor within clone(), so we still need to pay attention to the issue of shallow copy and deep copy. And in the cases of inheritance, clone() of a subclass sometimes may need to call its counterpart(aka. clone()) in its superclass for initializing new objects. By the way, Prototype Registry builds on Prototype pattern, which normally uses a hash map to cache some frequently used objects. The implementation is usually similar to the follows. 123Button b = new Button(10, 40, “red”);registry.addItem(“landingButton”, button);Button nb = registry.getByColor(“red”); Singleton Readings: https://refactoring.guru/design-patterns/singleton https://refactoring.guru/design-patterns/singleton/java/example#example-2 https://en.wikipedia.org/wiki/Double-checked_locking#Usage_in_Java https://blog.csdn.net/u011595939/article/details/79972371 Singleton aims to limit the amount of instances(usually 1) of a certain class. The implementation is to make the constructor private and to add a static function to serve as a constructor for creating objects. There are mainly two ways of Singleton: Lazy loading, which creates the instance(s) when function getInstance() is called for the first time; Eager loading, which creates the instance(s) at the initialization of the class. There are two main use cases I can come up with: To provide a substitute for global variables; To delay the initialization(with lazy loading) in order to save the memory. Although the definition of Singleton is simple, the implementation is quite annoying, because the issue of thread safety and potential attacks. Double-checked locking is an efficient way to solve this issue. However, in some languages(e.x. Java 1.4), a lot of implementations you find are probably problematic. The correct way is to add a seemingly useless local variable(https://refactoring.guru/design-patterns/singleton/java/example#example-2). However, this issue is solved in Java 1.5. So, to simply use volatile can guarantee the thread safety. In Java, another issue is serialization attack(https://blog.csdn.net/u013256816/article/details/50474678) and reflection attack(https://blog.csdn.net/u013256816/article/details/50525335), which can break the limitation of the amount of instances. So, the safe implementations of Singleton in Java are as follows. Eager loading: Enum is highly recommended(https://blog.csdn.net/qq_27093465/article/details/52180865). Lazy loading: Static nested class is recommended(http://wuchong.me/blog/2014/08/28/how-to-correctly-write-singleton-pattern/), which can defend reflection attack because inner class will not be automatically loaded. However, it’s still susceptible to serialization attack(https://blog.csdn.net/siying8419/article/details/82152921).","categories":[],"tags":[{"name":"design pattern","slug":"design-pattern","permalink":"https://proverbs.github.io/tags/design-pattern/"},{"name":"tech","slug":"tech","permalink":"https://proverbs.github.io/tags/tech/"}]},{"title":"Design Pattern Tour: Overview","slug":"Design-Pattern-Tour-Overview","date":"2020-06-30T22:42:44.000Z","updated":"2021-05-30T16:25:43.046Z","comments":true,"path":"2020/06/30/Design-Pattern-Tour-Overview/","link":"","permalink":"https://proverbs.github.io/2020/06/30/Design-Pattern-Tour-Overview/","excerpt":"Design Pattern Tour: Overview Today, I’d like to start a new series of Design Patterns. This is not a series for those who don’t have prior knowledge of these design patterns. So, my recommendation is to at least explore and skim through this website to gain some basic knowledge about design patterns. As for the code example, you can find a Java version on My Github, which is based on the example of the website and you should be able to run it directly. And as always, I will not talk about the detailed intents or implementations. Instead, I will be focusing on my personal understanding of these design patterns and their relationship and difference. Moreover, I will share some useful materials I was referring to for your further study.","text":"Design Pattern Tour: Overview Today, I’d like to start a new series of Design Patterns. This is not a series for those who don’t have prior knowledge of these design patterns. So, my recommendation is to at least explore and skim through this website to gain some basic knowledge about design patterns. As for the code example, you can find a Java version on My Github, which is based on the example of the website and you should be able to run it directly. And as always, I will not talk about the detailed intents or implementations. Instead, I will be focusing on my personal understanding of these design patterns and their relationship and difference. Moreover, I will share some useful materials I was referring to for your further study. This series will involve three blogs, including Creational Patterns, Structural Patterns and Behavioral Patterns. And here’s the outline for you to conveniently skip to the design pattern you are looking for. Creational Patterns: Factory(Factory Method, Abstract Factory), Builder, Prototype, Singleton. Structural Patterns: Adaptor, Bridge, Composite, Decorator, F acade, Flyweight, Proxy. Behavioral Patterns: Chain of Responsibility, Command, Iterator, Mediator, Memento, Observer, State, Strategy, Template Method, Visitor. Summary: What I was thinking after learning these design patterns. However, I always think that the name of a pattern doesn’t really matter. The only thing we should learn from these patterns is the underlying ideas. Hope my blogs will not waste your time and feedbacks are always welcome.","categories":[],"tags":[{"name":"design pattern","slug":"design-pattern","permalink":"https://proverbs.github.io/tags/design-pattern/"},{"name":"tech","slug":"tech","permalink":"https://proverbs.github.io/tags/tech/"}]},{"title":"[Reading]Percy Jackson and the Olympians: The Titan's Curse","slug":"Reading-Percy-Jackson-and-the-Olympians-The-Titan-s-Curse","date":"2020-06-21T04:20:26.000Z","updated":"2021-05-30T16:25:43.056Z","comments":true,"path":"2020/06/20/Reading-Percy-Jackson-and-the-Olympians-The-Titan-s-Curse/","link":"","permalink":"https://proverbs.github.io/2020/06/20/Reading-Percy-Jackson-and-the-Olympians-The-Titan-s-Curse/","excerpt":"Percy Jackson and the Olympians: The Titan’s Curse I don’t know how to evaluate this volume because it seemed like I was indulged in it. I indeed spent only two days reading it, but I can’t say it’s interesting. Probably because I finally figured out the stereotype of stories from the writer, which were just like American road movies. I can still remember some wonderful plots from the last volume The Sea of Monsters. However, for this volume, I can barely remember anything after reading. I think the only thing which motivate me to continue reading is the ending, which I hope will be the same as expectation.","text":"Percy Jackson and the Olympians: The Titan’s Curse I don’t know how to evaluate this volume because it seemed like I was indulged in it. I indeed spent only two days reading it, but I can’t say it’s interesting. Probably because I finally figured out the stereotype of stories from the writer, which were just like American road movies. I can still remember some wonderful plots from the last volume The Sea of Monsters. However, for this volume, I can barely remember anything after reading. I think the only thing which motivate me to continue reading is the ending, which I hope will be the same as expectation. In my last blog of The Sea of Monsters, I predicted that Thalia would be hesitating between good and evil. But finally, she would sacrifice herself to help Percy and let Percy become “the main in the prophecy”. I guess my prediction is almost perfectly correct. Luke tried to recruit her many times, and she never refused him decidedly although she “killed” Luke at last. To some extend, Thalia sacrificed herself in the front of the gods of Olympian by swearing an oath to become a Hunter. Then, Percy and she will not be killed by the gods. While reading this book, I have some predictions. When Percy just found these two sibling half-bloods in Westover Hall and their parent was unknown, I was guessing they were probably the children from Hades. Because Hades is the only god who had no known children. And according to the prophecy, Bianca and Zoe would be dead because the other three are main characters. It’s so obvious, right? At the ending, there are two suspenses for reader: Pan and Nico. So, here comes my prophecy. I think Grovor will find Pan and Nico will be the biggest boss in the next volume. In this book, Annabeth still insisted Luke was a good person(half-bloods) and he could be saved from the Titan, although Percy was strongly against it. However, I’ll be on Annabeth’s side and I think a good Luke will come back at the end of the next volume. However, I don’t know if I should continue on this series. Although it won’t take too much time for reading, I felt I was learning less from these books. My primary goal is to learn English, but I felt like I was putting more attention on the plots instead of English phrases and words. What’s more, I’m going to start my career next month. So, probably I should give myself a time-out and try something new, such as reading The Economist, listening to news or talk shows, and reviewing the summary of recent readings. But I’ll continue writing new blogs, because it’s now my only way for outputting what I’ve learned.","categories":[],"tags":[{"name":"reading","slug":"reading","permalink":"https://proverbs.github.io/tags/reading/"},{"name":"novel","slug":"novel","permalink":"https://proverbs.github.io/tags/novel/"}]},{"title":"[Reading]Percy Jackson and the Olympians: The Sea of Monsters","slug":"Reading-Percy-Jackson-and-the-Olympians-The-Sea-of-Monsters","date":"2020-06-14T04:35:00.000Z","updated":"2021-05-30T16:25:43.056Z","comments":true,"path":"2020/06/13/Reading-Percy-Jackson-and-the-Olympians-The-Sea-of-Monsters/","link":"","permalink":"https://proverbs.github.io/2020/06/13/Reading-Percy-Jackson-and-the-Olympians-The-Sea-of-Monsters/","excerpt":"[Reading]Percy Jackson and the Olympians: The Sea of Monsters HaHa, I think I’m not as old as I thought, since I can still get indulged in a book for children in elementary schools. Or probably I should say the author Rick Riordan wrote so good a story that I as an “old man” can also get fascinated.","text":"[Reading]Percy Jackson and the Olympians: The Sea of Monsters HaHa, I think I’m not as old as I thought, since I can still get indulged in a book for children in elementary schools. Or probably I should say the author Rick Riordan wrote so good a story that I as an “old man” can also get fascinated. Back to this book — The Sea of Monsters, I think it’s interesting than its predecessor — The Lightning Thief. Because I think the overall storytelling of the adventure is much more coherent. Compared to the last time, where I spent almost a week to read the first volume, it only took me two days for reading this time, which on the other side should also proved that this volume is the better one. Or maybe I was just reading faster than before? Most surprisingly, there is a big plot twist at the ending, which makes me can wait to start the next volume. Although there are some irrational plots, just as the first volume. For example, I can’t understand why the campers would change their attitude to us(Percy and his friends), since all of them just thought it was Clarisse who brought the Fleece back to the camp. Is it because I’m just too old to catch up with what young people are thinking? Then, I would like to talk about the plot twist. The author foreshadowed so much for this plot twist that I should have noticed it earlier. But until the author is writing “It was not Annabeth who was lying on the ground”, I just realized the big surprise. The author provided an obvious hint: Percy healed the badly injured Annabeth with the help of the Fleece on the island of Polyphemus, when I should have thought about the possibility that Thalia would be revived if the Fleece can be finally brought back to the camp. I couldn’t help exclaiming how calculating Kronos was when I was reading. He changed the prophecy by poisoning the pine tree and lured Percy and his friends to get back the Fleece to resurrect Thalia when all the reading are probably thinking our protagonist Percy should be “the person in the prophecy”, a person who only lived in people’s memory got revived and became the “person”. Hereby, I just want to where the plot will go. I think Percy should also be “the person in the prophecy”. After all, it cannot be more reasonable that the protagonist is the “person”. On the other hand, Thalia will hesitate between good(Olympians) and evil(Kronos). And she might even get bewitched by the evil for a time. But at the end she would come to realize her fault and sacrifice herself to help Percy. At last, I want to continue the talk about the combination of novels and mythologies. Actually, I know little about the mythical characters in this volume except Siren. As for Charybdis, Scylla, Circe, Polyphemus etc, I even haven’t heard about them. But it’s a quite interesting experience learning their stories, which is one of the reasons which encourage me to continue reading this series.","categories":[],"tags":[{"name":"reading","slug":"reading","permalink":"https://proverbs.github.io/tags/reading/"},{"name":"novel","slug":"novel","permalink":"https://proverbs.github.io/tags/novel/"}]},{"title":"[Reading]A Song of Ice and Fire: Game of Thrones(quited)","slug":"Reading-A-Song-of-Ice-and-Fire-Game-of-Thrones-quited","date":"2020-06-10T20:38:45.000Z","updated":"2021-05-30T16:25:43.056Z","comments":true,"path":"2020/06/10/Reading-A-Song-of-Ice-and-Fire-Game-of-Thrones-quited/","link":"","permalink":"https://proverbs.github.io/2020/06/10/Reading-A-Song-of-Ice-and-Fire-Game-of-Thrones-quited/","excerpt":"[Reading]A Song of Ice and Fire: Game of Thrones(quited) Recently I was reading the first volume of A Song of Ice and Fire — Game of Thrones. Till now, I have read a quarter of the whole book. However, today I decided to quit this book because it doesn’t fit into my purpose of reading, at least for recently. Because my primal reason for reading English novels is to improve my English, which can hardly be accomplished by reading this novel. This novel is telling a story of medieval fantasy epic, so the author are using a lot of “ancient” words which will merely be used in our real life. Although I can still understand what the author is telling with the help of my dictionary and Google, I don’t want to spend much time but gain little.","text":"[Reading]A Song of Ice and Fire: Game of Thrones(quited) Recently I was reading the first volume of A Song of Ice and Fire — Game of Thrones. Till now, I have read a quarter of the whole book. However, today I decided to quit this book because it doesn’t fit into my purpose of reading, at least for recently. Because my primal reason for reading English novels is to improve my English, which can hardly be accomplished by reading this novel. This novel is telling a story of medieval fantasy epic, so the author are using a lot of “ancient” words which will merely be used in our real life. Although I can still understand what the author is telling with the help of my dictionary and Google, I don’t want to spend much time but gain little. I didn’t mean this novel is not interesting. Rather, I would say it’s quite so good a novel that it almost makes me obsessed even through I’ve watched the whole TV series and I still have some vague memory about the plot. I feel impressed by the grand story background when I was reading, taking a look at the world map of the novel series at times. But now I don’t have much time for entertainment, because there’s only one month left before I my onboarding. The most important thing for me now is to improve my communication skills in English. However, I wish I could come back to this novel as soon as I feel comfortable talking to native speakers.","categories":[],"tags":[{"name":"reading","slug":"reading","permalink":"https://proverbs.github.io/tags/reading/"},{"name":"novel","slug":"novel","permalink":"https://proverbs.github.io/tags/novel/"}]},{"title":"[Reading]Murder on the Orient Express","slug":"Reading-Murder-on-the-Orient-Express","date":"2020-06-04T18:58:44.000Z","updated":"2021-05-30T16:25:43.056Z","comments":true,"path":"2020/06/04/Reading-Murder-on-the-Orient-Express/","link":"","permalink":"https://proverbs.github.io/2020/06/04/Reading-Murder-on-the-Orient-Express/","excerpt":"[Reading]Murder on the Orient Express The other day, I felt very lucky to finish my first Agatha Christie’s famous whodunit – Murder on the Orient Express. I had watched the movie, and I had some vague memories about the ending, although I can hardly remember any details of books or movies I watched or read. Thus, the so-called “unexpected ending” didn’t surprise me very much.","text":"[Reading]Murder on the Orient Express The other day, I felt very lucky to finish my first Agatha Christie’s famous whodunit – Murder on the Orient Express. I had watched the movie, and I had some vague memories about the ending, although I can hardly remember any details of books or movies I watched or read. Thus, the so-called “unexpected ending” didn’t surprise me very much. To be honest, I’m not a big fan of whodunits. And the reason why I decided to read this book is to improve my English. However, I like the organization of the book, because I think it should be like some kinds of “traditional whodunit”. Here I used “like” because “Case Closed” the anime and Keigo Higashino’s novels, including Journey Under the Midnight Sun and The Miracles of the Namiya General Store, had had great influence on me. When I was young, I used to watch Case Closed and I always thought whodunit is that the well-known detective walked around the crime scene and asked some queer questions which seems unrelated to the case. But the detective can always find some vital details from the alibi or the scene. And then he/she will show his/her wisdom and reconstruct how the crime is carried out. Therefore, I had some stereotype of whodunits that the core of the work should be the ingenious modus operandi. However, I have to say Keigo Higashino’s novels should be called mystery novels rather than whodunits because the organization and the plot are so amazing that readers will always ignore the clues or foreshadowing the author provides. In my opinion, the core of his novels is the ingenious plot instead of the reasoning. Going back to Agatha Christie’s novels, I think it’s not too hard to read from the perspective of an English learner. Because her words are very plain and the organization follows linear narrative. Although this simple organization doesn’t bring too much fun for reading, it’s undeniable that readers always cannot help continuing reading urgently. I think the key point is that, in Agatha’s work, readers can share the same amount of information as the famous detective. And to lower the difficulty of reading, she will even conclude all the important clues for the readers. Of course, as a detective, he should also do that, because the detective is also a human instead of God(Conan) and he cannot directly see everything beneath the surface. As a reader, I would also like to talk about my thoughts about the reasoning in this book. ATTENTION, SPOILERS AHEAD. I haven’t read any of Agatha’s novels before (although I’ve watched some movies adapted from her novels, such as Death on the Nile), but just for this novel, I don’t feel very satisfied with the reasoning process. Poirot didn’t have any solid evidence. He guessed the real identities of these twelve criminals and they just simply confessed. Probably, I’m just influenced by Case Closed so much that I always think criminals will never confess unless you have critical evidence which can’t be refuted. In general, I don’t recommend it as a book for learning English(mainly American English) because there are a lot of English expressions and many expressions seem not very morden. But as a book for killing time, it’s relatively good because its organization is simple but can always catch your attention.","categories":[],"tags":[{"name":"reading","slug":"reading","permalink":"https://proverbs.github.io/tags/reading/"},{"name":"novel","slug":"novel","permalink":"https://proverbs.github.io/tags/novel/"},{"name":"Agatha Christie","slug":"Agatha-Christie","permalink":"https://proverbs.github.io/tags/Agatha-Christie/"}]},{"title":"[Reading]Percy Jackson and the Olympians: The Lightning Thief","slug":"Reading-Percy-Jackson-and-the-Olympians-The-Lightning-Thief","date":"2020-05-29T17:39:08.000Z","updated":"2021-05-30T16:25:43.056Z","comments":true,"path":"2020/05/29/Reading-Percy-Jackson-and-the-Olympians-The-Lightning-Thief/","link":"","permalink":"https://proverbs.github.io/2020/05/29/Reading-Percy-Jackson-and-the-Olympians-The-Lightning-Thief/","excerpt":"[Reading]Percy Jackson and the Olympians: The Lightning Thief Today, I’m really glad that I’ve finally finished reading the first original English novel — the first novel of Percy Jackson and the Olympians series: The Lightning Thief — although it is of a low reading level (for elementary school students) for native speakers.","text":"[Reading]Percy Jackson and the Olympians: The Lightning Thief Today, I’m really glad that I’ve finally finished reading the first original English novel — the first novel of Percy Jackson and the Olympians series: The Lightning Thief — although it is of a low reading level (for elementary school students) for native speakers. At the very beginning, the book I wanted to read was the first novel of A song of Ice and Fire — A Game of Thrones. I have to admit it’s a little bit harder for me to read this book than The Lightning Thief. But it’s not so difficult that I’m not able to read it. And although I’ve watched the TV series of GoT, I’ve never been worried about spoilers because of my ephemeral memory. However, I have no idea why I didn’t feel motivated to continue reading. So, at last, I decided to read Percy Jackson series as recommended by other English learners from the 1point3acres forum. Now, I don’t regret my choice and even feel thankful that I made that choice. This book made me interested in Greek Mythologies (I even went to watch a documentary of Greek Mythologies) because a lot of characters and plots refers Greek Mythologies as blueprint. For instance, the most powerful Gods are Zeus, Poseidon and Hades and their weapons are Lightning bolt, Trident, Helmet of Darkness, respectively. Thus, if you have some knowledge about Greek Mythologies previously, you will be able to figure out how the story will go on without further reading. However, there is still some difference. For example, Medusa was actually raped by Poseidon in Athena’s palace by force instead of she falling in love with him in this novel. Although Medusa wanted to keep her virginity, after she and Poseidon were caught by Athena, Athena cursed her and turn her beautiful hairs to serpents. As for the plot, there are some flaws. However, since it’s a for child, we should not ask too much of it. At least, it always carried some foreshadowing and never made me feel bored. Back to my original purpose, I just want to learn English and English/Western culture through reading. From this perspective, I indeed learned a lot about grammar and good phrases. However, it might take a lot of time to summarize them all, I will definitely do it because this is the most important phase of learning from reading. I hope I can share my summary when I finish it. It’s not some kinds of professional notes, but it witnesses the learning progress of an English learner who is aspire for improving his English, especially writing and speaking. And I hope it will be at least a little bit helpful to some of you guys!","categories":[],"tags":[{"name":"reading","slug":"reading","permalink":"https://proverbs.github.io/tags/reading/"},{"name":"novel","slug":"novel","permalink":"https://proverbs.github.io/tags/novel/"}]},{"title":"[GAME]Life is Strange Review","slug":"GAME-Life-is-Strange-Review","date":"2020-03-14T19:59:42.000Z","updated":"2021-05-30T16:25:43.046Z","comments":true,"path":"2020/03/14/GAME-Life-is-Strange-Review/","link":"","permalink":"https://proverbs.github.io/2020/03/14/GAME-Life-is-Strange-Review/","excerpt":"[GAME]Life is Strange Review It’s been a long time since I played the game. And I was actually not a big fan of this kind of game, because I thought it was like a girl game and the story always developed slowly. However, I felt so exhausted after 6-week “homework-sleep-homework” life that I would like to play some casual games instead of those requiring too much focus, such as Dark Soul III. And Coronavirus and spring break provided me with plenty of time for playing this kind of “slow” game.","text":"[GAME]Life is Strange Review It’s been a long time since I played the game. And I was actually not a big fan of this kind of game, because I thought it was like a girl game and the story always developed slowly. However, I felt so exhausted after 6-week “homework-sleep-homework” life that I would like to play some casual games instead of those requiring too much focus, such as Dark Soul III. And Coronavirus and spring break provided me with plenty of time for playing this kind of “slow” game. I have to admit that Life is Strange is one of the greatest story-telling game I’ve ever played. As you might know, I don’t care too much of the video and user experience. In stead, I’m always serious about the audio and scenarios, because I think these two factors are the most important things to make players forget they are playing games and feel like they are exactly the role thay are playing. This game doesn’t require a high-performace graphic card, but you can still enjoy the great art style which is warm and sweet. Combined with the background music, espicially when Max is leaning on the window of the bus, you will never want this story to reach its end. Spoiler warning!! I think Life is Strange is telling us a story of making choice. Although Max is able to rewind the time and she is kind-hearted and always trying to help people, she cannot make everything right. She must make her choice between a good but paralyzed Chloe with a bankrupted family and a punk but pitiful Chloe with a broken family. Also, she travels from one reality to another again and again and almost gets lost in an infinite circle to save Chloe. But she still have to choose one from the people in Arcadia Bay and Chloe. Making choice is never easy, even with the ability of rewinding the time. When you are playing, you might often feel regretful for your previous choices. However, even you can replay the game and choose what you want now, you will probably still be regretful later. At the beginning, the game gives you a sense that you can change everything and make things go on as you want: You can make fun of Victoria easily; You can get Frank’s RV key by rewinding as many times as you want and trying all options; You can save Chloe’s from crashing by the train… However, when you want to save Kate, you realize that your power is not unlimited(Although I know you can save Kate if you can select the right options before she jumps.). So, after that, you always remind Chloe that you would not abuse your power. However, she still believe her power can do something. But another thing destorys you: You cannot make both William(Chloe’s father, and he was like her father) and Chloe(her best friend) alive. You finally realize everything you changed will pay. However, after you are saved by David(Chloe’s stepfather), you still try to save Chloe. But this time, time travel is not that easy: You get trapped in the chaos and the infinite circle. Although, you finally get out of it, find find Arcadia Bay is going to be destroyed by the tornado and you must make your final choice: save people or save your best friend. However, this time, Chloe helps you to make the choice: She chooses to sacrifice herself and saves Arcadia Bay, wich makes me heart-broken. This reminds me of Steins;Gate, one of my favoriate animes and video games, where Hououin is trying to save Mayuri but witnesses her death again and again. But as Chloe says, the moments and friendship between them are real, that’s enough. No matter what choices we made, we should treasure everything in our life just because we don’t have super power as Max and we cannot rewind the time and make up for regerets. And I think that’s what the story is trying to tell us.","categories":[],"tags":[{"name":"life","slug":"life","permalink":"https://proverbs.github.io/tags/life/"},{"name":"game","slug":"game","permalink":"https://proverbs.github.io/tags/game/"}]},{"title":"[FFXIV]FINAL FANTASY XIV Review","slug":"FFXIV-FINAL-FANTASY-XIV-Review","date":"2020-02-03T01:13:31.000Z","updated":"2021-05-30T16:25:43.046Z","comments":true,"path":"2020/02/02/FFXIV-FINAL-FANTASY-XIV-Review/","link":"","permalink":"https://proverbs.github.io/2020/02/02/FFXIV-FINAL-FANTASY-XIV-Review/","excerpt":"[FFXIV]FINAL FANTASY XIV Review I’ve been dreaming of playing in a world of MMORPG game for long years. However, MMORPG games are always famous(notorious) for costing a lot of time and money. Thus, I had never played a real MMORPG until last semester, when I got plenty of spare time to do things other than study. But I felt much stronger course pressure this semseter, so I decided to quit this game. It doesn’t mean that the game is boring. On the contrary, it is one of the greatest games and the greatest online game I’ve ever played. Although I quit this game, I’m not leaving this game. And that’s why I would like to spend the whole evening to write a review of this game and talk about the FFXIV in my heart.","text":"[FFXIV]FINAL FANTASY XIV Review I’ve been dreaming of playing in a world of MMORPG game for long years. However, MMORPG games are always famous(notorious) for costing a lot of time and money. Thus, I had never played a real MMORPG until last semester, when I got plenty of spare time to do things other than study. But I felt much stronger course pressure this semseter, so I decided to quit this game. It doesn’t mean that the game is boring. On the contrary, it is one of the greatest games and the greatest online game I’ve ever played. Although I quit this game, I’m not leaving this game. And that’s why I would like to spend the whole evening to write a review of this game and talk about the FFXIV in my heart. People always say it’s the worst age of MMORPG for now. Thus, I feel very lucky to get the opportunity to play FFXIV, which is called the No.1 MMORPG all over the world(because of the major Patch 5.0 ShadowBringers) in the worst age. I’m not a professional player, so this will not be a comprehensive game review. Instead, I will only talk about the most impressive parts in this game. I went through a hard time during FFXIV 2.0 A Realm Reborn. Scions of the Seventh Dawn, where there is no Aetheryte, kept calling me to meet with them and help them with side quests. Most of the side quests were so boring that I even wanted to quit. However, I am so glad that I didn’t do that at that time, because the ending of this patch is wonderful. What impressed me most is Nanamo crying in Raubahn’s arms because of her inability to save the refugees. Although, Scions members’ word “You go first, I will back up” is quite rediculous, 2.0 is definitely a success, especially after failure of the disastrous version 1.0. Patch 3.0 Heavensward is the my favoriate part among all patches in FFIXV because of the the Dragonsong and the BGM in Ishgard. They are so magnificient that my word is not able to describe them. So, I’ll leave the videos for you to experience on you own. Don’t thank me. I love the part that Alphinaud, Estinien and Ysayle spoke out their hearts at the campfire, looking back at the growth of Alphinaud, tsundere Estinien, and the collapse and rebuild of the confidence of Ysayle. With the story approaching the climax, we were getting to know the truth of the Dragonsong War after experiencing some unexpected turnings in the story. (If you want to ask me why I was not talking with them, my answer is “as known to all, Warrior of Light is dumb”.) As for the graphics, all sceneries are beautiful, especially The Sea of Clouds. As for Patch 4.0 Stormblood, I felt that Yoshida wanted to show the growth of Lyse, who at first disguised herself as Yda because of her confusion and hesitation, but then freed her homeland from the ruling and atrocity, and finally became a good leader of the Resistance. If that is the case, I think this patch is not a success because it seems so easy for a girl to grow up. Each time she had a setback, I just said some seemingly useless words and she would talk about her past and then get inspired. Thus, I think it’s a little bit unreasonable. However, the oriental BGM and architecture in Kugane intrigued me. And because it was the first place I went in patch 4.0, it was quite a surprise to me(a big fan of Japanese culture). As for the most impressive part of this patch, I think it should be the change of people in Doma, who were living under the persecution from Garlean Empire. They were so affraid of resist against the empire that they even refused to talk and help the liberators. The empire was so powerful to them all that resistance would defintely incur the death(They didn’t know we Warriors of Light were so strong). So, they decided to forsake their dignity and live on. As a Chinese growing under the influence of patriotism, I wanted to call them “traitors” at the very beginning. However, I began to understand the reason of their decision. I tried to ask myself, if I were one of these people, what would I do? Probably, I would do the same. How ironic! Patch 5.0 Shadowbringers is the latest major patch, which blinded me when I entered Lakeland because the light changes too much from dark to pink/white. But after my eyes got adapted to the light, I was attracted by the scenery. After I defeated the first Lightwarden, the First world also witnessed the infinite starry sky for the first time since one hundred years ago. People in Crystarium came out of their rooms and looked up at the same sky. No one were celebrating and even no one were talking. Everyone was just enjoying the peace. That made me feel a sense of achievement and I began to level up as fast as I could in order to defeat more Lightwardens for them. Facing the revenge on people in Crystarium taken by Eulmore, the shadow of Ardbert tried to axed the Sin Eaters. However, it turned out that he was dead and not able to touch anything in this world. All of his friend were dead and went back to the Universe, and he was the only one left behind in this world and beared all misunderstanding from people. Although he had a heart of saving the world, he could do nothing but watch the innocent people getting killed by Sin Eaters(and talk to a dumb person), which was the most brutal thing for a Warrior of Darkness. Personally speaking, this game is definitely a masterpiece. You can witness the growth of main characters under the magnificent settings, feel a sense of achivement and get moved by the characters and stories. Players in the gaming world are all very friendly. Every time I made some mistake, they would teach me how to play patiently instead of blaming me, which really changed my stereotype to the players in online games. Although some scenarios seems a little bit stupid, the playing experience is great. You will feel you are a real Warrior of Light/Darkness and you are saving the world. Thus, I’ll give 9/10 to this game. The reason why I deduct 1 point is that the engine is so outdated for current PCs that it cannot bring me similar image quality as 3A games. (Although I know it is impossible for a 10-year-old game to change the engine, especially when it’s a huge MMORPG). At last, I would like to conlcude FFXIV in a word. Game is not a game anymore since the emergence of MMORPG. Instead, it becomes a WORLD. For Eorzea!","categories":[],"tags":[{"name":"life","slug":"life","permalink":"https://proverbs.github.io/tags/life/"},{"name":"game","slug":"game","permalink":"https://proverbs.github.io/tags/game/"}]},{"title":"First Time Snowboarding","slug":"First-Time-Snowboarding","date":"2020-01-21T04:19:57.000Z","updated":"2021-05-30T16:25:43.046Z","comments":true,"path":"2020/01/20/First-Time-Snowboarding/","link":"","permalink":"https://proverbs.github.io/2020/01/20/First-Time-Snowboarding/","excerpt":"First Time Snowboarding That was so amazing!!! This time, we went to Dodge Ridge, which is the closest wintersports area to the Bay Area. And because it was my first going snowboarding, I registered a L1(beginner) lesson. The funny thing is the lesson includeing the rental and day pass is cheaper than day pass plus rental. I don’t know why…","text":"First Time Snowboarding That was so amazing!!! This time, we went to Dodge Ridge, which is the closest wintersports area to the Bay Area. And because it was my first going snowboarding, I registered a L1(beginner) lesson. The funny thing is the lesson includeing the rental and day pass is cheaper than day pass plus rental. I don’t know why… Whatever, I went to the lesson. And it seemed a lot of people were late, so only 8 people attended. The instructor was really great and always pointed out what was wrong during my practice and explained the correct way. I think I was the best student in that class, because every time the instructor taught some new stuff, I was always the first student finish it successfully, mostly in the first try. It took about 1.5h for the lesson and I learned slide with one foot unbuckled, toe slide, heel slide, toe turn and heel turn, which are all quite useful for real runs. After the lesson, I went to the green run, which is the easiest run. The chairlift run very slowly. But thanks to the slow speed, I got enough time to have a rest. NO! That’s not TRUE! Taking the chairlift is really exhausting, because you need to hold the heavy snowboard all the time using your foot or hand. And it’s always a long ride. At the end, you need to ski with only one foot buckled to go down through a very steep slope from the unloading spot, which is always the most difficult part of the entire run. However, as a genius, I made it in the second try. When you leave the unloading spot, you can buckle the second foot and begin your downhill ride. In the first ride, I finished with entire green run without break. And it took about 20s for me to ride back to the chairlift. After the successful start, I decided to try a toe turn under a high speed. However, it truned out that I was too confident in myself. I fell over and lay in the snow for a while and then finally regained consciousness. That was really dangerous. So, PRACTICE IN SLOW SPEED brefore acting in a high speed! At the end, THANK YOU my friends for inviting me to go snowboarding/skiing. Hope all you readers have fun going snowboarding/skiing and be careful! Safety should always come first!","categories":[],"tags":[{"name":"life","slug":"life","permalink":"https://proverbs.github.io/tags/life/"}]},{"title":"2020 New Start: Learning English","slug":"2020-New-Start-Learning-English","date":"2020-01-16T06:28:50.000Z","updated":"2021-05-30T16:25:43.046Z","comments":true,"path":"2020/01/15/2020-New-Start-Learning-English/","link":"","permalink":"https://proverbs.github.io/2020/01/15/2020-New-Start-Learning-English/","excerpt":"2020 New Start: Learning English Happy new year and happy new semester! This will be my last year as a student. I really treasure the time as a student, especially a CMU student, because there are still a lot of courses I love but not get the opportunity to take. However, the tuition here is also extremely thrilling and I wish I can start to work as early as possible to live on my own.","text":"2020 New Start: Learning English Happy new year and happy new semester! This will be my last year as a student. I really treasure the time as a student, especially a CMU student, because there are still a lot of courses I love but not get the opportunity to take. However, the tuition here is also extremely thrilling and I wish I can start to work as early as possible to live on my own. In five months, I will begin to work as a Software Engineer in a start-up of autonomous driving. I am quite nervous not because of my technical skills but my English and communication. Thus, I decide to spend some time learning English by writing and speaking(output) inspired by the following YouTube video. So, I’m going to write about my life, my trip and my readings in my blogs. As for speaking, em… I don’t know. Because I’m not good at talking even using Chinese, which is my first language. But I’m trying, by calling customer services, talking with people of my leasing office, etc. Also, I’m going to review what I learned in the past two years at CMU and try to write some summary. I always complained that I had quite a bad memory. However, I just realize that it’s because I don’t output what I learned that I always forget the knowledge so soon. Hope to see my next blog soon~","categories":[],"tags":[{"name":"life","slug":"life","permalink":"https://proverbs.github.io/tags/life/"},{"name":"English","slug":"English","permalink":"https://proverbs.github.io/tags/English/"}]},{"title":"[Leetcode]collection-2019-07-08","slug":"Leetcode-collection-2019-07-08","date":"2019-07-09T06:38:15.000Z","updated":"2021-05-30T16:25:43.056Z","comments":true,"path":"2019/07/08/Leetcode-collection-2019-07-08/","link":"","permalink":"https://proverbs.github.io/2019/07/08/Leetcode-collection-2019-07-08/","excerpt":"My code can be viewed in my github: Proverbs Github. The following difficulty is defined by myself. minimum-cost-for-tickets(medium) The straightforward way is dp day by day. dp[i]: the minimum cost for tickets before day i. The state transfer is: 1234if (!mp[i]) dp[i] = dp[i - 1];dp[i] = min(dp[i], dp[i - 1] + costs[0]);if (i &gt;= 7) dp[i] = min(dp[i], dp[i - 7] + costs[1]);if (i &gt;= 30) dp[i] = min(dp[i], dp[i - 30] + costs[2]); However, here is a trick: the result could not be dp[365]. Another solution is much brighter and faster: dp[i] indicates the minimum cost for tickets from day[i] to the last day. The state transfer is: 12345678910int n1 = n - 1, n7 = n - 1, n30 = n - 1;for (int i = n - 1; i &gt;= 0; i --) &#123; while (days[n1] &gt;= days[i] + 1) n1 --; while (days[n7] &gt;= days[i] + 7) n7 --; while (days[n30] &gt;= days[i] + 30) n30 --; dp[i] = min(dp[i], dp[n1 + 1] + costs[0]); dp[i] = min(dp[i], dp[n7 + 1] + costs[1]); dp[i] = min(dp[i], dp[n30 + 1] + costs[2]);&#125; Time complexity: O(400), or O(n). Space complexity: O(400), or O(n).","text":"My code can be viewed in my github: Proverbs Github. The following difficulty is defined by myself. minimum-cost-for-tickets(medium) The straightforward way is dp day by day. dp[i]: the minimum cost for tickets before day i. The state transfer is: 1234if (!mp[i]) dp[i] = dp[i - 1];dp[i] = min(dp[i], dp[i - 1] + costs[0]);if (i &gt;= 7) dp[i] = min(dp[i], dp[i - 7] + costs[1]);if (i &gt;= 30) dp[i] = min(dp[i], dp[i - 30] + costs[2]); However, here is a trick: the result could not be dp[365]. Another solution is much brighter and faster: dp[i] indicates the minimum cost for tickets from day[i] to the last day. The state transfer is: 12345678910int n1 = n - 1, n7 = n - 1, n30 = n - 1;for (int i = n - 1; i &gt;= 0; i --) &#123; while (days[n1] &gt;= days[i] + 1) n1 --; while (days[n7] &gt;= days[i] + 7) n7 --; while (days[n30] &gt;= days[i] + 30) n30 --; dp[i] = min(dp[i], dp[n1 + 1] + costs[0]); dp[i] = min(dp[i], dp[n7 + 1] + costs[1]); dp[i] = min(dp[i], dp[n30 + 1] + costs[2]);&#125; Time complexity: O(400), or O(n). Space complexity: O(400), or O(n). prison-cells-after-n-days(easy) The first element and the last element will become 0 and will never change after the first round. So, the total of possible states is 2^6 + 1. Thus, we can brute force the cycle and its length. Time complexity: O(2^6). Space complexity: O(2^6). squares-of-a-sorted-array(easy) The largest square is either the smallest negative or the largest positive. So, we can use two pointers to scan the array from head and tail respectively. Time complexity: O(n). Space complexity: O(n). verifying-an-alien-dictionary(easy) String comparison. Time complexity: O(n * len). Space complexity: O(1). fibonacci-number(medium) Please assume n can be extremely large and the values will never overflow or the values will module a specific number. Then the solution will be matrix fast power. 123&#123;&#123;0, 1, 0&#125;, &#123;&#123;0&#125;, F(0) &#123;&#123;1&#125;, F(1)&#123;0, 0, 1&#125;, * &#123;1&#125;, F(1) = &#123;1&#125;, F(2)&#123;0, 1, 1&#125;&#125; &#123;1&#125;&#125; F(2) &#123;2&#125;&#125; F(3) Time complexity: O(logn). Space complexity: O(1). basic-calculator-iii(hard) This problem can be quite annoying. Just note that: The curly brackets should have the lowest weights. This kind of expression: -1-(-1). To handle this, I use a flag to indicate that a operator can follow a bracket. Time complexity: O(n). Space complexity: O(n).","categories":[],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://proverbs.github.io/tags/algorithm/"},{"name":"LeetCode","slug":"LeetCode","permalink":"https://proverbs.github.io/tags/LeetCode/"}]},{"title":"[Leetcode]collection-2019-07-06","slug":"Leetcode-collection-2019-07-06","date":"2019-07-07T05:48:50.000Z","updated":"2021-05-30T16:25:43.056Z","comments":true,"path":"2019/07/06/Leetcode-collection-2019-07-06/","link":"","permalink":"https://proverbs.github.io/2019/07/06/Leetcode-collection-2019-07-06/","excerpt":"My code can be viewed in my github: Proverbs Github. The following difficulty is defined by myself. subarray-sums-divisible-by-k(medium) I have to admit that it’s a good problem and it seems pretty hard at first glance. However, if you know: a little about congruence group, the solution will be very straightforward; sum of a subarray can be represented using two the difference between two prefix sums. Time complexity: O(n). Space complexity: O(n). interval-list-intersections(easy) It’s a quite common interval merge problem. The solution is: sort if it’s out of order; use a pointer to indicate the next candidate which can contribute to the results. THere are two lists, so we’ll use two pointers for them respectively. Time complexity: O(n). Space complexity: O(n).","text":"My code can be viewed in my github: Proverbs Github. The following difficulty is defined by myself. subarray-sums-divisible-by-k(medium) I have to admit that it’s a good problem and it seems pretty hard at first glance. However, if you know: a little about congruence group, the solution will be very straightforward; sum of a subarray can be represented using two the difference between two prefix sums. Time complexity: O(n). Space complexity: O(n). interval-list-intersections(easy) It’s a quite common interval merge problem. The solution is: sort if it’s out of order; use a pointer to indicate the next candidate which can contribute to the results. THere are two lists, so we’ll use two pointers for them respectively. Time complexity: O(n). Space complexity: O(n). basic-calculator-ii(medium) Classic calculator problem: two stacks. One for operands(numbers), and one for operators. Use the priority(or weight) of the operators to decide whether it’s time to calculate. This problem is simplified because there’s no brackets. Time complexity: O(n). Space complexity: O(n). time-based-key-value-store(easy) unordered_map&lt;string, set&lt;pair&lt;int, string&gt;&gt;&gt; key_nts_val; Another trick is to use set.lower_bound(x) to search the largest number smaller than x. Hint: use negatives. Time complexity: O(logn) for each call. Space complexity: O(n). reorder-log-files(medium) Customize the compare function. Here’s a brief summary of how to customize the compare function. 1234static bool cmp(const string&amp; a, const string&amp; b) &#123; // b is the former number, a is the later number // false means not to swap&#125; Note we should use stable_sort because sort will keep the original order of the array. Time complexity: O(nlogn). Space complexity: O(nlogn). odd-even-jump(medium) You should notice that jump is always from left to right, which means there’s no aftereffects. Thus, the first idea we are supposed to come up with is DP. jp[0][i]: the index you are at when you finish an even jump at i. jp[1][i]: the index you are at when you finish an odd jump at i. dp[0][i]: the number of good starting indexes if your next jump is an even jump at i. dp[1][i]: the number of good starting indexes if your next jump is an odd jump at i. State transfer: 12if (~jp[0][i]) dp[0][jp[0][i]] += dp[1][i];if (~jp[1][i]) dp[1][jp[1][i]] += dp[0][i]; A trick is how to use lower_bound to find the largest value less than x, which is the same as time-based-key-value-store(easy). Time complexity: O(n). Space complexity: O(n).","categories":[],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://proverbs.github.io/tags/algorithm/"},{"name":"LeetCode","slug":"LeetCode","permalink":"https://proverbs.github.io/tags/LeetCode/"}]},{"title":"[Leetcode]collection-2019-07-04","slug":"Leetcode-collection-2019-07-04","date":"2019-07-05T01:11:01.000Z","updated":"2021-05-30T16:25:43.056Z","comments":true,"path":"2019/07/04/Leetcode-collection-2019-07-04/","link":"","permalink":"https://proverbs.github.io/2019/07/04/Leetcode-collection-2019-07-04/","excerpt":"My code can be viewed in my github: Proverbs Github. The following difficulty is defined by myself. robot-return-to-origin(easy) Use dx++/-- and dy++/-- to indicate the move of the robot. Time complexity: O(n). Space complexity: O(1). reverse-vowels-of-a-string(easy) Scan the string from left to right and save all vowels in order in an array. Then, replace the vowels from right to left according to the array. Another way is to use two pointers to walk the string from left and right respectively and swap the vowels. Time complexity: O(n). Space complexity: O(n).","text":"My code can be viewed in my github: Proverbs Github. The following difficulty is defined by myself. robot-return-to-origin(easy) Use dx++/-- and dy++/-- to indicate the move of the robot. Time complexity: O(n). Space complexity: O(1). reverse-vowels-of-a-string(easy) Scan the string from left to right and save all vowels in order in an array. Then, replace the vowels from right to left according to the array. Another way is to use two pointers to walk the string from left and right respectively and swap the vowels. Time complexity: O(n). Space complexity: O(n). maximum-xor-of-two-numbers-in-an-array(medium) This problem is really classic and I love it. It’s a problem of “selecting the optimal pair” and a problem of &quot; bitwise XOR&quot;. For the first problem, the basic idea is to enumerate each one, and compute the best with any other ones. Trie’s “find” function is exactly that. Time complexity: O(32n). Space complexity: O(n). power-of-three(easy) The easiest O(1) method is to calculate the maximum power of three within MAX_INT manually, and then all the other powers of three are all its factors. Time complexity: O(1). Space complexity: O(1). k-closest-points-to-origin(medium) The kind of problem is quite common(using Max Heap) now and it shouldn’t have been a “medium” problem. But the only reason why I marked it as “medium” is I can practice how to use STL Priority Queue with Comparator class. Time complexity: O(nlogK). Space complexity: O(K). partition-labels(easy) My straightforward idea is Greedy: to keep track of the occurrence of lowercase letters of both current string and the rest of the string. When there’s no letter occurring in both strings, I will make current string a new partition. It’s a solution with the time complexity of O(26n). However, there’s another solution which is much better in the Solution Page using next pointers. Time complexity: O(26n), the better solution is O(n). Space complexity: O(n). min-cost-climbing-stairs(easy) One of the easiest DP problems in Leetcode. Two ways of state transfer: one step of two steps. Time complexity: O(n). Space complexity: O(n). gray-code(easy) This is quite easy if you do know how to construct Gray Code: to unfold from 0 1 iteratively. For example: 1-bit Gray code: 1201 2-bit Gray code: 12345(0) 0(0) 1------(1) 1(1) 0 3-bit Gray code: 123456789(0) 0 0(0) 0 1(0) 1 1(0) 1 0-------(1) 1 0(1) 1 1(1) 0 1(1) 0 0 Time complexity: O(n). Space complexity: O(2^n). pascals-triangle-ii(easy) Use circular array to save the space, if you are calculating row by row. A smarter way is to calculate column by column. Time complexity: O(n^2). Space complexity: O(n). valid-number(hard) It’s not a real hard problem, it’s just nauseous: there are so many corner cases that you couldn’t cover they at the first shot or first several shots. My idea is to split in into 3 parts: integer, decimal, and exponential. Time complexity: O(n). Space complexity: O(n). paint-house(easy) The only the constraint is adjacent houses can’t be painted to the same color which is also a very common feature(no aftereffect) of DP. State: dp[i][j]: lowest cost for painting first i houses and the ith house’s color is j. State transfer: dp[i][j] = min(dp[i - 1][k] + cost[i][j]), where j != k. Time complexity: O(3^2*n). Space complexity: O(3n). binary-tree-upside-down(easy) Honestly, I didn’t understand the problem statement until I found another description in Discussion Page. We just need to rotate the original left child to the root, original root to the right child, original right child to left child. And do it recursively. Note that only binary trees whose right child is either leaf node or NULL can do this. Time complexity: O(n). Space complexity: O(n). second-minimum-node-in-a-binary-tree(easy) There are only two kinds of cases: left child is the same as right child: return the smaller value of the “second-minimum-node” the left subtree and the right subtree. not the same: return the smaller value of the “second-minimum-node” the left subtree and the value of the root of the right subtree if the right child is larger, and vice versa. Time complexity: O(n). Space complexity: O(n). can-i-win(hard) For this problem, you need to know what is SG function. And then you will know for a given state, a person can either force a win or eventually reach a unavoidable lose. If sg(state) is 1 if there exists a move which can reach a state1 whose sg value is -1. If sg(state) is -1 if all states a move can reach have a value of 1. Time complexity: O(2^#nums*tot). Space complexity: O(2^#nums). find-largest-value-in-each-tree-row(easy) DFS with passing the depth at the same time, or BFS. In practical, BFS is faster but DFS uses less memory. TIme complexity: O(n). Space complexity: O(n). sum-of-square-numbers(easy) Same as two 2-sum using 2 pointers. Time complexity: O(sqrt(n)). Space complexity: O(sqrt(n)).","categories":[],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://proverbs.github.io/tags/algorithm/"},{"name":"LeetCode","slug":"LeetCode","permalink":"https://proverbs.github.io/tags/LeetCode/"}]},{"title":"[Leetcode]collection-2019-02-02","slug":"Leetcode-collection-2019-02-02","date":"2019-02-03T03:22:08.000Z","updated":"2021-05-30T16:25:43.046Z","comments":true,"path":"2019/02/02/Leetcode-collection-2019-02-02/","link":"","permalink":"https://proverbs.github.io/2019/02/02/Leetcode-collection-2019-02-02/","excerpt":"My code can be viewed in my github: Proverbs Github. The following difficulty is defined by myself. find-leaves-of-binary-tree(easy) Compute the maximum distance to the leaves using Bottom-Up DFS. Time complexity: O(n). Space complexity: O(n). friends-of-appropriate-ages(easy) People with the same age have no difference to each other. So, we can just save how many people are of this age. Then, use the constraints to find the available age range. Time complexity: O(n). Space complexity: O(n). graph-valid-tree(easy) Use DSU to check whether a graph is a tree. Time complexity: O(n). Space complexity: O(n).","text":"My code can be viewed in my github: Proverbs Github. The following difficulty is defined by myself. find-leaves-of-binary-tree(easy) Compute the maximum distance to the leaves using Bottom-Up DFS. Time complexity: O(n). Space complexity: O(n). friends-of-appropriate-ages(easy) People with the same age have no difference to each other. So, we can just save how many people are of this age. Then, use the constraints to find the available age range. Time complexity: O(n). Space complexity: O(n). graph-valid-tree(easy) Use DSU to check whether a graph is a tree. Time complexity: O(n). Space complexity: O(n). insert-into-a-binary-search-tree(easy) The trick is to pass a reference to the pointer. 1void insert(TreeNode*&amp; x, int val); Time complexity: O(logn). Space complexity: O(1) for each insert. lexicographical-numbers(easy) It is quite easy to solve it using recursion which will enumerate the prefixes of the numbers less than the given number. Time complexity: O(n). Space complexity: O(n). minimum-height-trees(medium) The same as the problem of computing the diameter of a tree. That is to find the first longest downward paths and the longest upward path in two DFS, respectively. Another way is to use BFS to shrink the tree from its leaves which have only one edge connected to itself. Time complexity: O(n). Space complexity: O(n). my-calendar-i(easy) An important difference from segment overlap is there will never comes an overlap during the runtime. Thus, we can use only start time to determine the order of intervals. The solution is to use a BST(map in cpp) to maintain existing intervals. Time complexity: O(logn) for each book. Space complexity: O(nlogn) in total. palindrome-partitioning-ii(hard) I have two approach, one is quite easy to implement, the other is more complicated because of RK hash. However, both approaches are DP algorithm. dp[i] = min(dp[i], dp[j - 1] + 1), if s[j:i] is a palindrome, where dp[i] refers to the minimum parts of palindromes. Then, the only problem is how to check whether s[i:j] is a palindrome. enumerate the middle element(s), and then mark all is_palindrome[i][j] to true. Use RK hash to check s[i:j] in O(1) time. Time complexity: O(n^2). Space complexity: O(n^2) for the first method, O(n) for the second method. redundant-connection(easy) Use DSU to check whether a graph is a tree. Time complexity: O(n). Space complexity: O(n). rotate-string(medium) It is quite typical problem. The insight is any rotation of A is a substring of (A+A). Then, we can solve the problem using KMP. Here, I would like to show me KMP code: 1234567891011121314151617int kmp(string&amp; a, string&amp; b) &#123; int len = 0; int n = b.length(); vector&lt;int&gt; p(n, 0); for (int i = 1; i &lt; n; i ++) &#123; while (len &amp;&amp; b[len] != b[i]) len = p[len - 1]; if (b[len] == b[i]) len ++; p[i] = len; &#125; len = 0; for (int i = 0; i &lt; a.length(); i ++) &#123; while (len &amp;&amp; b[len] != a[i]) len = p[len - 1]; if (b[len] == a[i]) len ++; if (len == n) return i - len + 1; &#125; return -1;&#125;","categories":[],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://proverbs.github.io/tags/algorithm/"},{"name":"LeetCode","slug":"LeetCode","permalink":"https://proverbs.github.io/tags/LeetCode/"}]},{"title":"[Leetcode]collection-2019-01-30","slug":"Leetcode-collection-2019-01-30","date":"2019-01-30T18:39:30.000Z","updated":"2021-05-30T16:25:43.046Z","comments":true,"path":"2019/01/30/Leetcode-collection-2019-01-30/","link":"","permalink":"https://proverbs.github.io/2019/01/30/Leetcode-collection-2019-01-30/","excerpt":"My code can be viewed in my github: Proverbs Github. The following difficulty is defined by myself. 1-bit-and-2-bit-characters(easy) Check from left to right. Time complexity: O(n). Space complexity: O(1). construct-binary-tree-from-inorder-and-postorder-traversal(easy) The same as construct BST from inorder and preorder traversal. Time complexity: O(n^2) in the worst case. Space complexity: O(n). construct-quad-tree(easy) Just be careful to coordinates. Time complexity: O(n^2). Space complexity: O(n^2).","text":"My code can be viewed in my github: Proverbs Github. The following difficulty is defined by myself. 1-bit-and-2-bit-characters(easy) Check from left to right. Time complexity: O(n). Space complexity: O(1). construct-binary-tree-from-inorder-and-postorder-traversal(easy) The same as construct BST from inorder and preorder traversal. Time complexity: O(n^2) in the worst case. Space complexity: O(n). construct-quad-tree(easy) Just be careful to coordinates. Time complexity: O(n^2). Space complexity: O(n^2). find-and-replace-pattern(easy) Pattern matching need two mappings. One from pattern to string, another from string to pattern. Time complexity: O(n * length). Space complexity: O(#char). length-of-longest-fibonacci-subsequence(medium) DP. dp[i][j]: longest subsequence given the last two elements which is A[j] and A[i]. The state transition is O(1) because the state can only be updated by dp[j][idx(A[i] - A[j])]. Besides, pay attention to initialization. Time complexity: O(n^2). Space complexity: O(n^2). longest-palindrome(easy) Count characters appearing even times or odd times. Time complexity: O(n). Space complexity: O(#char). range-sum-query-mutable(medium) BIT(Binary Indexed Tree)(It’s my first time knowing its english name…). A followup is modifying a sub-array each time. Here is a summary of BIT. By the way, the straightforward approach is, of course, segment tree. Time complexity: O(logn) for each update and query. Space complexity: O(n). search-in-a-binary-search-tree(easy) Time complexity: O(logn), expected. Space complexity: O(1). solve-the-equation(medium) Count the scale of x and the constant for left part and right part, respectively. The only thing you should note is the scale of x could be 0. Time complexity: O(n). Space complexity: O(1).","categories":[],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://proverbs.github.io/tags/algorithm/"},{"name":"LeetCode","slug":"LeetCode","permalink":"https://proverbs.github.io/tags/LeetCode/"}]},{"title":"[Leetcode]collection-2019-01-28","slug":"Leetcode-collection-2019-01-28","date":"2019-01-28T23:45:35.000Z","updated":"2021-05-30T16:25:43.046Z","comments":true,"path":"2019/01/28/Leetcode-collection-2019-01-28/","link":"","permalink":"https://proverbs.github.io/2019/01/28/Leetcode-collection-2019-01-28/","excerpt":"My code can be viewed in my github: Proverbs Github. The following difficulty is defined by myself. beautiful-array(hard) It is hard because the first time I see this problem, I didn’t have any idea of how to solve it. Then, it the discuss, I found a quite brilliant way which is kind of like a reversion divide and conquer. Divide the range to the odd part and the even part. Combining with the two properties, we can scale down the problem. Link. Time complexity: O(n) with cache. Space complexity: O(n). expressive-words(easy) O(n) for enumerating groups, O(n) for checking if one group can extend to another. Time complexity: O(n^2). Space complexity: O(1) logger-rate-limiter(easy) Use a map to save the timestamp. Time complexity: O(1). Space complexity: O(n).","text":"My code can be viewed in my github: Proverbs Github. The following difficulty is defined by myself. beautiful-array(hard) It is hard because the first time I see this problem, I didn’t have any idea of how to solve it. Then, it the discuss, I found a quite brilliant way which is kind of like a reversion divide and conquer. Divide the range to the odd part and the even part. Combining with the two properties, we can scale down the problem. Link. Time complexity: O(n) with cache. Space complexity: O(n). expressive-words(easy) O(n) for enumerating groups, O(n) for checking if one group can extend to another. Time complexity: O(n^2). Space complexity: O(1) logger-rate-limiter(easy) Use a map to save the timestamp. Time complexity: O(1). Space complexity: O(n). longest-word-in-dictionary-through-deleting(easy) O(n) for enumerating words, O(word.length) for checking if the word is the subsequence of the given string. Time complexity: O(n * word.length). Space complexity: O(1). minesweeper(easy) Recursion. Just do as the description. Time complexity: O(len * col). Space complexity: O(len * col). most-stones-removed-with-same-row-or-column(hard) It quite easy to go into a incorrect greedy solution which can be seen in my github. A counter example. The correct solution is to find components. There are two key insights: Connected stones can be reduced to 1 stone. the maximum stones can be removed = stones number - islands number. Time complexity: O(n). Space complexity: O(n). print-binary-tree(medium) First, compute the size of the output. Then, use divide and conquer. I think my solution is quite elegant. I mean, just for this problem. ^_^. Time complexity: O(2^h). Space complexity: O(h * 2^h). self-dividing-numbers(easy) Do as the description. Time complexity: O(digits * n). Space complexity: O(1).","categories":[],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://proverbs.github.io/tags/algorithm/"},{"name":"LeetCode","slug":"LeetCode","permalink":"https://proverbs.github.io/tags/LeetCode/"}]},{"title":"[Leetcode]collection-2019-01-08","slug":"Leetcode-collection-2019-01-08","date":"2019-01-09T01:06:39.000Z","updated":"2021-05-30T16:25:43.046Z","comments":true,"path":"2019/01/08/Leetcode-collection-2019-01-08/","link":"","permalink":"https://proverbs.github.io/2019/01/08/Leetcode-collection-2019-01-08/","excerpt":"My code can be viewed in my github: Proverbs Github. The following difficulty is defined by myself. arranging-coins(easy) Math. Time complexity: O(1). Space complexity: O(1). combination-sum-iv(medium) Knapsack problem. Just note the order of the loops and which loop is the outer one. As for the follow-up, I think we should add the limitation that we can only use a negative number at most once, or there could be infinite combinations. And then to solve this new problem, my idea is run 01-knapsack problem to initialize the array dp. This is just what I think about, and I cannot guarantee it is correct. Time complexity: O(n*target). Space complexity: O(target). generate-random-point-in-a-circle(medium) A simplest way is to use rejection sampling, which I have mentioned before. However, my intuition is to pick a radius and a radian randomly, which seems like quite easy. However, there exists a pitfall that the probability of a point with a larger radius should be larger than that with a smaller radius. Time complexity: O(1). Space complexity: O(1).","text":"My code can be viewed in my github: Proverbs Github. The following difficulty is defined by myself. arranging-coins(easy) Math. Time complexity: O(1). Space complexity: O(1). combination-sum-iv(medium) Knapsack problem. Just note the order of the loops and which loop is the outer one. As for the follow-up, I think we should add the limitation that we can only use a negative number at most once, or there could be infinite combinations. And then to solve this new problem, my idea is run 01-knapsack problem to initialize the array dp. This is just what I think about, and I cannot guarantee it is correct. Time complexity: O(n*target). Space complexity: O(target). generate-random-point-in-a-circle(medium) A simplest way is to use rejection sampling, which I have mentioned before. However, my intuition is to pick a radius and a radian randomly, which seems like quite easy. However, there exists a pitfall that the probability of a point with a larger radius should be larger than that with a smaller radius. Time complexity: O(1). Space complexity: O(1). maximum-depth-of-n-ary-tree(easy) Recursion. Time complexity: O(n). Space complexity: O(n). minimum-ascii-delete-sum-for-two-strings(medium) DP. The same as longest common subsequence. Time complexity: O(s1.length*s2.length). Space complexity: O(s1.length*s2.length). n-queens-ii(medium) The same as n-queens which can be solved using backtracking. Time complexity: O(n!). Space complexity: O(n). optimal-account-balancing(hard) It can be converted to that some people need to pay and some people need to get paid, and the question is what is the least transactions. At first, it looks like a network flow(min cost max flow) problem. However, whatever how much you pay, it just count as 1 transaction, which does not meet the requirement of network flow. So, we should search for the result. Then, I wrote a quite complicated DFS and it got to be too slow. Finally, I found a really brilliant DFS method: 123456789101112131415void dfs(int x, int cs) &#123; if (x &gt;= out.size()) &#123; res = min(res, cs); return; &#125; if (out[x] == 0) dfs(x + 1, cs); else &#123; for (int i = x + 1; i &lt; out.size(); i ++) &#123; if (out[i] * out[x] &gt;= 0) continue; out[i] += out[x]; // brilliant! use i to replace x to pay or get paied dfs(x + 1, cs + 1); out[i] -= out[x]; &#125; &#125;&#125; Time complexity: O(n!). Space complexity: O(n). permutation-sequence(easy) It is easy to calculate there are how many permutations start with a certain number. Time complexity: O(n). Space complexity: O(n). russian-doll-envelopes(medium) The same as longest increasing subsequence after sorting the array by the width. One simple approach is that dp[i] denotes the length of the longest increasing subsequence end with the i-th element, which is O(n^2). Another faster approach is that dp[i] denotes the smallest ending element for the subsequence with the length of i, which is O(nlogn). A trick is [3, 4] cannot contains [3, 3], so we need to put [3, 4] before [3, 3] when sorting otherwise it will be counted as an increasing number if the order is [3, 3], [3, 4]. Time complexity: O(n^2) or O(n). Space complexity: O(n). shortest-path-to-get-all-keys(hard) State compressed dijkstra(optimized by PQ) dis[i][state] means the person is at position i and state consists of what keys he has. Time complexity: O(n2^klog(n*2^k)). Space complexity: O(n*2^k). word-pattern-ii(medium) Backtracking. The most difficult parts are how to solve it concisely(I think my implementation is elegant, ^_^) and hwo to optimize it. What I use for optimization is an argument of remaining length for patterns out of the map. Time complexity: It is quite hard to tell because of the optimization. Space complexity: O(str,.length).","categories":[],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://proverbs.github.io/tags/algorithm/"},{"name":"LeetCode","slug":"LeetCode","permalink":"https://proverbs.github.io/tags/LeetCode/"}]},{"title":"[Leetcode]collection-2019-01-07","slug":"Leetcode-collection-2019-01-07","date":"2019-01-08T01:41:21.000Z","updated":"2021-05-30T16:25:43.046Z","comments":true,"path":"2019/01/07/Leetcode-collection-2019-01-07/","link":"","permalink":"https://proverbs.github.io/2019/01/07/Leetcode-collection-2019-01-07/","excerpt":"My code can be viewed in my github: Proverbs Github. The following difficulty is defined by myself. boundary-of-binary-tree(easy) The top is the root, the left or right boundary is the “leftmost” or “rightmost” nodes. The remaining leaves are the bottom. Use dfs to get the left boundary and leaves in the left subtree. And do the same thing for right boundary and leaves in the right subtree. Time complexity: O(n). Space complexity: O(n). custom-sort-string(medium) The easiest approach is to use quick sort and overwrite the compare function, which is O(nlogn). However, there will only be at most 26 characters. Thus, we can use counting sort which is not based on comparison. Time complexity: O(s.length+t.length). Space complexity: extra O(26). design-circular-queue(easy) Circular queue’s size should be (1 + size of ordinary queue) in order to represent states of empty and full. Time complexity: O(1) for each operation. Space complexity: O(size).","text":"My code can be viewed in my github: Proverbs Github. The following difficulty is defined by myself. boundary-of-binary-tree(easy) The top is the root, the left or right boundary is the “leftmost” or “rightmost” nodes. The remaining leaves are the bottom. Use dfs to get the left boundary and leaves in the left subtree. And do the same thing for right boundary and leaves in the right subtree. Time complexity: O(n). Space complexity: O(n). custom-sort-string(medium) The easiest approach is to use quick sort and overwrite the compare function, which is O(nlogn). However, there will only be at most 26 characters. Thus, we can use counting sort which is not based on comparison. Time complexity: O(s.length+t.length). Space complexity: extra O(26). design-circular-queue(easy) Circular queue’s size should be (1 + size of ordinary queue) in order to represent states of empty and full. Time complexity: O(1) for each operation. Space complexity: O(size). encode-string-with-shortest-length(hard) DP. dp[i][j]: shortest encoded string from s[i] to s[j], dp[i][j] can be modified by dp[i][k] + dp[k + 1][j] and a substring of s[i~j] which can form s[i~j] by repeating. To check if there is a substring of s[i~j] which can form s[i~j] by repeating, we can use R-K Hash. Greedy algorithm to encode from the longest duplicate substrings is wrong. e.g. aaabbbaaabbbaaabbbaaa Time complexity: O(n^3). Space complexity: O(n^2). flipping-an-image(easy) Time complexity: O(row*col). Space complexity: O(row*col). guess-number-higher-or-lower-ii(hard) DP. dp[i][j] means the lowest cost to guess from i to j. dp[i][j] = min(i + max(dp[i][k - 1] + dp[k + 1][j])), which is O(n^3). There is a quite challengeable solution which is O(n^2). Time complexity: O(n^3). Space complexity: O(^2). implement-rand10-using-rand7(medium) It is a typical method: Rejection Sampling. Time complexity: O(1) expected. Space complexity: O(n). implement-stack-using-queues(medium) Keep the order of queue except that the last element becomes the first when pushing. Time complexity: O(n) for push, O(1) for other functions. Space complexity: O(n). insert-into-a-cyclic-sorted-list(medium) Find the smallest and greatest nodes. Time complexity: O(n). Space complexity: O(1). is-subsequence(easy) Greedy algorithm. Time complexity: O(t.length). Space complexity: O(1). knight-dialer(medium) It is a simplest problem of fast power of matrix. And the ordinary method is DP. Time complexity: O(logn). Space complexity: O(10). maximize-distance-to-closest-person(easy) Scan from left to right and keep track of a last pointer. Time complexity: O(n). Space complexity: O(1). minimum-moves-to-equal-array-elements(medium) The last state before all elements are equal is (n-1) elements are equal. The last state before (n-1) elements are equal is (n-2) elements are equal. … That is the approach. Time complexity: O(nlogn). Space complexity: O(n). odd-even-linked-list(easy) Divide linked list to odd and even parts. Time complexity: O(n). Space complexity: O(1). palindrome-permutation(easy) There are no more than 2 characters which appear odd times. Time complexity: O(n). Space complexity: O(n). rectangle-area(easy) Sum of two areas subtract the overlapped area. Time complexity: O(1). Space complexity: O(1). score-of-parentheses(easy) Recursion. Time complexity: O(n). Space complexity: O(n). search-in-rotated-sorted-array-ii(hard) Maybe when I had a messy mind when I tried to solve it. Time complexity: O(n) in the worst case. Space complexity: O(1). trapping-rain-water-ii(hard) It a good problem. However, 1D solution is not applicable for 2D problem because there are many path for water to go down. The solution is to use priority queue to maintain the minimum border and current height which means the shortest piece of the bucket for the new added point. Time complexity: O(nmlog(n*m)). Space complexity: O(n*m).","categories":[],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://proverbs.github.io/tags/algorithm/"},{"name":"LeetCode","slug":"LeetCode","permalink":"https://proverbs.github.io/tags/LeetCode/"}]},{"title":"[Leetcode]collection-2019-01-06","slug":"Leetcode-collection-2019-01-06","date":"2019-01-07T05:25:56.000Z","updated":"2021-05-30T16:25:43.046Z","comments":true,"path":"2019/01/06/Leetcode-collection-2019-01-06/","link":"","permalink":"https://proverbs.github.io/2019/01/06/Leetcode-collection-2019-01-06/","excerpt":"My code can be viewed in my github: Proverbs Github. The following difficulty is defined by myself. all-paths-from-source-to-target(easy) DFS and keep track of current path. Time complexity: O(n). Space complexity: O(n). convert-sorted-list-to-binary-search-tree(medium) The same as building BST from sorted array. And the only difference is we should traverse the whole linked list to get its length is each round of DFS. So, the time complexity will be O(nlogn) rather than O(n). Another smarter O(n) solution is using in-order traversal: Link, which is to keep track of current node pointer and build the tree from left to right using recursion of in-order traversal. Time complexity: O(nlogn). Space complexity: O(n).","text":"My code can be viewed in my github: Proverbs Github. The following difficulty is defined by myself. all-paths-from-source-to-target(easy) DFS and keep track of current path. Time complexity: O(n). Space complexity: O(n). convert-sorted-list-to-binary-search-tree(medium) The same as building BST from sorted array. And the only difference is we should traverse the whole linked list to get its length is each round of DFS. So, the time complexity will be O(nlogn) rather than O(n). Another smarter O(n) solution is using in-order traversal: Link, which is to keep track of current node pointer and build the tree from left to right using recursion of in-order traversal. Time complexity: O(nlogn). Space complexity: O(n). find-duplicate-subtrees(medium) Tree serialization. Time complexity: O(n^2) for the worst case that the tree is a linked list. Space complexity: O(n^2). find-k-pairs-with-smallest-sums(hard) Consider a 2D table from nums1 x nums2. Then, you will find some rules and figure out the solution. 2D table. Time complexity: O(klogk). Space complexity: O(k). maximum-binary-tree(hard) Build “BST”. To solve the queries of the maximum value of intervals, a better way is segment tree, though I used brute force. However, I think brute force and segment solutions are both O(nlogn). A quite brilliant resolution is based on the finding that the parent of a node = min(nearest max to the left, nearest max to the right), which can be seen at Link. Time complexity: O(nlogn). Space complexity: O(n). maximum-vacation-days(medium) DP. dp[i][j]: max vacation if staying at place i in the j-th week. Time complexity: O(n^2k) Space complexity: O(nk). one-edit-distance(easy) Because we can only use the operations once, we can just use DFS. Time complexity: O(n). Space complexity: O(n). shortest-path-visiting-all-nodes(medium) The simplest state compressed DP. dp[x][state]: max vacation days if cities you have been to are state, and you are current staying at x. A trick is how to handle the problem that you can go to a cities many times. My solution is to add an additional loop to modify dp array: modify n times for dp[point][state], because dp[p1][state] can be modified by dp[p2][state]. Time complexity: O(n^3*2^n). Space complexity: O(n*2^n). shortest-word-distance(easy) Find the nearest word2 left or right to each word1. Time complexity: O(n). Space complexity: O(1). valid-triangle-number(medium) Sort + two pointers, which is similar to 3sum. Time complexity: O(n^2). Space complexity: O(n).","categories":[],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://proverbs.github.io/tags/algorithm/"},{"name":"LeetCode","slug":"LeetCode","permalink":"https://proverbs.github.io/tags/LeetCode/"}]},{"title":"[Leetcode]collection-2019-01-05","slug":"Leetcode-collection-2019-01-05","date":"2019-01-06T05:46:31.000Z","updated":"2021-05-30T16:25:43.046Z","comments":true,"path":"2019/01/05/Leetcode-collection-2019-01-05/","link":"","permalink":"https://proverbs.github.io/2019/01/05/Leetcode-collection-2019-01-05/","excerpt":"My code can be viewed in my github: Proverbs Github. The following difficulty is defined by myself. card-flipping-game(easy) The description is kind of vague. Another description from discussion is: Given an array of cards with numbers written on both sides and an infinite number of card flips, find the minimum number appearing on any card’s back which is not appearing on any card’s front. And the solution is to find the smallest number which never appears on both sides of any card. Time complexity: O(n). Space complexity: O(n). count-different-palindromic-subsequences(hard) The most difficult point of this problem is how to deal with the duplicate subsequences. dp[c][lt][rt]: number of different subsequences which start with c and end with c using letters in range [lt, rt]. The key point is when c == s[lt] == s[rt]: 1234567891011121314151617if (s[lt] == 'a' + c &amp;&amp; s[rt] == 'a' + c) &#123; if (lt + 1 == rt) &#123; res = 2; // c, cc return res; &#125; res = 1; // cc res += dfs(dp, s, c, lt + 1, rt - 1); if (dfs(dp, s, c, lt + 1, rt - 1)) res ++; // there exists at least one c, then 1 for cc...cc or c...c...c else res ++; // there exists no c, then 1 for c res %= mod; for (int i = 0; i &lt; 4; i ++) if (i != c) &#123; res += dfs(dp, s, i, lt + 1, rt - 1); res %= mod; &#125;&#125; PS: Why I got MLE if I used the resize function??? Time complexity: O(4*length^2). Space complexity: O(4*length^2).","text":"My code can be viewed in my github: Proverbs Github. The following difficulty is defined by myself. card-flipping-game(easy) The description is kind of vague. Another description from discussion is: Given an array of cards with numbers written on both sides and an infinite number of card flips, find the minimum number appearing on any card’s back which is not appearing on any card’s front. And the solution is to find the smallest number which never appears on both sides of any card. Time complexity: O(n). Space complexity: O(n). count-different-palindromic-subsequences(hard) The most difficult point of this problem is how to deal with the duplicate subsequences. dp[c][lt][rt]: number of different subsequences which start with c and end with c using letters in range [lt, rt]. The key point is when c == s[lt] == s[rt]: 1234567891011121314151617if (s[lt] == 'a' + c &amp;&amp; s[rt] == 'a' + c) &#123; if (lt + 1 == rt) &#123; res = 2; // c, cc return res; &#125; res = 1; // cc res += dfs(dp, s, c, lt + 1, rt - 1); if (dfs(dp, s, c, lt + 1, rt - 1)) res ++; // there exists at least one c, then 1 for cc...cc or c...c...c else res ++; // there exists no c, then 1 for c res %= mod; for (int i = 0; i &lt; 4; i ++) if (i != c) &#123; res += dfs(dp, s, i, lt + 1, rt - 1); res %= mod; &#125;&#125; PS: Why I got MLE if I used the resize function??? Time complexity: O(4*length^2). Space complexity: O(4*length^2). delete-node-in-a-linked-list(medium) We do not know the root of the linked list, then we create a root by swapping current node with the next node. Time complexity: O(1). Space complexity: O(1). design-snake-game(medium) Use deque to represent the snake and use queue to represent the food. Time complexity: O(1). Space complexity: O(1). h-index(hard) The result must be from 1 to n. So, we can sort the array and then enumerate the result and use binary search to check how many numbers are not less than the result. This is the O(nlogn) method. However, there is a brilliant solution which applies the counting sort whose complexity is determined by range. Again, the result must be from 1 to n, then all numbers larger than n are meaningless and we can change them to n to reduce the range. Time complexity: O(nlogn) or O(n). Space complexity: O(n). longest-line-of-consecutive-one-in-matrix(medium) Only check the top, left, top-left or top-right 1 for each line. Then, we can solve it in one pass. Time complexity: O(row*col). Space complexity: O(row*col). longest-substring-with-at-least-k-repeating-characters(hard) It is hard to apply sliding window, when we cannot determine how many unique letters should be in the sliding window. So, we can enumerate the number of unique letters and then use 26 sliding windows for different numbers of unique letters. Time complexity: O(26*n). Space complexity: O(n). network-delay-time(medium) Shortest path from a single source point: SPFA. Time complexity: O(n^2). Space complexity: O(n^2). next-greater-element-ii(easy) Extend the array using itself and then use stack to get the first larger element on the right. Time complexity: O(n). Space complexity: O(n). number-of-connected-components-in-an-undirected-graph(easy) DFS. Time complexity: O(n). Space complexity: O(n). partition-list(medium) Take the elements not less than x out of the original list. Then connect two lists. Time complexity: O(n). Space complexity: O(n). path-sum-ii(easy) DFS. Time complexity: O(n). Space complexity: O(n^2). random-pick-index(easy) Use a map to store all indices of a number. Time complexity: O(n) initialization, O(1) pick. Space complexity: O(n). same-tree(easy) Do it recursively. Time complexity: O(n). Space complexity: O(n). sentence-similarity(easy) Use nested maps to store the similarities. Time complexity: O(n+m). Space complexity: O(n+m). sum-of-subarray-minimums(medium) I have misunderstood the problem sum-of-subsequence-widths to this problem. You can see the method at: Link. Time complexity: O(n). Space complexity: O(n). the-maze-ii(medium) Heap or priority_queue + Dijkstra. Time complexity: O(colrowlog(row*col)). Space complexity: O(col*row).","categories":[],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://proverbs.github.io/tags/algorithm/"},{"name":"LeetCode","slug":"LeetCode","permalink":"https://proverbs.github.io/tags/LeetCode/"}]},{"title":"[Leetcode]collection-2019-01-04","slug":"Leetcode-collection-2019-01-04","date":"2019-01-05T02:06:19.000Z","updated":"2021-05-30T16:25:43.046Z","comments":true,"path":"2019/01/04/Leetcode-collection-2019-01-04/","link":"","permalink":"https://proverbs.github.io/2019/01/04/Leetcode-collection-2019-01-04/","excerpt":"My code can be viewed in my github: Proverbs Github. The following difficulty is defined by myself. bricks-falling-when-hit(hard) Reverse thinking and DSU to solve it offline. Time complexity: O(row*col). Space complexity: O(row*col). closest-binary-search-tree-value-ii(medium) Size of a subtree is a quite useful property for BST. Binary search the radius of the result range. Then get the number of elements less than a certain value can be solved in O(logn) by using the size property. If k is much smaller than n, then we can find k predecessors and k successors using stack. Time complexity: O(n) for initialization of size, O(logn*log(MAX_DIFF)) for binary searching and checking. Space complexity: O(n).","text":"My code can be viewed in my github: Proverbs Github. The following difficulty is defined by myself. bricks-falling-when-hit(hard) Reverse thinking and DSU to solve it offline. Time complexity: O(row*col). Space complexity: O(row*col). closest-binary-search-tree-value-ii(medium) Size of a subtree is a quite useful property for BST. Binary search the radius of the result range. Then get the number of elements less than a certain value can be solved in O(logn) by using the size property. If k is much smaller than n, then we can find k predecessors and k successors using stack. Time complexity: O(n) for initialization of size, O(logn*log(MAX_DIFF)) for binary searching and checking. Space complexity: O(n). delete-and-earn(medium) DP. Note that the range of numbers’ values are small. dp[0][i]: maximum earn after delete numbers less than i, and i is deleted for earning. dp[1][i]: delete numbers less than i, and i is not deleted for earning. It should be deleted by deleting (i - 1) to guarantee no aftereffect. Time complexity: O(range) + O(n). Space complexity: O(range). design-phone-directory(easy) unordered_set. Time complexity: O(1). Space complexity: O(n). excel-sheet-column-title(easy) It can be a little bit awkward, because the numbers do not start with 0. Time complexity: O(logn). Space complexity: O(logn). house-robber-ii(easy) DP. There are two cases: rob the first, then you cannot rob the last and not rob the first, then you can rob the last house or not rob. Time complexity: O(n). Space complexity: O(n). kth-smallest-element-in-a-bst(easy) Use size property. Follow-up: maintain the size of each subtree, then each query will be O(logn). Time complexity: O(n) for initialization, O(logn) for query. Space complexity: O(n). longest-palindromic-subsequence(medium) DP if intervals implemented by dfs with cache. Time complexity: O(length^2). Space complexity: O(length^2). next-greater-element-i(easy) First greater element on the right using mono-stack in O(n). Time complexity: O(n). Space complexity: O(n). number-of-atoms(medium) DFS of intervals and keep track of the outer scale. However, it could be annoying to numbers, letters and parentheses. Time complexity: O(length^2). Space complexity: O(length). pacific-atlantic-water-flow(medium) BFS. Add all points out of the range to the queue. Time complexity: O(row*col). Space complexity: O(row*col). read-n-characters-given-read4(easy) Bad description. Time complexity: O(n). Space complexity: O(1). reverse-pairs(medium) Reverse pairs using BIT with discretization. 12sort(v.begin(), v.end());sz = unique(v.begin(), v.end()) - v.begin(); Time complexity: O(nlogn). Space complexity: O(n). strobogrammatic-number(easy) Time complexity: O(length). Space complexity: O(1). sum-of-subsequence-widths(medium) I misunderstood the meaning of subsequence as subarray which should be continuous. Then, my solution is to convert sum of widths to: sum(max) - sum(min). I found the problem with this meaning. For A[i], if we want it to be the maximum in the subarray, then only need to know there are how many such subarrays which can be solved using the first larger element on its left and the first larger element on its right. However, subsequence here means subset. Then, we can use the same conversion and the problem gets much easier using fast power. Time complexity: O(n*logn). Space complexity: O(n). walls-and-gates(medium) It is a typical usage of BFS of multi-bfs in one. For these kind of BFS, we will add many start states to the queue. Time complexity: O(row*col). Space complexity: O(row*col).","categories":[],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://proverbs.github.io/tags/algorithm/"},{"name":"LeetCode","slug":"LeetCode","permalink":"https://proverbs.github.io/tags/LeetCode/"}]},{"title":"[Leetcode]collection-2019-01-03","slug":"Leetcode-collection-2019-01-03","date":"2019-01-04T03:42:52.000Z","updated":"2021-05-30T16:25:43.046Z","comments":true,"path":"2019/01/03/Leetcode-collection-2019-01-03/","link":"","permalink":"https://proverbs.github.io/2019/01/03/Leetcode-collection-2019-01-03/","excerpt":"My code can be viewed in my github: Proverbs Github. The following difficulty is defined by myself. battleships-in-a-board(easy) Because there is no two adjacent battleships, we can just count the top-left X in one pass. Time complexity: O(row*col). Space complexity: O(1). best-meeting-point(medium) Manhattan distance: x and y are independent. Then we can just think about the problem of 1D, and the solution is quite direct: to find the median. Time complexity: O(col*row). Space complexity: O(max(col, row)). bulls-and-cows(easy) Count using map. To avoid duplication, we can decrease the counter by one when there is a cow. Time complexity: O(n). Space complexity: O(n).","text":"My code can be viewed in my github: Proverbs Github. The following difficulty is defined by myself. battleships-in-a-board(easy) Because there is no two adjacent battleships, we can just count the top-left X in one pass. Time complexity: O(row*col). Space complexity: O(1). best-meeting-point(medium) Manhattan distance: x and y are independent. Then we can just think about the problem of 1D, and the solution is quite direct: to find the median. Time complexity: O(col*row). Space complexity: O(max(col, row)). bulls-and-cows(easy) Count using map. To avoid duplication, we can decrease the counter by one when there is a cow. Time complexity: O(n). Space complexity: O(n). can-place-flowers(easy) Greedy. Time complexity: O(n). Space complexity: O(1). construct-binary-tree-from-preorder-and-postorder-traversal(medium) The first element of preorder sequence which is the same as the last element of postorder sequence is the root. Delete this element and then find first k elements of preorder sequence and postorder sequence which can make two same sets. Then there elements can be the left subtree which may not be unique. Time complexity: O(n). Space complexity: O(n). contains-duplicate-iii(medium) A straightforward method is to maintain a sliding window with the size of k. And then use a BST(set) to find the largest element smaller then current number and the least element larger then current number. And Another quite brilliant method is bucketing. Details can be seen at: Link, which is O(n). Time complexity: O(nlogk). Space complexity: O(n). excel-sheet-column-number(easy) Number based on 26. Time complexity: O(length). Space complexity: O(1). fraction-addition-and-subtraction(medium) GCD(Greatest Common Divisor) and LCM(Least Common Multiple). 1234int get_gcd(int a, int b) &#123; if (!b) return a; return get_gcd(b, a % b);&#125; Time complexity: O(length*log(#factions)). Space complexity: O(1). k-diff-pairs-in-an-array(easy) Use map to eliminate duplicates. Or use two pointers after sorting. Time complexity: O(n). Space complexity: O(n). kill-process(medium) DFS on trees. Build tree: 123456head.resize(n, -1);void dfs(int x, vector&lt;int&gt;&amp; res) &#123; res.push_back(x); for (int i = head[x]; ~i; i = nxt[i]) dfs(to[i], res);&#125; Time complexity: O(n). Space complexity: O(n). minimum-area-rectangle(medium) Use map to classify points according to x-coordinates. Then sort each class according to y-coordinates. Enumerate two classes for left and right sides. Then, enumerate the top and bottom sides using map. Time complexity: O(n^2). Space complexity: O(n). peak-index-in-a-mountain-array(easy) Binary search. Time complexity: O(logn). Space complexity: O(1). permutations-ii(medium) Use dfs to generate all permutations. Do not use the same number for more than one times in each round. Time complexity: O(n!). Space complexity: O(n!*n). poor-pigs(hard) It is a good math problem and this method is widely used. Note the description could be misleading. REF. Time complexity: O(logn). Space complexity: O(1). recover-binary-search-tree(medium) The key point is to find which two elements are swapped. One dfs from largest number to smallest number to find the larger one, another dfs from smallest number to largest number to find the smaller one. Time complexity: O(n). Space complexity: O(n). remove-duplicates-from-sorted-list(easy) Linked list operations. Time complexity: O(n). Space complexity: O(1). special-binary-string(hard) Every time we can only swap two special strings, so the result should always be a special string. Represent a 01 string as “mountains, which is quite typical.”: Link. Note that we should enumerate height from high to low. An example is 111000-1101110000. Time complexity: O(length^2). Space complexity: O(length). split-array-largest-sum(medium) Binary search the result. Time complexity: O(logSUM*n). Space complexity: O(1). sum-of-distances-in-tree(hard) For the distance of a node, there are two parts: distance from its children and distance from its parent. Suppose s[x] is the sum of distance from its children, p[x] is the sum of distance from its parent and n[x] is the number of nodes in its subtree. Then s[x] and n[x] can be compute using DFS easily. And p[x] = s[fa[x]] - (s[x] + n[x]) + p[x] + n[fa[x]] - n[x] + p[x] + p[fa[x]] + (N - n[fa[x]]) which can be compute using anther DFS., Time complexity: O(n). Space complexity: O(n). the-maze(medium) DFS. Time complexity: O(col*row). Space complexity: O(col*row). valid-parenthesis-string(medium) DFS with cache to implement DP. Cannot understand the greedy solution. Time complexity: O(n^2). Space complexity: O(n^2). valid-square(easy) Note that the sides do not need to be parallel to x or y axes. Use vectors’ dot product to check if two vectors are perpendicular to each other. Time complexity: O(4!). Space complexity: O(1).","categories":[],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://proverbs.github.io/tags/algorithm/"},{"name":"LeetCode","slug":"LeetCode","permalink":"https://proverbs.github.io/tags/LeetCode/"}]},{"title":"[Leetcode]collection-2019-01-02","slug":"Leetcode-collection-2019-01-02","date":"2019-01-03T01:41:09.000Z","updated":"2021-05-30T16:25:43.046Z","comments":true,"path":"2019/01/02/Leetcode-collection-2019-01-02/","link":"","permalink":"https://proverbs.github.io/2019/01/02/Leetcode-collection-2019-01-02/","excerpt":"My code can be viewed in my github: Proverbs Github. The following difficulty is defined by myself. all-nodes-distance-k-in-binary-tree(medium) ALL problem related to distance in trees can be solved using depth. Find the depth of the target node. If it is in the left subtree, find all nodes which meet the requirement in the right subtree. And if it is in the right subtree, find all nodes in left subtree. If the difference of depth between current node and the target node is K, push back current node to the results. Time complexity: O(n). Space complexity: O(n). binary-tree-paths(easy) DFS. Time complexity: O(n). Space complexity: O(n). diagonal-traverse(easy) There are 4 ways of going out of bounds in total. Time complexity: O(row*col). Space complexity: O(row*col).","text":"My code can be viewed in my github: Proverbs Github. The following difficulty is defined by myself. all-nodes-distance-k-in-binary-tree(medium) ALL problem related to distance in trees can be solved using depth. Find the depth of the target node. If it is in the left subtree, find all nodes which meet the requirement in the right subtree. And if it is in the right subtree, find all nodes in left subtree. If the difference of depth between current node and the target node is K, push back current node to the results. Time complexity: O(n). Space complexity: O(n). binary-tree-paths(easy) DFS. Time complexity: O(n). Space complexity: O(n). diagonal-traverse(easy) There are 4 ways of going out of bounds in total. Time complexity: O(row*col). Space complexity: O(row*col). encode-and-decode-strings(medium) Because all 256 characters can be used, so we cannot use special characters as separator. A smart way is to combine the length with the string to encoded. Time complexity: O(#strings*length). Space complexity: O(#strings*length). flood-fill(easy) DFS. Be careful of the case that the new color is the same as current color. Time complexity: O(row*col). Space complexity: O(row*col). largest-number(medium) It is quite typical problem. We can use a custom comparator to decide how to order the numbers. Time complexity: O(nlogn*length). Space complexity: O(n*length). longest-continuous-increasing-subsequence(easy) Scan from left to right. Time complexity: O(n). Space complexity: O(1). maximum-sum-circular-subarray(hard) I worked out a method of using two pointers. However, it showed that this method is wrong although I did not find a small-scale counter-example. Then I use sliding window and keep track of the minimum number in the window by converting sums of subarray to difference between prefix sums. Time complexity: O(n). Space complexity: O(n). middle-of-the-linked-list(easy) The straightforward way is to find the length. Another way is to use fast-slow pointers. Time complexity: O(n). Space complexity: O(1). minimum-number-of-refueling-stops(medium) DP. dp[i][j]: max fuel when the car reaches i and has stopped at j stations for refueling. There are two ways of state transition: refuel at i or not refuel. And because the target may not be a station, so we create a virtual station for convenience. Optimization: first dimension can be compressed or even eliminated. Time complexity: O(n^2). Space complexity: O(n^2) or O(n). next-greater-element-iii(medium) Next permutation. Find the longest ascending sequence from right to left. Then, swap and reverse. Just be careful of the case that there exists many digits with the same value. Time complexity: O(n). Space complexity: O(1). number-of-1-bits(easy) Bits operation. Time complexity: O(32). Space complexity: O(1). number-of-islands-ii(medium) Disjoint set union. This problem can be solved online. Time complexity: O(row*col) if considering findfa() as an O(1) method. Space complexity: O(row*col). number-of-music-playlists(hard) DP. dp[i][j]: number of ways to play first i songs using j unique songs. There are two ways of state transition: play a new song or an old song. Time complexity: O(NL). Space complexity: O(NL). peeking-iterator(medium) At first glance, I did not have any idea of how to do it. And after a while, I use a variable to keep track of whether peek() function has been called. If true, we will not call Iterator::next() for the next next() function. Time complexity: O(1). Space complexity: O(1). reorganize-string(medium) The straight forward method is to first meet the requirement from the most frequent number. Time complexity: O(nlogn). Space complexity: O(n). smallest-range(medium) The same as merge k ordered arrays. Time complexity: O(nlogk). Space complexity: O(k). sum-of-two-integers(easy) Add using 1’s complement. Time complexity: O(32). Space complexity: O(1). toeplitz-matrix(easy) Time complexity: O(row*col). Space complexity: O(1). transpose-matrix(easy) Time complexity: O(row*col). Space complexity: O(row*col).","categories":[],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://proverbs.github.io/tags/algorithm/"},{"name":"LeetCode","slug":"LeetCode","permalink":"https://proverbs.github.io/tags/LeetCode/"}]},{"title":"[Leetcode]collection-2019-01-01","slug":"Leetcode-collection-2019-01-01","date":"2019-01-02T01:37:12.000Z","updated":"2021-05-30T16:25:43.046Z","comments":true,"path":"2019/01/01/Leetcode-collection-2019-01-01/","link":"","permalink":"https://proverbs.github.io/2019/01/01/Leetcode-collection-2019-01-01/","excerpt":"My code can be viewed in my github: Proverbs Github. The following difficulty is defined by myself. balanced-binary-tree(easy) DFS for depth. Time complexity: O(n). Space complexity: O(1) without stack. best-time-to-buy-and-sell-stock-iv(hard) DP. Basic idea: dp[i][j] denotes maximum profit for first i days and at most j transactions. dp[i][j] = max(dp[p - 1][j - 1] + prices[i] - prices[p]), where p &lt;= i. However, it is an O(kn^2) method. And the optimization is to keep track of the maximum value of (dp[p - 1][j - 1] - prices[p]) while looping through i. And another optimization is to use rolling array. Time complexity: O(min(kn, n^2)). Space complexity: O(min(kn, n^2)). design-linked-list(easy) I did not implement linked list myself, but directly use stl list. Time complexity: O(1) for insert and delete, O(n) for indexing. Space complexity: O(n).","text":"My code can be viewed in my github: Proverbs Github. The following difficulty is defined by myself. balanced-binary-tree(easy) DFS for depth. Time complexity: O(n). Space complexity: O(1) without stack. best-time-to-buy-and-sell-stock-iv(hard) DP. Basic idea: dp[i][j] denotes maximum profit for first i days and at most j transactions. dp[i][j] = max(dp[p - 1][j - 1] + prices[i] - prices[p]), where p &lt;= i. However, it is an O(kn^2) method. And the optimization is to keep track of the maximum value of (dp[p - 1][j - 1] - prices[p]) while looping through i. And another optimization is to use rolling array. Time complexity: O(min(kn, n^2)). Space complexity: O(min(kn, n^2)). design-linked-list(easy) I did not implement linked list myself, but directly use stl list. Time complexity: O(1) for insert and delete, O(n) for indexing. Space complexity: O(n). exam-room(hard) The most popular method is to use priority queue. However, remove function for priority queue is O(n). My solution is to use set and map to implement O(logn) for both seat and leave. Use set to keep track of all available intervals according to their length, and use map to keep track of the left interval and right interval of a seat position. Time complexity: O(logn). Space complexity: O(nlogn). find-k-closest-elements(easy) Two pointers. Time complexity: O(n). Space complexity: O(k). heaters(medium) Use binary search to convert to the problem of checking whether a result is feasible. The O(n) checking method is typical. 1234567bool check(vector&lt;int&gt;&amp; ho, vector&lt;int&gt;&amp; he, int r) &#123; // O(n) check int nht = 0; for (int i = 0; i &lt; ho.size() &amp;&amp; nht &lt; he.size(); i ++) &#123; while (nht &lt; he.size() &amp;&amp; (ho[i] &lt; he[nht] - r || ho[i] &gt; he[nht] + r)) nht ++; &#125; return nht &lt; he.size();&#125; Time complexity: O(nlog(MAX_INT)). Space complexity: O(1). longest-substring-with-at-most-k-distinct-characters(medium) Sliding window. Time complexity: O(n). Space complexity: O(#char). majority-element-ii(hard) It is easy if you know moore majority voting. Time complexity: O(n). Space complexity: O(1). maximum-product-of-three-numbers(easy) A maximum is either nummaximum or numminimum. Time complexity: O(n). Space complexity: O(1). minimize-malware-spread-ii(medium) An infected node will not be infected if only one initially infected node can reach it without passing other initially infected nodes. Time complexity: O(kn^2). Space complexity: O(n^2). reaching-points(medium) Thinking of transform (tx,ty) to (sx,sy). However, there are many corner cases. Time complexity: O(logn) or even less. Space complexity: O(logn) or even less. rectangle-overlap(easy) Time complexity: O(1). Space complexity: O(1). search-a-2d-matrix(easy) Two binary search. lower_bound: first a[i] &gt;= val; upper_bound: first a[i] &gt; val. Time complexity: O((logn)^2). Space complexity: O(1). shuffle-an-array(hard) It is a quite typical method of shuffling. If you know the method, it is quite easy. It can be approved using mathematical induction. ref. Time complexity: O(n). Space complexity: O(1). snakes-and-ladders(medium) BFS. But be careful of the board!!! Time complexity: O(n^2). Space complexity: O(n^2). sort-characters-by-frequency(easy) Quick sort which is not a stable sort method! Time complexity: O(nlogn). Space complexity: O(1).","categories":[],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://proverbs.github.io/tags/algorithm/"},{"name":"LeetCode","slug":"LeetCode","permalink":"https://proverbs.github.io/tags/LeetCode/"}]},{"title":"[Leetcode]collection-2018-12-31","slug":"Leetcode-collection-2018-12-31","date":"2018-12-31T19:54:23.000Z","updated":"2021-05-30T16:25:43.046Z","comments":true,"path":"2018/12/31/Leetcode-collection-2018-12-31/","link":"","permalink":"https://proverbs.github.io/2018/12/31/Leetcode-collection-2018-12-31/","excerpt":"My code can be viewed in my github: Proverbs Github. The following difficulty is defined by myself. delete-node-in-a-bst(medium) First, find the node which should be deleted. (1) If the node is a leaf node, delete it directly. (2) If the node has exactly one child, replace it with its child. (3) If the node has two child, we will find the largest element in its left subtree, and replace it with that element. This can be implemented using recursion of deleting an element in its left subtree. Time complexity: O(height). Space complexity: O(1). flatten-a-multilevel-doubly-linked-list(easy) There are some pitfalls: (1) make nodes’ child pointers to NULL; (2) the same instance can be used for many times. Time complexity: O(n). Space complexity: O(1).","text":"My code can be viewed in my github: Proverbs Github. The following difficulty is defined by myself. delete-node-in-a-bst(medium) First, find the node which should be deleted. (1) If the node is a leaf node, delete it directly. (2) If the node has exactly one child, replace it with its child. (3) If the node has two child, we will find the largest element in its left subtree, and replace it with that element. This can be implemented using recursion of deleting an element in its left subtree. Time complexity: O(height). Space complexity: O(1). flatten-a-multilevel-doubly-linked-list(easy) There are some pitfalls: (1) make nodes’ child pointers to NULL; (2) the same instance can be used for many times. Time complexity: O(n). Space complexity: O(1). knight-probability-in-chessboard(easy) Like DP, cs[i + 1][nx][ny] += 1.0 * cs[i][x][y] / 8, where cs[i][x][y] denotes the probability of the knight staying at (x,y) after i moves. Time complexity: O(KN^2). Space complexity: O(KN^2) without compressing state space. kth-largest-element-in-a-stream(medium) k never changes, so we can use min-heap to maintain the k largest numbers. Or, we should use BST. Time complexity: O(logn) for add. Space complexity: O(n). largest-palindrome-product(medium) I do not have any good idea for this problem, although I passed all test cases using brute force whose time complexity can be very large theoretically. Time complexity: hard to tell. Space complexity: O(n). lowest-common-ancestor-of-a-binary-search-tree(easy) DFS. Time complexity: O(n). Space complexity: O(n). maximum-size-subarray-sum-equals-k(medium) Same as 2sum by converting sum of a subarray to the difference of two prefix sums. Time complexity: O(n). Space complexity: O(n). range-sum-query-2d-mutable(hard) 2D-bits. Time complexity: O(logn*logn) for each add and sumRegion functions, O((nlogn)^2) for initialization. Space complexity: O(n^2). reverse-bits(easy) Bits operations. Time complexity: O(32). Space complexity: O(1). reverse-words-in-a-string-iii(easy) Find each word and reverse it. Time complexity: O(n). Space complexity: O(1). rotate-array(medium) (1) push_back first (n-k) numbers, then move forwards elements by (n-k) positions. (2) Cyclic Replacements without using extra space. The trick is about how do we know whether a number has been swapped. (3) Reverse three times. Time complexity: O(n). Space complexity: O(n) or O(1). sort-array-by-parity(easy) Like partition in quick-sort. Time complexity: O(n). Space complexity: O(1). strobogrammatic-number-ii(easy) DFS and use an argument to denote whether we can use 0. Time complexity: O(5^(n/2)*n). Space complexity: O(^(n/2)*n). strobogrammatic-number-iii(hard) DFS to calculate how many numbers whose value are less than s and whose length is less than len. Also we use an argument to denote whether we can use 0. And there are many important details in the implementation. Time complexity: O(length). Space complexity: O(length). unique-binary-search-trees-ii(medium) DFS to build all trees of the range of [min_number, max_number]. Time complexity: hard to tell, but must be exponential complexity. Space complexity: same as Time complexity. unique-paths-ii(easy) Simplest DP. Time complexity: O(row*col). Space complexity: O(row*col). valid-palindrome-ii(easy) There will be only one decision we should make. Time complexity: O(n). Space complexity: O(1).","categories":[],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://proverbs.github.io/tags/algorithm/"},{"name":"LeetCode","slug":"LeetCode","permalink":"https://proverbs.github.io/tags/LeetCode/"}]},{"title":"[Leetcode]collection-2018-12-30","slug":"Leetcode-collection-2018-12-30","date":"2018-12-30T18:21:40.000Z","updated":"2021-05-30T16:25:43.046Z","comments":true,"path":"2018/12/30/Leetcode-collection-2018-12-30/","link":"","permalink":"https://proverbs.github.io/2018/12/30/Leetcode-collection-2018-12-30/","excerpt":"My code can be viewed in my github: Proverbs Github. The following difficulty is defined by myself. accounts-merge(medium) We cannot merge accounts in one pass because of the cases such as [[“David&quot;,&quot;David0@m.co”,&quot;David1@m.co&quot;],[“David&quot;,&quot;David3@m.co”,&quot;David4@m.co&quot;],[“David&quot;,&quot;David4@m.co”,&quot;David5@m.co&quot;],[“David&quot;,&quot;David2@m.co”,&quot;David3@m.co&quot;],[“David&quot;,&quot;David1@m.co”,&quot;David2@m.co&quot;]] So we need to do union find first. Time complexity: O(nlogn). Space complexity: O(nlogn). best-time-to-buy-and-sell-stock-iii(medium) DP. dp[i]: max profit before i; sq[i]: max profit after i. And the result should be max(dp[i] + sq[i]). Time complexity: O(n). Space complexity: O(n).","text":"My code can be viewed in my github: Proverbs Github. The following difficulty is defined by myself. accounts-merge(medium) We cannot merge accounts in one pass because of the cases such as [[“David&quot;,&quot;David0@m.co”,&quot;David1@m.co&quot;],[“David&quot;,&quot;David3@m.co”,&quot;David4@m.co&quot;],[“David&quot;,&quot;David4@m.co”,&quot;David5@m.co&quot;],[“David&quot;,&quot;David2@m.co”,&quot;David3@m.co&quot;],[“David&quot;,&quot;David1@m.co”,&quot;David2@m.co&quot;]] So we need to do union find first. Time complexity: O(nlogn). Space complexity: O(nlogn). best-time-to-buy-and-sell-stock-iii(medium) DP. dp[i]: max profit before i; sq[i]: max profit after i. And the result should be max(dp[i] + sq[i]). Time complexity: O(n). Space complexity: O(n). cherry-pickup(hard) DP. Similar to NOI-传纸条. dp[steps][x1][x2]: how many cherries can be picked from (0, 0) to (x1, steps-x1) and from (x1, steps-x1) to (0, 0). Time complexity: O(n^3). Space complexity: O(n^3). count-complete-tree-nodes(medium) If left child’s left-most path is longer than right child’s left-most path, then the right subtree is a full binary tree. Otherwise, the left subtree is a full binary tree. And number of nodes in a full binary tree can be computed according to the depth. Time complexity: O(logn*logn). Space complexity: O(1). find-pivot-index(easy) Prefix sums. Time complexity: O(n). Space complexity: O(n). happy-number(easy) DFS. Time complexity: hard to tell. Space complexity: O(1) except for stack. implement-queue-using-stacks(medium) It is a typical problem. Two stacks: one for pushing back and one for popping front. Time complexity: O(1) for push and empty. Amortized O(1) for pop and peek. Space complexity: O(n). interleaving-string(hard) We cannot do it using greedy algorithm. DP. It is similar to longest common subsequence. dp[i][j]: first i letters in s3 matching first j letters in s1 and first (i - j) letters in s2. Time complexity: O(s1.length*s3.length). Space complexity: O(s1.length*s3.length). island-perimeter(easy) Perimeter increases by 1 where 1 is adjacent to 0. Time complexity: O(width*length). Space complexity: O(1). max-increase-to-keep-city-skyline(easy) The maximum height of a building is min(max(height of the buildings in the row), max(height of the buildings in the column)). Time complexity: O(row*col). Space complexity: O(row*col). number-of-distinct-islands(medium) It is a typical problem. Different islands have different dfs sequences. Time complexity: O(width*length). Space complexity: O(width*length). populating-next-right-pointers-in-each-node-ii(medium) BFS: right child comes first. Time complexity: O(n). Space complexity: O(n). remove-duplicate-letters(hard) Greedy algorithm. We prefer a to be first letter. However, can a be the first letter? we can check this by finding if all other letters contain a position which is larger than current index of a. And this is the basic idea. Then we can try all as from the left-most position to the right-most position, then all bs and so on. Time complexity: O(n). Space complexity: O(n). search-insert-position(easy) Binary search. Time complexity: O(logn). Space complexity: O(1). sparse-matrix-multiplication(easy) Compress the sparse matrix. Time complexity: it depends on how sparse the matrix is. Space complexity: O(#non-zero-number). spiral-matrix-ii(easy) Maintain a direction. Time complexity: O(n^2). Space complexity: O(n^2). substring-with-concatenation-of-all-words(hard) k sliding windows where k is the length of the word. Time complexity: O(s.length*k). Space complexity: (s.length*k).","categories":[],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://proverbs.github.io/tags/algorithm/"},{"name":"LeetCode","slug":"LeetCode","permalink":"https://proverbs.github.io/tags/LeetCode/"}]},{"title":"[Leetcode]collection-2018-12-29","slug":"Leetcode-collection-2018-12-29","date":"2018-12-29T18:42:01.000Z","updated":"2021-05-30T16:25:43.046Z","comments":true,"path":"2018/12/29/Leetcode-collection-2018-12-29/","link":"","permalink":"https://proverbs.github.io/2018/12/29/Leetcode-collection-2018-12-29/","excerpt":"My code can be viewed in my github: Proverbs Github. The following difficulty is defined by myself. candy-crush(medium) Each round, we should crush all candies simultaneously and then we go for the next round. My way is to mark horizontal candies as 1 and vertical candies as 2. It takes O(width*height) time. Time complexity: O(#roundwidthheight). Space complexity: O(width*height). candy(medium) Compute the longest consecutive ascending subarray both from left and right. Select the greater number as the number of candies the child is given. Time complexity: O(n). Space complexity: O(n). degree-of-an-array(easy) keep track of how many times a number occurs and its left-most and right-most index using three maps. Time complexity: O(n). Space complexity: O(n).","text":"My code can be viewed in my github: Proverbs Github. The following difficulty is defined by myself. candy-crush(medium) Each round, we should crush all candies simultaneously and then we go for the next round. My way is to mark horizontal candies as 1 and vertical candies as 2. It takes O(width*height) time. Time complexity: O(#roundwidthheight). Space complexity: O(width*height). candy(medium) Compute the longest consecutive ascending subarray both from left and right. Select the greater number as the number of candies the child is given. Time complexity: O(n). Space complexity: O(n). degree-of-an-array(easy) keep track of how many times a number occurs and its left-most and right-most index using three maps. Time complexity: O(n). Space complexity: O(n). employee-free-time(medium) My intuition is segments overlap(line sweep) which takes O(mlogm) time where m is the number of intervals. Another method is to merge k ordered array and keep track of the latest end time, which is O(mlogn) where n is the number of employees. Time complexity: O(mlogm) or O(mlogn). Space complexity: O(m). find-all-duplicates-in-an-array(medium) It is a tricky but typical problem. Without using extra space, we should make a better use of the indexes by swapping nums[i] to the index of (nums[i] - 1). Then, only duplicated numbers’ indexes will not be num - 1. Time complexity: O(n). Space complexity: O(1) extra space. insert-delete-getrandom-o1-duplicates-allowed(hard) GetRandom in O(1) time means we should use array as the fundamental data structure. To delete a number, we can use a map to save its index and move the last number of the array to its index if there is no duplicate. When duplicates are allowed, we should build a doubly linked list on the array. Time complexity: O(1) for each operation. Space complexity: O(n). partition-to-k-equal-sum-subsets(hard) The straightforward way is DFS. However, I got TLE because I did not pass the start index as a parameter. Without it, we can run into cases which have been searched. Another way is state-compressed DP. We should only consider the last number we have added to current subset. Time complexity: O(NN!) for DFS and O(N2^N) for DP. Space complexity: O(N) for DFS and O(2^N) for DP. serialize-and-deserialize-n-ary-tree(medium) DFS. The same as binary tree serialization and deserialization by using a special character to denote backtracking. Time complexity: O(n). Space complexity: O(n). sliding-puzzle(medium) BFS. We should compress the puzzle grids to a number when pushing into the queue and extract the number to the puzzle grid when searching. A better but more complicated way is to bfs from source state and target state at the same time. Time complexity: O(6!46). Space complexity: O(6!46). summary-ranges(easy) Just scan from left to right. Time complexity: O(n). Space complexity: O(n).","categories":[],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://proverbs.github.io/tags/algorithm/"},{"name":"LeetCode","slug":"LeetCode","permalink":"https://proverbs.github.io/tags/LeetCode/"}]},{"title":"[Leetcode]collection-2018-12-28","slug":"Leetcode-collection-2018-12-28","date":"2018-12-28T17:55:14.000Z","updated":"2021-05-30T16:25:43.046Z","comments":true,"path":"2018/12/28/Leetcode-collection-2018-12-28/","link":"","permalink":"https://proverbs.github.io/2018/12/28/Leetcode-collection-2018-12-28/","excerpt":"My code can be viewed in my github: Proverbs Github. The following difficulty is defined by myself. cheapest-flights-within-k-stops(medium) Shortest path problem with an additional dimension to denote steps: dis[i][j] means shortest path from src to i, passing j nodes. It is an O(mk) solution, where m is number of edges. Another brilliant way is floyd + fast power. However, it takes O(n^3logk) time, which is much larger than former solution. Time complexity: O(n^3logk) or O(mk). Space complexity: O(n^2) or O(nk). continuous-subarray-sum(easy) Because the subarray should contains at least two elements, we should apply delay insertion to map. Time complexity: O(n). Space complexity: O(n). design-hashmap(medium) Self-designed map. Time complexity: O(1) if no conflicts. Space complexity: it depends.","text":"My code can be viewed in my github: Proverbs Github. The following difficulty is defined by myself. cheapest-flights-within-k-stops(medium) Shortest path problem with an additional dimension to denote steps: dis[i][j] means shortest path from src to i, passing j nodes. It is an O(mk) solution, where m is number of edges. Another brilliant way is floyd + fast power. However, it takes O(n^3logk) time, which is much larger than former solution. Time complexity: O(n^3logk) or O(mk). Space complexity: O(n^2) or O(nk). continuous-subarray-sum(easy) Because the subarray should contains at least two elements, we should apply delay insertion to map. Time complexity: O(n). Space complexity: O(n). design-hashmap(medium) Self-designed map. Time complexity: O(1) if no conflicts. Space complexity: it depends. 24-game(hard) Use stack to simulate ( and ), then we do not to consider brackets when running dfs. Enumerate the order of four numbers, then enumerate three operators. When running dfs, use stack to determine calculation order. However, it is a stupid method. A smarter way is to enumerate the order of four numbers according to calculation order. Time complexity: O(4^3*4!*2), where 2 means for - and / we should consider which number is put at the front and which number is put at the back. Space complexity: O(4). add-and-search-word-data-structure-design(medium) DFS on trie. Time complexity: O(length) for addWord, O(#nodes) for search in the worst case. Space complexity: O(n*length) in the worst case. coin-change-2(medium) Complete knapsack problem. Time complexity: O(n * amount). Space complexity: O(amount). count-univalue-subtrees(easy) DFS(recursion): the left child and right child should be univalue if a subtree is univalue. Time complexity: O(n). Space complexity: O(n). first-bad-version(easy) Binary search. Time complexity: O(logn). Space complexity: O(1). flatten-2d-vector(easy) Just be care of empty vector. Time complexity: O(1) on average. Space complexity: O(1). intersection-of-two-arrays-ii(easy) Count how many times each element appears in these two arrays respectively. Time complexity: O(n). Space complexity: O(n). kth-smallest-element-in-a-sorted-matrix(medium) Binary search the result, then we should count how many numbers less than the result. For counting, we can enumerate the rows and binary search each row. Time complexity: O(log(MAX_INT) * row * log(col)). Space complexity: O(1). maximum-sum-of-3-non-overlapping-subarrays(medium) DP with storing paths(decisions). dp[i][j] denotes the maximum sum of j subarrays for the first i elements. Time complexity: O(n). Space complexity: O(n). minimum-time-difference(easy) Convert the string of time to a number of minutes. Time complexity: O(n). Space complexity: O(24*60). missing-number(easy) Sum of 1 to n. Time complexity: O(n). Space complexity: O(1). moving-average-from-data-stream(easy) Sliding window and maintaining sum of elements in the window. Time complexity: O(n). Space complexity: O(n). permutation-in-string(easy) Sliding window. Reduce time complexity from O(26n) to O(n) by counting how many times letters appears. Time complexity: O(n). Space complexity: O(26). range-sum-query-2d-immutable(easy) Prefix sum of 2d array. Time complexity: O(n^2). Space complexity: O(n^2). shortest-distance-from-all-buildings(medium) BFS from all buildings and add distance to empty land for each BFS. Time complexity: O(building*empty). Space complexity: O(row*col). shortest-word-distance-ii(medium) Merge two ordered array because the shortest distance must be two adjacent positions. Time complexity: O(n) in the worst case. Space complexity: O(n). sudoku-solver(medium) DFS with accelerating checking availability: maintaining number available for 9 rows, 9 cols and 9 sub-boxes. Dancing links are too complicated. Time complexity: O(9^#empty_position) although in practical it never reach this complexity. Space complexity: O((9+9+9)*9). triangle(easy) DP. Space can be compressed because current state only depends on states in the upper layer. Time complexity: O(n^2). Space complexity: O(n). two-sum-iii-data-structure-design(easy) The testcase mostly consists of add rather than find, so we should mainly consider the time complexity of add function. Time complexity: O(1) for add, O(n) for find. Space complexity: O(n). wiggle-sort(medium) It is much easier than wiggle-sort-ii. It can be solved using double sorts, although it can also be solved using the same method of wiggle-sort-ii. Time complexity: O(n). Space complexity: O(n).","categories":[],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://proverbs.github.io/tags/algorithm/"},{"name":"LeetCode","slug":"LeetCode","permalink":"https://proverbs.github.io/tags/LeetCode/"}]},{"title":"[Leetcode]collection-2018-12-27","slug":"Leetcode-collection-2018-12-27","date":"2018-12-27T17:13:13.000Z","updated":"2021-05-30T16:25:43.046Z","comments":true,"path":"2018/12/27/Leetcode-collection-2018-12-27/","link":"","permalink":"https://proverbs.github.io/2018/12/27/Leetcode-collection-2018-12-27/","excerpt":"My code can be viewed in my github: Proverbs Github. The following difficulty is defined by myself. 4sum(medium) We can apply the same method of enumerating the first 2 positions as 3sum to this problem and the time complexity will be O(n^3). Sum of four numbers is the sum of two pairs. Thus, another way is to use a map to save the sums of all pairs of numbers and use a set to store corresponding pairs. To avoid duplications, we can stipulate that numbers in the first pair should not greater than numbers in the second pair. And to avoid cases like [-1, -1, -1, -1], sum=4, we should check if the combination of two pairs is available. Time complexity: O(n^2logn) if using set, O(n^2) if using unordered_set(need to customize hash function). Space complexity: O(n^2logn) if using set. all-oone-data-structure(hard) I have mentioned that: inc/dec by 1 --&gt; linked list before. Time complexity: O(1). Space complexity: O(n).","text":"My code can be viewed in my github: Proverbs Github. The following difficulty is defined by myself. 4sum(medium) We can apply the same method of enumerating the first 2 positions as 3sum to this problem and the time complexity will be O(n^3). Sum of four numbers is the sum of two pairs. Thus, another way is to use a map to save the sums of all pairs of numbers and use a set to store corresponding pairs. To avoid duplications, we can stipulate that numbers in the first pair should not greater than numbers in the second pair. And to avoid cases like [-1, -1, -1, -1], sum=4, we should check if the combination of two pairs is available. Time complexity: O(n^2logn) if using set, O(n^2) if using unordered_set(need to customize hash function). Space complexity: O(n^2logn) if using set. all-oone-data-structure(hard) I have mentioned that: inc/dec by 1 --&gt; linked list before. Time complexity: O(1). Space complexity: O(n). count-primes(easy) Sieve method to check primes. Time complexity: O(n). Space complexity: O(n). design-log-storage-system(medium) Set(customized comparator) + binary search. Time complexity: O(logn) for put function, O(result_size) for retrieve function. Space complexity: O(nlogn). frog-jump(medium) DP using recurrence(递推). Time complexity: O(n^2). Space complexity: O(n^2). is-graph-bipartite(easy) Coloring using two colors. Time complexity: O(n). Space complexity: O(n). isomorphic-strings(easy) s can mapping to t, t can mapping to s. Time complexity: O(n). Space complexity: O(n). simplify-path(easy) Stack for ... Time complexity: O(n). Space complexity: O(n). string-compression(easy) The compressed string will be always shorter than(or equal to) the its original string. Time complexity: O(n). Space complexity: O(1) in-place. swap-nodes-in-pairs(easy) Operations of linked list. Time complexity: O(n). Space complexity: O(1) in-place. to-lower-case(easy) Time complexity: O(n). Space complexity: O(n). two-sum-ii-input-array-is-sorted(easy) Two pointers. Each time left pointer moves right, right pointer will never move right. Time complexity: O(n). Space complexity: O(1). validate-ip-address(easy) Be careful of some special cases. Time complexity: O(n). Space complexity: O(1). zigzag-conversion(easy) The straightforward way is to put all letters to their 2D coordinates. But the smarter way is to compute the coordinates directly, O(length). Time complexity: O(num * length) for the first way. Space complexity: O(num * length) for the first way. course-schedule-ii(easy) Topological sort. TIme complexity: O(n). Space complexity: O(n). wiggle-sort-ii(hard) For wiggle-sort, we can just put those less than or equal to the median to even slots and those greater or equal to the median to odd slots. However, it is not correct for this problem because the relationship between two consecutive numbers is strict. For example, the solution of [4,5,5,6] is [5,6,4,5]. To get wiggle sort, you want to put the number in the following way such that (1) elements smaller than the ‘median’ are put into the last even slots (2) elements larger than the ‘median’ are put into the first odd slots (3) the medians are put into the remaining slots. ref. And the solution use three-way-partition and virtual indexing which is quite brilliant.","categories":[],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://proverbs.github.io/tags/algorithm/"},{"name":"LeetCode","slug":"LeetCode","permalink":"https://proverbs.github.io/tags/LeetCode/"}]},{"title":"[Leetcode]collection-2018-12-26","slug":"Leetcode-collection-2018-12-26","date":"2018-12-26T17:49:16.000Z","updated":"2021-05-30T16:25:43.046Z","comments":true,"path":"2018/12/26/Leetcode-collection-2018-12-26/","link":"","permalink":"https://proverbs.github.io/2018/12/26/Leetcode-collection-2018-12-26/","excerpt":"My code can be viewed in my github: Proverbs Github. The following difficulty is defined by myself. 3sum-with-multiplicity(easy) Similar to 3sum problem. Use map to count the multiplicity. Time complexity: O(n^2). Space complexity: O(100). circular-array-loop(medium) Bad description. [-2, 1, -1, -2, -2] returns false. To be a loop, it must never change direction. In other words, the elements of the loop must all have the same sign, either all positive or all negative. If it reverses direction it is an oscillation rather than a loop. Solution in O(1) space: Mark nums[x] as (sign * size) when visiting. Mark nums[x] as (2 * sign * size) after visiting. Time complexity: O(n). Space complexity: O(1).","text":"My code can be viewed in my github: Proverbs Github. The following difficulty is defined by myself. 3sum-with-multiplicity(easy) Similar to 3sum problem. Use map to count the multiplicity. Time complexity: O(n^2). Space complexity: O(100). circular-array-loop(medium) Bad description. [-2, 1, -1, -2, -2] returns false. To be a loop, it must never change direction. In other words, the elements of the loop must all have the same sign, either all positive or all negative. If it reverses direction it is an oscillation rather than a loop. Solution in O(1) space: Mark nums[x] as (sign * size) when visiting. Mark nums[x] as (2 * sign * size) after visiting. Time complexity: O(n). Space complexity: O(1). compare-version-numbers(easy) Split string to vector by points and compare from left to right. Time complexity: O(length). Space complexity: O(length). design-hit-counter(easy) Deque. Time complexity: O(1). Space complexity: O(n). inorder-successor-in-bst(easy) Do it during inorder traverse. Time complexity: O(n). Space complexity: O(1). insert-interval(medium) No need to binary search, can just scan from left to right and merge in the meanwhile. Time complexity: O(n). Space complexity: O(n). minimum-size-subarray-sum(medium) Two pointers. Maintain the sum between two pointers. Followup: shortest-subarray-with-sum-at-least-k. Time complexity: O(n). Space complexity: O(1). n-queens(medium) DFS. Time complexity: O(n^n). Space complexity: O(n^2). nested-list-weight-sum(easy) DFS. Time complexity: O(n). Space complexity: O(1) except for stack space. number-of-digit-one(medium) Math. Consider how many numbers are there less than n if the i-th digit is 1. Time complexity: O(#digits). Space complexity: O(1). shortest-subarray-with-sum-at-least-k(hard) It is a typical problem. Mono-increasing deque extending from two pointers method. For the right positions, (left, right], deque stores possible left pointers. The trick is to pop back when there is a negative number. Time complexity: O(n). Space complexity: O(n).","categories":[],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://proverbs.github.io/tags/algorithm/"},{"name":"LeetCode","slug":"LeetCode","permalink":"https://proverbs.github.io/tags/LeetCode/"}]},{"title":"[Leetcode]collection-2018-12-25","slug":"Leetcode-collection-2018-12-25","date":"2018-12-25T17:51:20.000Z","updated":"2021-05-30T16:25:43.046Z","comments":true,"path":"2018/12/25/Leetcode-collection-2018-12-25/","link":"","permalink":"https://proverbs.github.io/2018/12/25/Leetcode-collection-2018-12-25/","excerpt":"My code can be viewed in my github: Proverbs Github. The following difficulty is defined by myself. asteroid-collision(medium) Monotonous stack: each negative asteroid will make positive asteroids with less size explode until it meet a larger positive asteroid. Time complexity: O(n). Space complexity: O(n). design-tic-tac-toe(easy) There are only n + n + 2 ways to win the tic tac toe: n rows, n columns, and 2 diagonals. Time complexity: O(n). Space complexity: O(n).","text":"My code can be viewed in my github: Proverbs Github. The following difficulty is defined by myself. asteroid-collision(medium) Monotonous stack: each negative asteroid will make positive asteroids with less size explode until it meet a larger positive asteroid. Time complexity: O(n). Space complexity: O(n). design-tic-tac-toe(easy) There are only n + n + 2 ways to win the tic tac toe: n rows, n columns, and 2 diagonals. Time complexity: O(n). Space complexity: O(n). mencode-and-decode-tinyurl(easy) Map url to a number and then convert the number to a string with the length of 6 consisting of ‘a’-‘z’, ‘A’-‘Z’ and ‘0’-‘9’. Thus, it can store 62^6 mappings. Time complexity: O(length). Space complexity: O(n). find-the-celebrity(medium) The definition of a celebrity is that all the other n - 1 people know him/her but he/she does not know any of them. Thus, the celebrity must be the last node in any one of the paths. Time complexity: O(n). Space complexity: O(1). guess-the-word(medium) Because words are generated randomly, there should be many pairs matching 0 letters and much less pairs matching word.length()-1 letters. For a word, if the return value of guess() is 0, we cannot exclude any other words. So, we should select the word with least matching-0 pairs to guess to reduce the probability of getting 0 from guess(). Time complexity: in worst case, such as {‘a’, ‘b’, … , ‘z’}, O(n). Space complexity: O(n). reverse-linked-list-ii(easy) One pass solution. Time complexity: O(n). Space complexity: O(1). robot-room-cleaner(medium) Use relative coordinates to DFS with backtracking. Time complexity: O(width*length). Space complexity: O(width*length). serialize-and-deserialize-bst(medium) Use DFS to encode and decode the tree. When come to a NULL node, backtrack. Time complexity: O(n). Space complexity: O(n). subarray-product-less-than-k(medium) Two pointers and maintain the product of numbers between left and right pointers. When left pointer moves back, the product will not increase. Thus, the right pointer never moves forward. And there is a brilliant idea that to use binary search by converting the problem from subarray products to subarray sums using log. Time complexity: O(n). Space complexity: O(1). super-egg-drop(hard) First, my intuition is to binary search. However, it is correct only when K is large enough. Then, I thought a dp solution: dp[i][j] = min(max(dp[i - 1][k], dp[i][j - k - 1])), O(k*n^2). However, it is O(n) for each state transition. Finally, I saw a elegant dp solution: dp[i][j] = 1 + dp[i - 1][j - 1] + dp[i][j - 1], where dp[i][j] means given i moves and j eggs, how many floors can be excluded. 1 means current floor, dp[i - 1][j - 1] means the egg is broken and move downstairs, dp[i][j - 1] means the egg is not broken and move upstairs. Time complexity: O(kn). Space complexity: O(kn). top-k-frequent-words(medium) Use a priority_queue to maintain the top k frequent words. The trick is to keep the least frequent words at the top. If the output order is not required, we can use the similar methods as finding the k-th largest number in O(n). Time complexity: O(n + klogk). Space complexity: O(n). valid-anagram(easy) Count the frequency of all letters. Time complexity: O(n). Space complexity: O(26).","categories":[],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://proverbs.github.io/tags/algorithm/"},{"name":"LeetCode","slug":"LeetCode","permalink":"https://proverbs.github.io/tags/LeetCode/"}]},{"title":"[Leetcode]collection-2018-12-24","slug":"Leetcode-collection-2018-12-24","date":"2018-12-24T18:15:13.000Z","updated":"2021-05-30T16:25:43.046Z","comments":true,"path":"2018/12/24/Leetcode-collection-2018-12-24/","link":"","permalink":"https://proverbs.github.io/2018/12/24/Leetcode-collection-2018-12-24/","excerpt":"My code can be viewed in my github: Proverbs Github. The following difficulty is defined by myself. add-digits(easy) Time complexity: It is hard to tell, I think it should be O(num_of_digits). Space complexity: O(1). add-two-numbers-ii(medium) It is easy if we can modify the structure of the linked lists: we can reverse and add these two linked lists and then reverse back. Without changing the structure, we should first align these two linked lists and then concatenate the remaining part. A trick is to ignore the carry numbers when adding two linked list and to handle carry numbers after concatenation. Time complexity: O(n). Space complexity: O(n).","text":"My code can be viewed in my github: Proverbs Github. The following difficulty is defined by myself. add-digits(easy) Time complexity: It is hard to tell, I think it should be O(num_of_digits). Space complexity: O(1). add-two-numbers-ii(medium) It is easy if we can modify the structure of the linked lists: we can reverse and add these two linked lists and then reverse back. Without changing the structure, we should first align these two linked lists and then concatenate the remaining part. A trick is to ignore the carry numbers when adding two linked list and to handle carry numbers after concatenation. Time complexity: O(n). Space complexity: O(n). binary-tree-vertical-order-traversal(medium) BFS. It is easy to use map to handle negative index although it may increase time complexity. The best way is to use doubly linked list or calculate the left-most depth and the right-most depth using dfs. Time complexity: O(nlogn), but can be optimized to O(n). Space complexity: O(nlogn). intersection-of-two-arrays(easy) If the result should be in order according to nums1, we can binary serach nums2. Or we can use map directly. Time complexity: O(nlogn). Space complexity: O(n). max-stack(hard) Again, I made some mistake using iterator. And finally, I replace iterator with linked list. Use linked list as the underlying data structure of stack. At the same time, we should maintain a priority_queue to retrieve the max element. A trick is to use lazy delete because we cannot find the corresponding element in the other data structure when removing from either priority_queue or stack. Time complexity: O(nlogn). Space complexity: O(n). word-search-ii(medium) DFS in the trie and board at the same time. However, in the worst case, it is the same as brute force because the number of nodes in the trie can be the same as total number of letters of all words. Time complexity: O(lengthwidthn*m) where m is the average length of letters. Space complexity: O(nm+lengthwidth). pour-water(hard) The simplest way is to do as shown in the description. However, we can find that for the left side, the only thing we need to do is to find the right-most smallest number in the non-decreasing sequence left to index K. This can be maintained using a priority_queue. The key point is to store the left-most position the priority_queue has reached which is mono-decreasing. For the right side, it is the same as the left side. Time complexity: O(VlogN). Space complexity: O(N).","categories":[],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://proverbs.github.io/tags/algorithm/"},{"name":"LeetCode","slug":"LeetCode","permalink":"https://proverbs.github.io/tags/LeetCode/"}]},{"title":"[Leetcode]collection-2018-12-23","slug":"Leetcode-collection-2018-12-23","date":"2018-12-23T20:15:43.000Z","updated":"2021-05-30T16:25:43.046Z","comments":true,"path":"2018/12/23/Leetcode-collection-2018-12-23/","link":"","permalink":"https://proverbs.github.io/2018/12/23/Leetcode-collection-2018-12-23/","excerpt":"My code can be viewed in my github: Proverbs Github. The following difficulty is defined by myself. backspace-string-compare(easy) Stack. binary-tree-right-side-view(medium) DFS. First, compute the depth of all subtrees. Second, for each subtree, decide which layers of its left subtree and its right subtree should be displayed. clone-graph(easy) It will be easy if we can use map to check if we have visited a node. convert-binary-search-tree-to-sorted-doubly-linked-list(medium) Convert the tree to doubly linked list recursively.","text":"My code can be viewed in my github: Proverbs Github. The following difficulty is defined by myself. backspace-string-compare(easy) Stack. binary-tree-right-side-view(medium) DFS. First, compute the depth of all subtrees. Second, for each subtree, decide which layers of its left subtree and its right subtree should be displayed. clone-graph(easy) It will be easy if we can use map to check if we have visited a node. convert-binary-search-tree-to-sorted-doubly-linked-list(medium) Convert the tree to doubly linked list recursively. find-duplicate-file-in-system(easy) Map. find-the-closest-palindrome(hard) First, find the first larger palindromic number. Then, find the first less palindromic number. Finally, select the closer number. first-unique-character-in-a-string(easy) Save how many times and where a letter occurs. jump-game-ii(medium) The straightforward way is to convert it to a graph by connecting node i to the following nums[i] nodes and convert it to a shortest path problem. However, its time complexity is high. According to the idea of modify the distances, we can find the distances never decrease from left to right. That means we do not to modify the distance of the node we have modified and the time complexity will be O(1). lfu-cache(hard) It is a typical problem. O(1) get -&gt; hashtable, O(1) modification(+1/-1) to maintain order -&gt; linked list. I am not familiar with stl::list, so it takes me a lot of time to debug because of the operation erase which may free the memory of the erased element. minimize-malware-spread(medium) Find the largest group with only one infected node. most-common-word(easy) nested-list-weight-sum-ii(easy) DFS. However, the description is problematic because it does not tell what if the depth of the left child is different from that of the right child. remove-linked-list-elements(easy) Remove element from linked list recursively.","categories":[],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://proverbs.github.io/tags/algorithm/"},{"name":"LeetCode","slug":"LeetCode","permalink":"https://proverbs.github.io/tags/LeetCode/"}]},{"title":"[Leetcode]collection-2018-12-22","slug":"Leetcode-collection-2018-12-22","date":"2018-12-22T18:51:00.000Z","updated":"2021-05-30T16:25:43.046Z","comments":true,"path":"2018/12/22/Leetcode-collection-2018-12-22/","link":"","permalink":"https://proverbs.github.io/2018/12/22/Leetcode-collection-2018-12-22/","excerpt":"My code can be viewed in my github: Proverbs Github. The following difficulty is defined by myself. exclusive-time-of-functions(medium) DFS of partitions. Be clear about the return value you defined. flatten-nested-list-iterator(hard) Empty nested array makes it much more complicated because you could find no value when you go into the deeper dimension and then you should go back to shallower dimension. Another key point is that NestedInteger and vector&lt;NestedInteger&gt; can mess us up. k-empty-slots(medium) It is quite a typical problem of reverse thinking. We cannot find and insert a node to a linked list in O(1) time using common thinking. However, use reverse thinking, we can do it. multiply-strings(medium) High-precision multiplication. Do it as how we calculate the multiplication manually.","text":"My code can be viewed in my github: Proverbs Github. The following difficulty is defined by myself. exclusive-time-of-functions(medium) DFS of partitions. Be clear about the return value you defined. flatten-nested-list-iterator(hard) Empty nested array makes it much more complicated because you could find no value when you go into the deeper dimension and then you should go back to shallower dimension. Another key point is that NestedInteger and vector&lt;NestedInteger&gt; can mess us up. k-empty-slots(medium) It is quite a typical problem of reverse thinking. We cannot find and insert a node to a linked list in O(1) time using common thinking. However, use reverse thinking, we can do it. multiply-strings(medium) High-precision multiplication. Do it as how we calculate the multiplication manually. remove-comments(easy) Easy but should be careful to some corner cases. remove-k-digits(medium) It is also a typical problem using mono-increasing stack to remove digits. Another similar problem is to output the greatest number by concatenating a set of numbers. The solution is to compare each pair of two numbers by concatenating them in two different ways. reorder-list(medium) Linked list operation: split + reverse + merge. subdomain-visit-count(easy) Brute force with map. text-justification(easy) Just be careful with some corner cases.","categories":[],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://proverbs.github.io/tags/algorithm/"},{"name":"LeetCode","slug":"LeetCode","permalink":"https://proverbs.github.io/tags/LeetCode/"}]},{"title":"[Leetcode]collection-2018-12-21","slug":"Leetcode-collection-2018-12-21","date":"2018-12-21T07:39:20.000Z","updated":"2021-05-30T16:25:43.046Z","comments":true,"path":"2018/12/20/Leetcode-collection-2018-12-21/","link":"","permalink":"https://proverbs.github.io/2018/12/20/Leetcode-collection-2018-12-21/","excerpt":"My code can be viewed in my github: Proverbs Github. The following difficulty is defined by myself. 3sum-closest(medium) The same as the two pointers method of 3-sum. add-binary(easy) Same mechanism as high-precision calculation. basic-calculator(hard) It is a quite typical problem using two stacks. However, each time I tried to solve this problem, I cannot get it accepted at my first submission. A trick to simplify the implementation is to define the priority of operators. Another trick is how to handle negative numbers. It can be simplify our code if we combine the - with the following number rather than regard it as a operator. 1234wt['+'] = wt['-'] = 1;wt['*'] = wt['/'] = 2;wt['('] = -1;wt[')'] = 0; consecutive-numbers-sum(easy) Math: formula for sum of arithmetic progression.","text":"My code can be viewed in my github: Proverbs Github. The following difficulty is defined by myself. 3sum-closest(medium) The same as the two pointers method of 3-sum. add-binary(easy) Same mechanism as high-precision calculation. basic-calculator(hard) It is a quite typical problem using two stacks. However, each time I tried to solve this problem, I cannot get it accepted at my first submission. A trick to simplify the implementation is to define the priority of operators. Another trick is how to handle negative numbers. It can be simplify our code if we combine the - with the following number rather than regard it as a operator. 1234wt['+'] = wt['-'] = 1;wt['*'] = wt['/'] = 2;wt['('] = -1;wt[')'] = 0; consecutive-numbers-sum(easy) Math: formula for sum of arithmetic progression. design-search-autocomplete-system(hard) A simplest method is to build a trie and search the whole current subtree when input() is called. This can be the same as brute force in the worst case. A better method is to maintain three hottest strings for all nodes in the trie. It is quite intuitive, but I there are many details in the implementation. Thus, I marked it as hard, although it is should be medium. insert-delete-getrandom-o1(medium) It is quite a typical problem. To implement O(1) random get, we can only use array. And to implement O(1) insert/remove, we can only use hashmap. So, the solution is straightforward: use hashmap to maintain the index of numbers in the array. minimum-cost-to-hire-k-workers(hard) The solution is not intuitive, and I thought for some time to find how to do it. First, we cannot do it using brute force. So, according to previous experiences, can we enumerate all ratios and then calculate the minimum cost for each ratio? The key point is how to calculate the minimum cost given a ratio. To calculate the cost, we should select K workers with the least quality from those whose ratios are less than current ratio. First thing went in my head is sort. Then, maintain workers whose ratios are less than current ratio, and select K workers with the least quality using priority_queue or heap. read-n-characters-given-read4-ii-call-multiple-times(easy) restore-ip-addresses(easy) reverse-nodes-in-k-group(medium) Operation of linked list. The basic idea is to split the linked list into many linked lists, reverse them and then connect them. To implement it in constant space makes it more complicate because we should cut constant pieces of linked list and then connect them before curring the remaining parts of the linked list. reverse-words-in-a-string(medium) The basic idea is to reverse the words and then reverse the whole string.","categories":[],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://proverbs.github.io/tags/algorithm/"},{"name":"LeetCode","slug":"LeetCode","permalink":"https://proverbs.github.io/tags/LeetCode/"}]},{"title":"[Leetcode]collection-2018-12-20","slug":"Leetcode-collection-2018-12-20","date":"2018-12-20T06:26:54.000Z","updated":"2021-05-30T16:25:43.046Z","comments":true,"path":"2018/12/19/Leetcode-collection-2018-12-20/","link":"","permalink":"https://proverbs.github.io/2018/12/19/Leetcode-collection-2018-12-20/","excerpt":"My code can be viewed in my github: Proverbs Github. The following difficulty is defined by myself. integer-to-english-words(medium) Divide the number into different parts according to the commas of writing a number. The most difficult part of the problem is various corner cases, such as when should we output Zero. alien-dictionary(medium) Most sort algorithms are based on comparison, so we can exploit lexicographical order by comparing two contiguous words. Then we can represent the relationship using graph and use topological sort to check if there is a loop in the graph. jewels-and-stones(easy) license-key-formatting(easy) meeting-rooms-ii(medium) As usual, sort the intervals by the start time. Use current rooms as possible as we can. When there is no room available, we should add a new room. So, the problem is how to judge if there is an available room. At first, I tried to use set and binary search. Then, add current interval to the searched room. Sure it is correct. However, we can find the room which ends earliest and add current interval to this room. It is corret because the following intervals start later then current interval and all available rooms for current interval are also available for the following intervals. Thus, we can add current interval to any one of the available rooms.","text":"My code can be viewed in my github: Proverbs Github. The following difficulty is defined by myself. integer-to-english-words(medium) Divide the number into different parts according to the commas of writing a number. The most difficult part of the problem is various corner cases, such as when should we output Zero. alien-dictionary(medium) Most sort algorithms are based on comparison, so we can exploit lexicographical order by comparing two contiguous words. Then we can represent the relationship using graph and use topological sort to check if there is a loop in the graph. jewels-and-stones(easy) license-key-formatting(easy) meeting-rooms-ii(medium) As usual, sort the intervals by the start time. Use current rooms as possible as we can. When there is no room available, we should add a new room. So, the problem is how to judge if there is an available room. At first, I tried to use set and binary search. Then, add current interval to the searched room. Sure it is correct. However, we can find the room which ends earliest and add current interval to this room. It is corret because the following intervals start later then current interval and all available rooms for current interval are also available for the following intervals. Thus, we can add current interval to any one of the available rooms. next-closest-time(easy) Numerate all possible time using brute force and then check if the time is correct. A trick is to add a big number to the time of the next day. palindrome-number(easy) Convert a number to a string using sprintf. reverse-string(easy) unique-email-addresses(easy) binary-search-tree-iterator(medium) I always use a iterator to traverse a set or map, however, I never think about the implementation. The simplest idea is to simulate the stack of traversing. Sure it is correct. But when I was exploring the discussions, I found a more elegant method: pop the node from the stack when walking into its right child. fizz-buzz(easy) friend-circles(easy) Use DFS to find number of blocks of connected nodes. longest-substring-with-at-most-two-distinct-characters(medium) Use double pointers to maintain a sliding window. First, move the left pointer and then move the right pointer. max-area-of-island(easy) Similar to friend-circles. Use DFS to traverse the whole 2D graph. utf-8-validation(easy) Be careful.","categories":[],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://proverbs.github.io/tags/algorithm/"},{"name":"LeetCode","slug":"LeetCode","permalink":"https://proverbs.github.io/tags/LeetCode/"}]},{"title":"[Review]LeetCode Top 100 Liked Questions(1)","slug":"Review-LeetCode-Top-100-Liked-Questions-1","date":"2018-03-20T02:39:12.000Z","updated":"2021-05-30T16:25:43.056Z","comments":true,"path":"2018/03/19/Review-LeetCode-Top-100-Liked-Questions-1/","link":"","permalink":"https://proverbs.github.io/2018/03/19/Review-LeetCode-Top-100-Liked-Questions-1/","excerpt":"[Review]LeetCode Top 100 Liked Questions(1) 所有代码可以在github上下载：https://github.com/proverbs/LTC 以下难易度评级为个人评级，非官方评级 个人认为比较有代表性的题目，标题将加粗","text":"[Review]LeetCode Top 100 Liked Questions(1) 所有代码可以在github上下载：https://github.com/proverbs/LTC 以下难易度评级为个人评级，非官方评级 个人认为比较有代表性的题目，标题将加粗 Two Sum[easy] https://leetcode.com/problems/two-sum/description/ 从左向右扫，维护当前位置左侧的数字是否出现过（hashmap实现） Add Two Numbers[easy] https://leetcode.com/problems/add-two-numbers/description/ 链表对应位置直接相加 Longest Substring Without Repeating Characters[medium] https://leetcode.com/problems/longest-substring-without-repeating-characters/description/ 双指针确定滑窗位置，set维护滑窗中字母是否出现。熟悉这种套路之后这题也是easy Median of Two Sorted Arrays[easy] https://leetcode.com/problems/median-of-two-sorted-arrays/description/ 归并排序的数组合并方法 Longest Palindromic Substring[hard] https://leetcode.com/problems/longest-palindromic-substring/description/ 暴力O(n^2)可以过 我用的二分+区间hash（需要手写，如果怕重复，可以多重hash），O(nlogn) 还有O(n)的方法，Manacher 算法 Regular Expression Matching[hard] https://leetcode.com/problems/regular-expression-matching/description/ dp[i][j]表示s的前i个和p的前j个匹配是否可行，但是恶心在条件转移非常复杂，需要考虑各种情况 Container With Most Water[hard] https://leetcode.com/problems/container-with-most-water/description/ 一开始没有思路。考虑构成最大容器的左右边界，如果一个边它的左右两侧都有比它高的边，那么它不可能构成最大容器，所以可以删除。那么，最终剩下的所有边界构成单峰形。考虑i,j两条边构成的容器，其中较短的向中间移动则构成的新容器可能会更大，但是如果较长的向中间移动，则构成的新容器必然更小。所以得到贪心策略。最终做法，如果不删边对算法也不会有影响。 3Sum[easy] https://leetcode.com/problems/3sum/description/ 和2sum一样，a+b=-c，枚举c，然后用2sum的方法求解 Letter Combinations of a Phone Number[easy] https://leetcode.com/problems/letter-combinations-of-a-phone-number/description/ dfs Remove Nth Node From End of List[easy] https://leetcode.com/problems/remove-nth-node-from-end-of-list/description/ 指针操作 Valid Parentheses[easy] https://leetcode.com/problems/valid-parentheses/description/ 非常经典，通用的括号匹配方法——使用栈匹配 Merge Two Sorted Lists[easy] https://leetcode.com/problems/merge-two-sorted-lists/description/ 归并排序的合并思想 Generate Parentheses[east] https://leetcode.com/problems/generate-parentheses/description/ dfs Merge k Sorted Lists[easy] https://leetcode.com/problems/merge-k-sorted-lists/description/ 和Merge Two Sorted Lists类似，只不过想要快速的比较k个队头元素的大小需要使用优先队列或者堆这类数据结构。 代码里有heap的简单使用方式。 Next Permutation[easy] https://leetcode.com/problems/next-permutation/description/ 从右向左，找第一个下降的数字，然后从这个数字到结尾排序 Longest Valid Parentheses[hard] https://leetcode.com/problems/longest-valid-parentheses/description/ 利用之前提到的栈的括号匹配方法，只不过栈中还要保存这个括号的下标 还可以用dp[i]表示以i开头的最长匹配括号串长度，可由dp[i + 1]转移 Search in Rotated Sorted Array[easy] https://leetcode.com/problems/search-in-rotated-sorted-array/description/ 很经典的题。二分查找先找出断点位置，然后再二分查找需要的数字 Search for a Range[easy] https://leetcode.com/problems/search-for-a-range/description/ 二分查找，找不小于target+1的第一个数字，再找不小于target的第一个数字 Combination Sum[easy] https://leetcode.com/problems/combination-sum/description/ 爆搜 Trapping Rain Water[hard] https://leetcode.com/problems/trapping-rain-water/description/ 题目中的图给人启发：每个点的水位高度=min(这个点左侧最大值，这个点右侧最大值) 这两个最大值可以从左右两遍dp一下就可以了 Permutations[easy] https://leetcode.com/problems/permutations/description/ 按字典序暴搜 Rotate Image[medium] https://leetcode.com/problems/rotate-image/description/ 我写的方法超级麻烦，不说了。 比较好的方法是，既然我们会沿主对角线翻转，那么沿副对角翻转=水平翻转+沿主对角线翻转+水平翻转 Group Anagrams[easy] https://leetcode.com/problems/group-anagrams/description/ sort Maximum Subarray[easy] https://leetcode.com/problems/maximum-subarray/description/ 最简单的dp Jump Game[easy] https://leetcode.com/problems/jump-game/description/ 维护一个最远可达位置 Merge Intervals[easy] https://leetcode.com/problems/merge-intervals/description/ sort+维护最远可达位置 Unique Paths[easy] https://leetcode.com/problems/unique-paths/description/ dp或者直接组合数计算 Minimum Path Sum[easy] https://leetcode.com/problems/minimum-path-sum/description/ 这个题本身很水，dp。 但这题有个拓展——传纸条问题，也就是两条不同路径，sum最小。dp[k][i][j]表示走了k步，其中向下走了i步和j步的两个位置到左上角的sum最小值。 Climbing Stairs[easy] https://leetcode.com/problems/climbing-stairs/description/ dp Edit Distance[medium] https://leetcode.com/problems/edit-distance/description/ dp[i][j]表示word1前i个和word2前j个匹配的最小距离，对于每个位置，根据3种操作有3种转移方式。 Sort Colors[medium] https://leetcode.com/problems/sort-colors/description/ 第一种方法，统计每个数字的个数，然后在数组中直接填充； 第二种方法，从左向右扫描，动态更新每个数字下一个可插入位置的下标 Minimum Window Substring[medium] https://leetcode.com/problems/minimum-window-substring/description/ 双指针确定滑窗位置，set维护滑窗中字母是否出现。和Longest Substring Without Repeating Characters一样 Subsets[easy] https://leetcode.com/problems/subsets/description/ 2^n爆搜 Word Search[easy] https://leetcode.com/problems/word-search/description/ 爆搜 Largest Rectangle in Histogram[hard] https://leetcode.com/problems/largest-rectangle-in-histogram/description/ 很经典的stack应用。 枚举i作为面积的最高度，只需要知道左右两侧比h[i]小的第一个的位置。用stack维护单调减的队列即可。 Maximal Rectangle[hard] https://leetcode.com/problems/maximal-rectangle/description/ 和上一道题一样，先枚举一下矩形区域的底部坐标即可 Binary Tree Inorder Traversal[easy] https://leetcode.com/problems/binary-tree-inorder-traversal/description/ dfs。 为什么加粗，是因为可以思考一下如何用非递归形式实现3种遍历。（我不管，反正我用手工栈） Unique Binary Search Trees[medium] https://leetcode.com/problems/unique-binary-search-trees/description/ 类似区间dp Validate Binary Search Tree[easy] https://leetcode.com/problems/validate-binary-search-tree/description/ 第一种方法，递归直接判断； 第二种方法，中序遍历是否有序 Symmetric Tree[easy] https://leetcode.com/problems/symmetric-tree/description/ 树形结构上的题一般都递归做 Binary Tree Level Order Traversal[easy] https://leetcode.com/problems/binary-tree-level-order-traversal/description/ 树的bfs Maximum Depth of Binary Tree[easy] https://leetcode.com/problems/maximum-depth-of-binary-tree/description/ dfs Construct Binary Tree from Preorder and Inorder Traversal[medium] https://leetcode.com/problems/construct-binary-tree-from-preorder-and-inorder-traversal/description/ 根据先序遍历确定根，然后根据中序遍历确定左右子树节点，递归构造 Flatten Binary Tree to Linked List[medium] https://leetcode.com/problems/flatten-binary-tree-to-linked-list/description/ 使用递归函数：将子树化为链表，并返回链表首尾指针 Best Time to Buy and Sell Stock[easy] https://leetcode.com/problems/best-time-to-buy-and-sell-stock/description/ 动态维护当前最小值 Binary Tree Maximum Path Sum[easy] https://leetcode.com/problems/binary-tree-maximum-path-sum/description/ 如果是多叉树，需要两次dp，分别算出节点向下的最大和第二大路径长度。 而二叉树则确定了最大和第二大路径长度：左子树最大路径长度和右子树最大路径长度（或者相反），所以更简单 Longest Consecutive Sequence[medium] https://leetcode.com/problems/longest-consecutive-sequence/description/ dp+hashmap Single Number[medium] https://leetcode.com/problems/single-number/description/ 这里只讨论不用额外空间的做法：异或 Word Break[medium] https://leetcode.com/problems/word-break/description/ 注意这个题不可以搜索和贪心匹配，所以需要使用dp Linked List Cycle[hard] https://leetcode.com/problems/linked-list-cycle/description/ 以下解都不使用额外空间！真的有难度，反正我是想不到。 原题解：2个指针，其中一个每次移动1步，另一个每次移动2步，有环则必然相遇。 拓展1：求环的起点 拓展1解：设链表头到环的起点有x步，相遇点距环起点b步，环长s；则2k=x+ns+b, k=x+ms+b；相减2k-k = k = (n-m)s=x+ms+b；则x+b=(n-2m)s；也就是说从环起点走x+b步可以回到环起点；也就是说从链表头走x+(x+b)步可以到环起点；所以从相遇点走x步可到环起点。但是环起点未知，所以使用第3个指针从链表头开始，与相遇点指针每次移动1步，相遇时则为环起点。 拓展2：数组长度0-n(共n+1个数字)，每个数字为1-n中的一个，求重复数字 拓展2解：这样的数组其实是链表！！解法和拓展1相同。","categories":[],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://proverbs.github.io/tags/algorithm/"},{"name":"LeetCode","slug":"LeetCode","permalink":"https://proverbs.github.io/tags/LeetCode/"}]},{"title":"Hexo-Deploy-Backup","slug":"Hexo-Deploy-Backup","date":"2018-02-09T22:10:25.000Z","updated":"2021-05-30T16:25:43.046Z","comments":true,"path":"2018/02/09/Hexo-Deploy-Backup/","link":"","permalink":"https://proverbs.github.io/2018/02/09/Hexo-Deploy-Backup/","excerpt":"Hexo部署与备份 安装 参考官网教程 重要插件 hexo-admin，管理本地post hexo-deployer-git，使用git进行部署 部署与备份 hexo_gen_deploy文件夹（origin：proverbs.github.io仓库）：负责生成+部署 hexo_backup文件夹（origin：HexoBackup仓库）：负责备份，其中备份脚本为：backup.sh（放在hexo_backup文件夹中）","text":"Hexo部署与备份 安装 参考官网教程 重要插件 hexo-admin，管理本地post hexo-deployer-git，使用git进行部署 部署与备份 hexo_gen_deploy文件夹（origin：proverbs.github.io仓库）：负责生成+部署 hexo_backup文件夹（origin：HexoBackup仓库）：负责备份，其中备份脚本为：backup.sh（放在hexo_backup文件夹中） 12345678#!/bin/sh# clear dirrm -rf !deploy.sh# backup hexo blogcp -R /home/proverbs/hexo/hexo_gen_deploy/* ./git add -Agit commit -m \"Blog update on: `date +%F`\"git push origin master","categories":[],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://proverbs.github.io/tags/hexo/"}]},{"title":"Deep-Leaning-DeepID","slug":"Deep-Leaning-DeepID","date":"2017-08-01T23:27:34.000Z","updated":"2021-05-30T16:25:43.046Z","comments":true,"path":"2017/08/01/Deep-Leaning-DeepID/","link":"","permalink":"https://proverbs.github.io/2017/08/01/Deep-Leaning-DeepID/","excerpt":"DeepID学习笔记 参考文献 Deep Learning Face Representation from Predicting 10,000 Classes（DeepID1） Deep Learning Face Representation by Joint Identification-Verification（DeepID2） Deeply learned face representations are sparse, selective, and robust（DeepID2+） DeepID3: Face Recognition with Very Deep Neural Networks（DeepID3） DeepID1 0. Abstract 目标是提取Deep hidden IDentity features(DeepID)，这是在神经网络较高的一层所表示的特征，论文利用DeepID层提取的特征进行进行face verification（给两张人脸，判断是不是一个人） 1. Introduction 一般的，神经网络是使用二值verification信号（是或否）作为监督信号训练网络。但是本文使用identification信号（多分类，类别达10000）作为监督信号提取个体特征 模型的思想大概是：**将一张人脸切分成多个patch，然后每个patch训练一个网络产生多个网络。然后将多个网络的特征压缩到160维，作为整个人的特征。**具体的做法将在后面部分详述。 这160维的特征是high-level的（一般非深度学习提取的特征属于low-level的，如LBP），可以使用Joint Bayesian（联合贝叶斯）和NN（神经网络）等任意分类器对特征进行分类。后文也将给出联合贝叶斯和神经网络的比较 这种模型对于weakly aligned faces也可以达到很高的verification正确率","text":"DeepID学习笔记 参考文献 Deep Learning Face Representation from Predicting 10,000 Classes（DeepID1） Deep Learning Face Representation by Joint Identification-Verification（DeepID2） Deeply learned face representations are sparse, selective, and robust（DeepID2+） DeepID3: Face Recognition with Very Deep Neural Networks（DeepID3） DeepID1 0. Abstract 目标是提取Deep hidden IDentity features(DeepID)，这是在神经网络较高的一层所表示的特征，论文利用DeepID层提取的特征进行进行face verification（给两张人脸，判断是不是一个人） 1. Introduction 一般的，神经网络是使用二值verification信号（是或否）作为监督信号训练网络。但是本文使用identification信号（多分类，类别达10000）作为监督信号提取个体特征 模型的思想大概是：**将一张人脸切分成多个patch，然后每个patch训练一个网络产生多个网络。然后将多个网络的特征压缩到160维，作为整个人的特征。**具体的做法将在后面部分详述。 这160维的特征是high-level的（一般非深度学习提取的特征属于low-level的，如LBP），可以使用Joint Bayesian（联合贝叶斯）和NN（神经网络）等任意分类器对特征进行分类。后文也将给出联合贝叶斯和神经网络的比较 这种模型对于weakly aligned faces也可以达到很高的verification正确率 2. Related Work 太多了，见论文相关章节吧 3. Learning DeepID for face verification DeepID网络结构，见Figure 2。着重注意Max-pooling layer 3、Convolutional layer 4和DeepID layer，从图中看出Max-pooling layer 3和Convolutional layer 4是通过concatenate的方式形成的DeepID层（这点论文中并没有提到）。最后，DeepID层全连接到Soft-max层做分类 作者这样连接的目的是：高维的卷积层面临信息瓶颈的问题（神经元太少），使用低维卷积层提取的特征可以补充高维卷积层提取的特征，且这个特征是多尺度的（multi-scale），这个网络也称为multi-scale ConvNets 形成的特征一定要比类别少很多，这样才能体现出用特征做预测的价值 这里详细解释如何切分为60个patch：一个人脸图片按照左右眼为中心、最右嘴角为中心、鼻尖为中心切分成5部分，这5部分又有3中不同的尺度，这样就有15种patch了。然后因为图片是RGB通道的，所有按照3个通道可以形成45中patch；在加上15个gray通道的patch，最终一共是60个patch。60个patch每个都训练一个DeepID网络。以上部分可以参考一下Figure 3，但个人觉得看了也没什么用，只是一种切分patch的思想。 特征提取：通过上面的patch切分，我们现在有60个DeepID网络了。对于一张图片，我们用同样的方法切分成60个patch，通过60个网络，得到60* 160维的特征。然后将60个patch水平翻转，同理又得到60* 160维的特征。将两个特征合在一起，得到60* 160* 2维的特征 为了verification，作者这里使用的分类模型是Joint Bayesian和NN。关于Joint Bayesian，大致思想是人脸特征服从两个高斯分布（不同identity之间的差异和相同identity的不同图片之间的差异）的和，最终转换为用类EM算法求协方差矩阵的问题，更详细的内容要参考之前关于Bayesian Face的相关论文（这部分我也没有完全理解其数学推导，等学会了，我会整理一篇冠以Bayesian Face的学习笔记）。关于NN，输入层有60组，每组包含两个人脸的2个patch及其水平翻转；然后每个patch有160维特征，所以每组总共640维特征。两个隐含层分别是locally connected和fully-connected，分别用来学习同组两个patch之间的关系（顺便降低特征维度，减少训练参数）和综合所有关系。详见Figure 4 NN的训练方法参数还是太多了，为了解决梯度弥散的问题，在隐层后面加入Dropout（input层后面不加），并预训练参数初始化权值 4. Experiments 使用CelebFaces（CelebFaces+）训练DeepID网络，使用LFW测试结果。 作者用实验证明，multi-scale ConvNets（多尺度卷积网络）比普通的CNN能学习到更有效的特征。见Figure 5 作者发现：在同样维度（160维）的特征表示下，随着类别增加，错误率下降。见Figure 6和Figure 7 作者发现：对于160维的DeepID层，同一个人在DeepID层的神经元响应的相似度更高，不同人响应相似度低。这再次证明了DeepID层提取的特征非常有效。见Figure 8 作者又研究了patch不同取值对正确率的影响：patch越多正确率越高。见Figure 9 作者又将论文中的方法和其他方法进行了比较。见Figure 10 5. Conclusion and Discussion 论文提出了一种有效提取不同个体high-level的人脸特征的方法 DeepID2 0. Abstract face recognition的关键得到一种特征表示，intra-personal之间差距小，inter-personal之间差距大。根据这个思想，作者提出了使用verification（减小intra-personal之间差距）和identification（增加inter-personal之间差距）两种监督信号训练模型 1. Introduction identification信号用于拉开不同identity之间的特征差距，使得不同人提取的特征有rich identity-related（inter-personal）variation；与identification互补，使用verification信号减小相同identity之间的特征差距 使用不同区域、不同分辨率的图片，提取特征。然后将这些特征连接起来，再用PCA降维，使用Joint Bayesian的方法做verification 2. Identification-verification guided deep feature learning 网络结构与DeepID1类似，但是**（1）第三和第四个卷积层局部权值共享**（不懂？），（2）DeepID2层是第三和第四层通过Dense（全连接）层之后的add（原文没说是add，但是理解起来应该是add），Dense和DeepID2后要加入ReLU，见Figure 1 Identification信号：cross-entropy loss。θid\\theta_{id}θid​ 是指隐层参数 Verification信号：L2范数规范化后的特征。θve\\theta_{ve}θve​ 是指softmax层参数 Verification信号可以改写成如下表达式 训练方法：每次抽取两个样本（不是按照batch训练了），对identification和verification信号的梯度加权，再用梯度下降更新。见Table 1 3. Face Verification 作者基于SDM算法搞出了400个patch（在位置、尺寸、颜色通道和水平翻转上各有不同），400个patch训练出200个网络（水平翻转使用同一个网络），每个网络提取160维特征。不同于DeepID1中用PCA降维，这里使用forward-backward greedy算法从400个特征向量中选择25个（每个向量对应一个patch）。再用PCA对25* 160的向量降维。最终使用Joint Bayesian做verification。 4. Experiments 训练过程：（1）用CelebFaces+A训练，CelebFaces+B验证，从而调整模型的lr、epoch、和参数λ\\lambdaλ ；（2）用CelebFaces+B一部分训练网络权值，另一部分验证；（3）用整个CelebFaces+B训练Joint Bayesian，用LFW测试（为什么要这样训练？） 参数λ\\lambdaλ （控制identification和verification权重的参数）对实验结果的影响：参数λ\\lambdaλ 为0.05时（identification为1，verification为0.05），效果最好，见Figure 3。作者用LDA中的inter- and intra-personal variations解释了参数选择的原因（暂时还没有懂），见图Figure 5。 作者还发现，和DeepID1一样，用于训练的类别数越多，模型准确率越高，见Figure 4 作者调查了verification的作用：在相同的identification信号下，降低类内距离且增加类间距离的L2效果最好。见Table 2 对patch数和模型准确率的关系的研究：见Table 3。最终模型选择了25个patch 与其他模型做了比较：使用SVM将过个Joint Bayesian融合，创造了state-of-the-art 5. Conclusion 用identification和verification两种信号监督训练的模型准确率很高 DeepID2+ 0. Abstract 相比DeepID2，增加隐含层的尺寸，在较低的层次加入监督信号 对神经元进行深入研究，实验发现：神经元的激活特性有稀疏性（激活神经元稀疏；用二值信号表示激活效果也很好）、选择性（更高层的神经元对不同的identity激活或抑制区分明显）、鲁棒性（训练中无遮挡数据，但测试时对遮挡鲁棒） 1. Introduction 稀疏性：（1）对于一个图片，DeepID层有一半左右的神经元被激活；对于一个神经元，只对一半左右的图片处于激活状态。（2）使用二值表示的激活状态作为人脸特征进行verification准确率只下降了1%，也就提出了一种非常高效（时间+空间）的人脸表示方法 选择性：对于同一个人的不同图片，总有一部分神经元是一直处于激活状态的，还有一部分一直处于抑制状态。说明，虽然模型并没有明确的让DeepID层提取特征，但是这层“偷偷”学到的特征已经比LBP更适合分类了 鲁棒性：对于遮挡，神经元激活状态几乎一样（然后激活程度有些差别）。作者认为，高层次的神经元可能已经拥有获取全局特征的能力了（只是基于实验现象的猜想） 以上三种特性对应实验中的现象，见Figure 1（这图不用仔细看，后面部分会更详细的解释） 2. Related work 详见论文，不再一一列举 3. DeepID2+ nets DeepID2+继承自DeepID2网络，但主要有3点区别：（1）DeepID2+的feature maps（filters）提高到128个，最后一层的DeepID层扩大到512维；（2）训练数据量更大，包括CelebFaces+、WDRef和其他一些数据；（3）在4个卷积层的后面都加入一个512维的全连接层，并对每一层都加入identification和verification监督信号。见Figure 2。这里我认为图画的不是很好，FC-4应该是全连接到Conv-3和Conv-4的（就像DeepID2中一样），这里图中并没有画出来。 根据DeepID3的论文，作者这里已经改变了DeepID2的结构，但是在论文中没有提到，真实的结构就像图中画的一样 4. High-performance of DeepID2+ nets 训练方法，和DeepID2相同。选DeepID2中选定的25个patch，用FC-4作为特征，同样用Joint Bayesian训练，最终得到每个patch的verification准确率都高于DeepID2。见Figure 3 在和其他模型的比较，见Table 1, Table 2, Table 3 5. Moderate sparsity of neural activations 作者认为这种moderate sparsity使得特征有最大化的表达差异的能力 用实验现象解释稀疏性：对于一个图片，DeepID层有一半左右的神经元被激活；对于一个神经元，只对一半左右的图片处于激活状态。见Figure 6 用实验结果证明二值化的特征依旧有很好的表达能力 6. Selectiveness on identities and attributes 通过实验证明，DeepID2+的FC-4层的特征和高维LBP相比，可以更好的表示属性与个体。见Figure 7 通过实验证明： 看前两列：DeepID2特征对于一个人激活程度高时；则对于其他的人，激活程度相对较低（一定程度上证明了选择性） 看第三列：且对于同一个人的不同图片，平均激活程度较高（或者较低）的神经元，单单用这个神经元的激活程度+阈值就可以有很高的正确率（输入一张图片，判断是不是某个特定的人）。见Figure 10，其中神经元按第一列的激活平均值（对指定人的激活平均值）排序 实验证明：特征对于不同的人有很好的选择性。见Figure 12，随机选择了5个神经元。 试验证明：对于类中的一个属性激活，则对应同类的其他属性就会抑制。见Figure 13，其中神经元是选择了5个判断准确率最高的神经元。 7. Robustness of DeepID2+ features 实验证明，无论哪个FC层的特征，其面对遮挡的鲁棒性都优于高维LBP特征。见Figure 15 即使面对大面积的遮挡，DeepID2+特征仍然有较高的准确率 8. Conclusion 基于实验，DeepID2+网络有更高的准确率 基于实验，DeepID2+网络有稀疏性、选择性和鲁棒性 基于实验，研究了神经元激活特性，帮助人们理解神经网络（虽然只是一些表层的结论） DeepID3 0. Abstract 在DeepID2+的基础上，借鉴了VGG net和GoogleNet，加深了网络层数，同样在每个中间层都使用identification+verification监督信号训练，分别训练了2个模型（基于VGG net和GoogleNet），达到了更高的准确率 1. Introduction 介绍了之前的网络结构，包括DeepID系列、VGG net和GoogleNet 2. DeepID3 net 这里作者在回顾DeepID2+的时候，又偷偷改变了网络结构：第三层卷积层变成了局部卷积层（在局部区域共享权重，什么意思？），第三个池化层后加入了一个局部连接层 ，见Figure 1 相比较DeepID2+，DeepID3更深。连续的conv或inception可以获得更大区域的更复杂的非线性表示；而局部连接层的权值不共享可以使用更低的维度表达更具有表达能力。2种网络结构，见Figure 2和Figure 3 训练方法和DeepID2+相同 3. Experiments 两种网络各提取总特征数的一半（同一种网络不能同时训练一个patch及其水平翻转），然后将特征拼在一起形成30000维的向量，然后PCA降维到300 DeepID3效果比DeepID2+效果好一点，见Table 1 4. Discussion 其实LFW中有一些错误标注的数据，当把这些错误修正后，DeepID3相比DeepID2+就没有提高了。原因未知。 作者分析了一下false negatives和false positives的图片对，错误来源主要是人确实长得比较像、或者有遮挡、或者化妆差距大 5. Conclusion 作者说这个模型更好，但我觉得这个文章相比前三篇DeepID系列，确实水了点… 后记 终于总结完DeepID系列的文章了，累死。 我最初的目的是写一个很简单的笔记，但不知道怎么的，写着写着就越写越细了。 可能是因为我在总结笔记的时候又发现了很多之前没有注意到的细节，想要写在笔记里提醒自己吧。 以后不能这样了，真的要总结精华，才是笔记的作用。","categories":[],"tags":[{"name":"Deep Learning - FER","slug":"Deep-Learning-FER","permalink":"https://proverbs.github.io/tags/Deep-Learning-FER/"}]},{"title":"Deep-Leaning-ResNet","slug":"Deep-Leaning-ResNet","date":"2017-07-27T00:39:39.000Z","updated":"2021-05-30T16:25:43.046Z","comments":true,"path":"2017/07/26/Deep-Leaning-ResNet/","link":"","permalink":"https://proverbs.github.io/2017/07/26/Deep-Leaning-ResNet/","excerpt":"ResNet学习笔记 相关论文 Deep Residual Learning for Image Recognition Identity Mappings in Deep Residual Networks ResNet基础 1.Abstract 显示地使用了残差函数作为训练目标 残差函数易于优化；增加深度网络准确率更高 2.Introduction 问题1：近来，有很多很深的神经网络模型取得了很好的效果。但是，单纯的增加层数就能训练出更好的网络吗？ 增加层数会遇到非常烦人的问题：梯度消失、梯度下降。解决方法是：初始化正则化、正则化层 问题2：烦人的问题解决了，但是实验证明，当深度增加时，训练效果反而更差，而这个更差的效果并不是因为过拟合造成的。这就表示深层的网络并不是那么好优化的。 作者提出了一种优化深层网络的方案：deep residual learning framework。一般的网络模型输入与输出本质上是一种函数映射关系，即H(x⃗)H(\\vec{x})H(x) 。我们训练权重就是为了逼近函数H(x⃗)H(\\vec{x})H(x) 。而作者提出训练权重去逼近残差函数F(x⃗)−x⃗F(\\vec{x})-\\vec{x}F(x)−x ，并提出假设：这种残差函数更容易逼近。 deep residual learning framework的构块见Figure 2。右边跨越层的连接称为shortcut connect。当F(x⃗)F(\\vec{x})F(x) 和 x⃗\\vec{x}x 维度相同时，网络不加入新的参数；维度不同时只会增加一个线性映射带来的参数。","text":"ResNet学习笔记 相关论文 Deep Residual Learning for Image Recognition Identity Mappings in Deep Residual Networks ResNet基础 1.Abstract 显示地使用了残差函数作为训练目标 残差函数易于优化；增加深度网络准确率更高 2.Introduction 问题1：近来，有很多很深的神经网络模型取得了很好的效果。但是，单纯的增加层数就能训练出更好的网络吗？ 增加层数会遇到非常烦人的问题：梯度消失、梯度下降。解决方法是：初始化正则化、正则化层 问题2：烦人的问题解决了，但是实验证明，当深度增加时，训练效果反而更差，而这个更差的效果并不是因为过拟合造成的。这就表示深层的网络并不是那么好优化的。 作者提出了一种优化深层网络的方案：deep residual learning framework。一般的网络模型输入与输出本质上是一种函数映射关系，即H(x⃗)H(\\vec{x})H(x) 。我们训练权重就是为了逼近函数H(x⃗)H(\\vec{x})H(x) 。而作者提出训练权重去逼近残差函数F(x⃗)−x⃗F(\\vec{x})-\\vec{x}F(x)−x ，并提出假设：这种残差函数更容易逼近。 deep residual learning framework的构块见Figure 2。右边跨越层的连接称为shortcut connect。当F(x⃗)F(\\vec{x})F(x) 和 x⃗\\vec{x}x 维度相同时，网络不加入新的参数；维度不同时只会增加一个线性映射带来的参数。 3. Related Work 关于残差表示：Vector of Locally Aggregated Descriptors (VLAD)、Fisher Vector 关于shortcut connect：在之前的论文中也有类似的，但是作者提出的shortcut是identity的，即没有参数的，是直连 4.Deep Residual Learning 作者认为残差学习的有点在于：当函数H(x⃗)H(\\vec{x})H(x) 趋近于自身映射（x⃗\\vec{x}x）时，训练F(x⃗)F(\\vec{x})F(x)更容易逼近0 对比普通的网络与残差网络：见Figure 3 普通CNN有两点设计原则：（1）feature map大小不变，则filter数量不变；（2）feature map大小减半，filter数量加倍——为了保证每层的运算复杂度不变（但是难道不应是乘4么？） 普通CNN最后加入global average pooling层、1000维full connect层（softmax） 残差网络只比普通的CNN多几条shorcut connect，对于shortcut connect维度（feature map和filter）不一致时的两种方法：（1）补零；（2）使用1*1带strides=2的卷积层映射 残差网络实现：在convolution和activation之间加入batch normalization(BN)；不使用dropout 几种不同深度的残差网络结构：见Table 1 5. Experiment 在ImageNet数据集上：证明resnet层数增加效果更好，而plain（普通网络）层数增加效果反而会变差。见Figure 4 在plain网络中，使用了BN，所以问题不出在收敛性上。而具体的原因，作者也无法解释。 18层plain和resnet结果相对接近，作者认为原因在于18层还不够深，体现不出resnet的优势；但是resnet相比plain具有更快的收敛速度 作者对比了不同的shortcut connect连接方法（直连称为identity，映射连接称为projection）：（A）维度不同时补零，相同时identity；（B）维度不同时使用projection，相同时identity；（C）全部projection 效果差距差距不大：（C）&gt;（B）&gt;（A），且都比plain好。 Deeper Bottleneck Architecture：见Figure 5。这三层分别是1* 1 、3* 3，和1* 1的卷积层，其中1* 1层负责先减少后增加（恢复）尺寸的，使3* 3层具有较小的输入和输出尺寸。这样增加了深度，且保持几乎一样的复杂度。经过试验，bottleneck效果更好，这也是ILSVRC 2015夺冠使用的设计。 在CIFAR10数据上对resnet进行分析： 继续对比了plain和resnet，结果和ImageNet的结果类似 分析每个卷积层的响应：见Figure 7。resnet的卷积层输出的标准差更小。作者试图通过这个说明当函数H(x⃗)H(\\vec{x})H(x) 趋近于自身映射（x⃗\\vec{x}x）时，训练F(x⃗)F(\\vec{x})F(x)更容易逼近0 。但是难道不应该再考察一下输出的平均值是不是接近0呢？况且BN操作的作用就是将数据调整到均值接近于0，标准差接近1？ 对ResNet中构块的研究 1. Abstract 提出了一种新的更优秀的residual unit结构，用这种unit构建的ResNet拥有一条贯穿首尾的直连路径（路径上只有add操作），可以使得在任意两个unit之间信号可以直接正向传播和反向传播 2. Introduction 首先先记住这个公式——ResNet的一般表示： 当满足如下两个条件时，作者（通过实验）发现，因为此时存在直连路径，所以模型更容易训练：H(xl⃗)H(\\vec{x_l})H(xl​​) 和f(yl⃗)f(\\vec{y_l})f(yl​​) 是identity mapping（自身映射） proposed ResNet和original ResNet对比，见Figure 1 文章主要通过实验，研究对identity mapping（自身映射/直连结构）和pre-activation的重要性 3. ResNet分析 当满足上述的两个两个条件时，可以推出公式（4）。这展示了之前提到的贯穿首尾的正向直连特性。 误差对xl⃗\\vec{x_l}xl​​ 求偏导，可以得到公式（5）。这展示了之前提到的贯穿首尾的反向直连特性。这里之所以对xl⃗\\vec{x_l}xl​​ 求偏导是因为这里想要研究的是xl⃗\\vec{x_l}xl​​ 对误差的贡献，而不是推导反向传播公式。 这里作者解释了为什么新的结构可以在很深的神经网络中得到很好训练的原因：前面一项保证了信息的直连传播；后面一项中因为偏导项不太可能一直都是-1，所以后面一项不会是0，保证梯度不会消失。 4. Identity Mapping的重要性 作者使用不同的mapping策略进行了比较，比较结果见Figure 2和Table 1。 结论与发现：（1）只有在和直连相近时才能达到较好的结果；（2）1* 1的卷积层在上一篇论文中与identity没什么差距，那是因为层数较少，当层数较多时差距明显。从理论上讲，卷积层连接参数更多，表达能力更强。但是，参数过多的时候，根据模型，有些模型并不是那么好训练，所以问题的瓶颈现在是优化方法上。 5. 激活函数重要性 作者使用不同的activation策略进行了比较，比较结果见Figure 4和Table 2。 为了保证直连，将激活函数和BN只用于卷积路径上。然后在此基础上又产生了pre-activation的想法，通过实验发现full pre-activation效果最好。作者给出的解释是：relu在BN后面效果更好 结论与发现：（1）优化速度快（error降低的快）（原因解释没看懂）（2）减少了过拟合。从Figure 6中可以看出，proposed resnet训练的loss高，但是预测结果好。作者认为归功于BN的正则化效果。在新resnet中，所有卷积层之前都是经过BN的，这点与原始的resnet不同。 6. 模型实战结果 在CIFAR10/100和ImageNet数据集上，效果都很好 个人总结 个人认为第一篇论文主要就是提出一种新的深度神经网络结构（结构单元），使得网络在层数很深的情况下仍然可以获得良好的训练效果 第二篇论文主要是通过很多的实验与比较，改进了第一篇论文中的结构单元（改为直连方式），并试图说明identity（直连）路径的良好训练特性 源代码 keras-resnet（keras实现的resnet，并加入了第二篇论文中的直连结构，样例为CIFAR10）：https://github.com/raghakot/keras-resnet","categories":[],"tags":[{"name":"Deep Learning","slug":"Deep-Learning","permalink":"https://proverbs.github.io/tags/Deep-Learning/"},{"name":"FER","slug":"FER","permalink":"https://proverbs.github.io/tags/FER/"}]},{"title":"Algorithm-Suffix-Automaton","slug":"Algorithm-Suffix-Automaton","date":"2017-06-07T06:08:26.000Z","updated":"2021-05-30T16:25:43.046Z","comments":true,"path":"2017/06/06/Algorithm-Suffix-Automaton/","link":"","permalink":"https://proverbs.github.io/2017/06/06/Algorithm-Suffix-Automaton/","excerpt":"【算法】字符串：后缀自动机（SAM） 引言 首先，你需要知道什么是自动机。 通俗讲，就是状态转移图，可以接受字符串的所有后缀。 后缀自动机，是一个最简的确定状态自动机。 当然，从使用的角度考虑，管它什么机，知道能从中找到所有后缀、左右子串，有很多很吊的性质就行了。 SAM 准备 SAM我确实理解了很久，而且理解还不够，还需要看到SAM的实质。 看清实质需要在理解的基础上不断应用取探索，所以，现在我们先详细谈一谈如何理解这个吊炸天的SAM。 首先，请确保你看过clj的ppt讲稿（其中有几处错误），至少要明白其中符号的定义，然后再看我写的东西。","text":"【算法】字符串：后缀自动机（SAM） 引言 首先，你需要知道什么是自动机。 通俗讲，就是状态转移图，可以接受字符串的所有后缀。 后缀自动机，是一个最简的确定状态自动机。 当然，从使用的角度考虑，管它什么机，知道能从中找到所有后缀、左右子串，有很多很吊的性质就行了。 SAM 准备 SAM我确实理解了很久，而且理解还不够，还需要看到SAM的实质。 看清实质需要在理解的基础上不断应用取探索，所以，现在我们先详细谈一谈如何理解这个吊炸天的SAM。 首先，请确保你看过clj的ppt讲稿（其中有几处错误），至少要明白其中符号的定义，然后再看我写的东西。 重要前提 ParentParentParent树：内部节点至少有两个孩子。如果只有一个孩子的话，路径可以被压缩。 设fa=Parent(s)fa=Parent(s)fa=Parent(s)，那么Right(fa)⊃Right(s)Right(fa) \\supset Right(s)Right(fa)⊃Right(s) （注意，这里是真子集），且Right(fa)Right(fa)Right(fa)最小。 Max(fa)=Min(s)−1Max(fa)=Min(s)-1Max(fa)=Min(s)−1，所以之后就基本上不会考虑MinMinMin了，因为可以通过父节点的MaxMaxMax求出。所以，构造ParentParentParent树时只需要记录MaxMaxMax就好了（我的代码中用lmlmlm记录MaxMaxMax）。 重要认知 RightRightRight集合+给定长度能确定∣Right∣|Right|∣Right∣ 个子串。 如果sss出发有标号为xxx的边，则Parent(s)Parent(s)Parent(s)出发也有标号为xxx的边，因为Parent(s)Parent(s)Parent(s)的RightRightRight集合中有与Right(s)Right(s)Right(s)中同样的rir_iri​，即Parent(s)Parent(s)Parent(s)中包含着sss的后缀。 当前字符串为TTT ，一个节点sss，有标号为xxx的边，设Right(s)={r1,r2,...,rn}Right(s)=\\{r_1, r_2, ... , r_n\\}Right(s)={r1​,r2​,...,rn​} ，并不意味之所有rIr_IrI​可以表示的字符串后面加上xxx都可以称为TTT的子串，而是只有那些满足S[ri]=xS[r_i]=xS[ri​]=x的rir_iri​表示的子串加上xxx后才是TTT的子串。 SAM的构造是在线的。 核心过程 设当前字符串TTT，长度LLL，现在要从SAM(T)SAM(T)SAM(T)构造SAM(Tx)SAM(Tx)SAM(Tx) 新增字符串都是TxTxTx的后缀，也就是在TTT的后缀后面加一个xxx 表示TTT的后缀的节点的RightRightRight集合中必有LLL 包含LLL的节点在ParentParentParent树中按照ParentParentParent指针一一连接，且节点的RightRightRight 集合不断扩大 设RightRightRight集合从小到大依次为v1,v2,...v_1, v_2, ...v1​,v2​,... viv_ivi​如果有标号为xxx的边，则vi+1v_{i+1}vi+1​也必有标号为xxx的边 设vvv为viv_ivi​中无xxx标号边的一个节点，其Right(v)={r1,r2,...,rn=L}Right(v)= \\{r_1, r_2, ... , r_n=L\\}Right(v)={r1​,r2​,...,rn​=L} 此时加入xxx，只有S[L−k,L)S[L-k, L)S[L−k,L)可以有xxx的转移，Min(v)≤k≤Max(v)Min(v) \\leq k \\leq Max(v)Min(v)≤k≤Max(v) 所以新建npnpnp节点，Right(np)={L+1}Right(np)=\\{L+1\\}Right(np)={L+1} ，构建从vvv向npnpnp标号为xxx的边。同理，对于其他没有没有标号为xxx的节点viv_ivi​ 同理 设vpv_pvp​是按照ParentParentParent指针向上，第一个有xxx标号边的节点，设tans(vp,x)=qtans(v_p, x)=qtans(vp​,x)=q，Right(vp)={r1,r2,...,rn=L}Right(v_p)=\\{r_1, r_2, ... , r_n=L\\}Right(vp​)={r1​,r2​,...,rn​=L} 则Right(q)={ri+1∣S[ri]=x}={z1,z2,...,zk}Right(q)=\\{r_i+1|S[r_i]=x\\}=\\{z_1, z_2, ..., z_k\\}Right(q)={ri​+1∣S[ri​]=x}={z1​,z2​,...,zk​} 此时，对于qqq节点，还不知道新插入了xxx，所以Right(q)Right(q)Right(q)中没有L+1L+1L+1。但是，因为S[rn]=xS[r_n]=xS[rn​]=x，则L+1L+1L+1应该包含在Right(q)Right(q)Right(q)中 但是，并不一定可以直接将L+1L+1L+1插入Right(q)Right(q)Right(q)中，因为直接插入可能会使Max(q)Max(q)Max(q)减小，从而引发一系列问题，例如： 当Max(q)=Max(vp)+1Max(q)=Max(v_p)+1Max(q)=Max(vp​)+1时，不会改变Max(q)Max(q)Max(q)： 当Max(q)≠Max(vp)+1Max(q) \\neq Max(v_p)+1Max(q)​=Max(vp​)+1时，我们需要让L+1L+1L+1加入的同时，不改变Max(q)Max(q)Max(q)的大小，及不改变图1中qqq的左端点 方法是：在qqq和Parent(q)Parent(q)Parent(q)之间插入一个节点nqnqnq，使得Max(nq)=Max(vp)+1Max(nq)=Max(v_p)+1Max(nq)=Max(vp​)+1（模拟之前的情况），画成图就是这样的： 通过ParentParentParent指针访问到的点，RightRightRight集合中都有LLL，且必有一段vp,vp+1,...,vev_p, v_{p+1}, ..., v_evp​,vp+1​,...,ve​（为什么是一段呢？请回想：我们之前对于所有的v1,...,vp−1v_1, ... , v_{p-1}v1​,...,vp−1​这些没有x标号边的节点，将它们的xxx标号边连向了npnpnp），它们标号为xxx的边都连向原来的qqq 而此时nqnqnq代替了qqq的地位，所以这些点都应该将标号为xxx的边连向nqnqnq 应用 HDU 4622,很好的一道题，很考验对SAM的理解。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687#include &lt;iostream&gt;#include &lt;cstdio&gt;#include &lt;cstdlib&gt;#include &lt;cstring&gt;using namespace std;#define N 2010struct SAM &#123; int son[26]; int lm, fa; int right;&#125;sam[N &lt;&lt; 1];int cnt;int head, last;int sum[N][N];char a[N];int newnode() &#123; ++cnt; for (int i = 0; i &lt; 26; i++) sam[cnt].son[i] = -1; sam[cnt].fa = -1; sam[cnt].lm = 0; return cnt;&#125;void init_sam() &#123; cnt = 0; head = last = newnode();&#125;int add(int x) &#123; int p = last; int np = newnode(); sam[np].lm = sam[p].lm + 1; for (; ~p &amp;&amp; sam[p].son[x] == -1; p = sam[p].fa) sam[p].son[x] = np; if (p == -1) sam[np].fa = head; else &#123; int q = sam[p].son[x]; if (sam[p].lm + 1 == sam[q].lm) sam[np].fa = q; else &#123; int nq = newnode(); sam[nq] = sam[q];// 隐含sam[nq].fa = sam[q].fa sam[nq].lm = sam[p].lm + 1; sam[q].fa = sam[np].fa = nq; for (; ~p &amp;&amp; sam[p].son[x] == q; p = sam[p].fa) sam[p].son[x] = nq; &#125; &#125; last = np; // 设当前字符串为T，插入x，新增的字符串都是Tx的后缀 // pa = sam[np].fa表示的right集合中包含非L+1的成分，也就是这个集合表示的（在min(pa)和max(pa)限制下的）Tx的后缀与之T中的某些（个）子串相同 // 同理沿着fa到达的节点表示的Tx的后缀都是会逐渐缩小max的，所以只有比max(p)长的后缀才是新增加的，也就是下面这个式子了 // 这个值的理解非常考验对SAM的理解 return sam[np].lm - sam[sam[np].fa].lm;&#125;int main() &#123; int cas, qu; cin &gt;&gt; cas; while (cas--) &#123; scanf(\"%s\", a + 1); int len = strlen(a + 1); for (int i = 1; i &lt;= len; i++) &#123; init_sam(); sum[i][i] = add(a[i] - 'a'); for (int j = i + 1; j &lt;= len; j++) &#123; sum[i][j] = sum[i][j - 1] + add(a[j] - 'a'); &#125; //cout &lt;&lt; i &lt;&lt; endl; &#125; scanf(\"%d\", &amp;qu); int x, y; while (qu--) &#123; scanf(\"%d%d\", &amp;x, &amp;y); printf(\"%d\\n\", sum[x][y]); &#125; &#125; return 0;&#125; （待更新…） （等找到好的绘图工具就把照片中的丑图换了…）","categories":[],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://proverbs.github.io/tags/algorithm/"},{"name":"字符串","slug":"字符串","permalink":"https://proverbs.github.io/tags/%E5%AD%97%E7%AC%A6%E4%B8%B2/"}]},{"title":"Algorithm-Heavy-Light-Decomposition","slug":"Algorithm-Heavy-Light-Decomposition","date":"2017-06-04T22:57:19.000Z","updated":"2021-05-30T16:25:43.046Z","comments":true,"path":"2017/06/04/Algorithm-Heavy-Light-Decomposition/","link":"","permalink":"https://proverbs.github.io/2017/06/04/Algorithm-Heavy-Light-Decomposition/","excerpt":"【数据结构】树链剖分 引言 我在之前写过的一片关于树状数组的文章中有一道题，是利用dfs的方法将一棵树“拍扁”，称为一维数组，并将树中的查询和修改转换成一维数组中的查询与修改。 之所以可以使用dfs这种简单的方法是因为题目中的查询是针对子树的查询，dfs序列可以很好的应用。 但是如果查询是针对树中一条路径的话，那么dfs这种简单的序列就不能使用了。 面对这种问题，我们的解决方法是：树链剖分。 树链剖分 核心思想 树链剖分实际上是将树划分成很多的链，并将这些链合在一起，用线段树维护。所以，自然支持区间操作和单点操作。 所以，关键其实是树的划分方法。 划分的核心思想是轻重链划分，这种划分方法有一个非常好的性质：从根到某一点的路径上，不超过logn条轻边，且不超过logn条重路径。 而这就是树链剖分(logn)^2时间复杂度的保证。","text":"【数据结构】树链剖分 引言 我在之前写过的一片关于树状数组的文章中有一道题，是利用dfs的方法将一棵树“拍扁”，称为一维数组，并将树中的查询和修改转换成一维数组中的查询与修改。 之所以可以使用dfs这种简单的方法是因为题目中的查询是针对子树的查询，dfs序列可以很好的应用。 但是如果查询是针对树中一条路径的话，那么dfs这种简单的序列就不能使用了。 面对这种问题，我们的解决方法是：树链剖分。 树链剖分 核心思想 树链剖分实际上是将树划分成很多的链，并将这些链合在一起，用线段树维护。所以，自然支持区间操作和单点操作。 所以，关键其实是树的划分方法。 划分的核心思想是轻重链划分，这种划分方法有一个非常好的性质：从根到某一点的路径上，不超过logn条轻边，且不超过logn条重路径。 而这就是树链剖分(logn)^2时间复杂度的保证。 具体的讲解可以参考：http://blog.csdn.net/vecsun/article/details/48938777 对英语不发憷的同学可以看看这篇外国人写的：https://blog.anudeep2011.com/heavy-light-decomposition/ 说实话，总感觉外国人的东西，无论是课本还是博客，思维过程都特别清楚。 而包括我自己在内的中国人，写东西总是一步到位。 当然，题外话，我写这些博客主要是为了我长时间不接触算法之后能快速回忆起算法的核心思想，而不是去告诉一个刚学算法的人怎么完全掌握这个算法。 模板 树链剖分主要有两种情况，一种是维护边权的，一种是维护点权的。 中间存在一些细微的差别，但是核心思想是相同的。 模板例行见应用～ 应用 大名鼎鼎的SPOJ QTREE系列前两道是模板题，可以做一下，后面的QTREE我就不知道了。 因为懒得取SPOJ的网站，所以就取HDU找了一个模板题：HDU 3966。 维护点权的～ 有一点要注意，树链剖分使用dfs遍历经常会爆栈，所以我推荐使用我这样的bfs的写法～ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147#include &lt;iostream&gt;#include &lt;cstring&gt;#include &lt;cstdlib&gt;#include &lt;cstdio&gt;using namespace std;#define N 50100#define M 100010int n, m, p;int cnt, tot;int head[N], nxt[M], to[M];int det[N &lt;&lt; 2];int ind[N];int fa[N], top[N], dep[N], sz[N], son[N];int q[N];int a[N];void add(int u, int v) &#123; to[cnt] = v; nxt[cnt] = head[u]; head[u] = cnt++;&#125;void init() &#123; memset(son, 0, sizeof son); memset(head, -1, sizeof head); tot = cnt = 0;&#125;void preprocess() &#123; // 获取fa, dep int h = 1, t = 2, sta; q[1] = 1; dep[1] = 1; fa[1] = 0; while (h &lt; t) &#123; sta = q[h++]; sz[sta] = 1; for (int i = head[sta]; ~i; i = nxt[i]) &#123; if (fa[sta] != to[i]) &#123; fa[to[i]] = sta; dep[to[i]] = dep[sta] + 1; q[t++] = to[i]; &#125; &#125; &#125; // 使用bfs队列模拟dfs，避免爆栈 // 计算sz， son for (int j = t - 1; j &gt;= 1; j--) &#123; sta = q[j]; for (int i = head[sta]; ~i; i = nxt[i]) &#123; if (fa[sta] != to[i]) &#123; sz[sta] += sz[to[i]]; if (sz[to[i]] &gt; sz[son[sta]]) son[sta] = to[i];// sz[0] == 0 &#125; &#125; &#125; // 计算top top[1] = 1; for (int i = 2; i &lt; t; i++) &#123; sta = q[i]; if (sta == son[fa[sta]]) top[sta] = top[fa[sta]]; else top[sta] = sta; &#125; // 将树拍扁，求ind for (int j = 1; j &lt;= n; j++) &#123; if (top[j] == j) &#123; for (int i = j; i; i = son[i]) ind[i] = ++tot; &#125; &#125;&#125;void pushdown(int u) &#123; det[u &lt;&lt; 1] += det[u]; det[u &lt;&lt; 1 | 1] += det[u]; det[u] = 0;&#125;void build(int u, int L, int R) &#123; det[u] = 0; if (L == R) return; int MID = (L + R) &gt;&gt; 1; build(u &lt;&lt; 1, L, MID); build(u &lt;&lt; 1 | 1, MID + 1, R);&#125;int query(int u, int L, int R, int p) &#123; if (L == R) return det[u]; if (det[u] != 0) pushdown(u); int MID = (L + R) &gt;&gt; 1; if (p &lt;= MID) return query(u &lt;&lt; 1, L, MID, p); return query(u &lt;&lt; 1 | 1, MID + 1, R, p);&#125;void update(int u, int L, int R, int l, int r, int k) &#123; if (l &lt;= L &amp;&amp; r &gt;= R) &#123; det[u] += k; return; &#125; int MID = (L + R) &gt;&gt; 1; if (l &lt;= MID) update(u &lt;&lt; 1, L, MID, l, r, k); if (r &gt; MID) update(u &lt;&lt; 1 | 1, MID + 1, R, l, r, k);&#125;void update_range(int x, int y, int k) &#123; while (top[x] != top[y]) &#123; if (dep[top[x]] &lt; dep[top[y]]) swap(x, y); update(1, 1, tot, ind[top[x]], ind[x], k); x = fa[top[x]]; &#125; if (ind[x] &gt; ind[y]) swap(x, y);// 在一条重链上 update(1, 1, tot, ind[x], ind[y], k);&#125;int main() &#123; while (scanf(\"%d%d%d\", &amp;n, &amp;m, &amp;p) != EOF) &#123; int x, y, z; char qu[3]; init(); for (int i = 1; i &lt;= n; i++) scanf(\"%d\", &amp;a[i]); for (int i = 1; i &lt;= m; i++) &#123; scanf(\"%d%d\", &amp;x, &amp;y); add(x, y); add(y, x); &#125; preprocess(); build(1, 1, tot); while (p--) &#123; scanf(\"%s\", qu); if (qu[0] == 'Q') &#123; scanf(\"%d\", &amp;x); // 单点查询 printf(\"%d\\n\", a[x] + query(1, 1, tot, ind[x])); &#125; else &#123; scanf(\"%d%d%d\", &amp;x, &amp;y, &amp;z); // 区间更新 if (qu[0] == 'D') update_range(x, y, -z); else update_range(x, y, z); &#125; &#125; &#125; return 0;&#125; （待更新…）","categories":[],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://proverbs.github.io/tags/algorithm/"},{"name":"数据结构","slug":"数据结构","permalink":"https://proverbs.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}]},{"title":"Algorithm-Functional-Segment-Tree","slug":"Algorithm-Functional-Segment-Tree","date":"2017-06-03T20:18:48.000Z","updated":"2021-05-30T16:25:43.046Z","comments":true,"path":"2017/06/03/Algorithm-Functional-Segment-Tree/","link":"","permalink":"https://proverbs.github.io/2017/06/03/Algorithm-Functional-Segment-Tree/","excerpt":"【数据结构】函数式（可持久化）线段树 引言 函数式线段树也叫主席树，恩，原因嘛，不知道！ 函数式线段树非常之吊，可以支持历史版本的查询。 关键是写起来很简单！ 函数式线段树 核心思想 函数式线段树本质上很多棵线段树，即有很多的根节点。 这些线段树之间，通过共用一些子树以节省空间开销和时间开销。 更具体的说，在现在的基础上每增加一棵树的开销是logn。 函数式线段树需要满足一定的条件才能使用：维护的数据必须具有区间可减性。 更详细的讲解请看：http://www.cnblogs.com/zyf0163/p/4749042.html","text":"【数据结构】函数式（可持久化）线段树 引言 函数式线段树也叫主席树，恩，原因嘛，不知道！ 函数式线段树非常之吊，可以支持历史版本的查询。 关键是写起来很简单！ 函数式线段树 核心思想 函数式线段树本质上很多棵线段树，即有很多的根节点。 这些线段树之间，通过共用一些子树以节省空间开销和时间开销。 更具体的说，在现在的基础上每增加一棵树的开销是logn。 函数式线段树需要满足一定的条件才能使用：维护的数据必须具有区间可减性。 更详细的讲解请看：http://www.cnblogs.com/zyf0163/p/4749042.html 模板 模板同样看应用吧～ 应用 HDU2665，区间第k大。 可以用划分树写，但是，你们懂得，太麻烦了，而主席树完美解决这个问题。 将数组的n个前缀看做n棵线段树，将数字区间作为线段树维护的区间范围～ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576#include &lt;iostream&gt;#include &lt;cstring&gt;#include &lt;cstdlib&gt;#include &lt;cstdio&gt;#include &lt;algorithm&gt;using namespace std;#define N 100010#define LN 17int cas;int n, m;int a[N], b[N], rt[N];int uni_num;int sum[N * LN + 4 * N], ls[N * LN + 4 * N], rs[N * LN + 4 * N];int cnt;int newnode(int l, int r, int s) &#123; cnt++; ls[cnt] = l; rs[cnt] = r; sum[cnt] = s; return cnt;&#125;void build(int l, int r, int &amp;x) &#123; x = newnode(0, 0, 0); if (l == r) return; int mid = (l + r) &gt;&gt; 1; build(l, mid, ls[x]); build(mid + 1, r, rs[x]);&#125;void update(int l, int r, int &amp;x, int px, int val) &#123; x = newnode(ls[px], rs[px], sum[px] + 1); if (l == r) return; int mid = (l + r) &gt;&gt; 1; if (val &gt; mid ) update(mid + 1, r, rs[x], rs[px], val); else update(l, mid, ls[x], ls[px], val);&#125;int query(int l, int r, int y, int x, int k) &#123; if (l == r) return l; int mid = (l + r) &gt;&gt; 1; int dt = sum[ls[y]] - sum[ls[x]]; if (dt &lt; k) return query(mid + 1, r, rs[y], rs[x], k - dt); return query(l, mid, ls[y], ls[x], k);&#125;int main() &#123; scanf(\"%d\", &amp;cas); while (cas--) &#123; scanf(\"%d%d\", &amp;n, &amp;m); for (int i = 1; i &lt;= n; i++) &#123; scanf(\"%d\", &amp;a[i]); b[i] = a[i]; &#125; // 离散化 sort(b + 1, b + 1 + n); uni_num = unique(b + 1, b + 1 + n) - b - 1; for (int i = 1; i &lt;= n; i++) a[i] = lower_bound(b + 1, b + 1 + uni_num, a[i]) - b; // 建立可持久化线段树 cnt = 0; build(1, uni_num, rt[0]); for (int i = 1; i &lt;= n; i++) update(1, uni_num, rt[i], rt[i - 1], a[i]); int s, t, k; while (m--) &#123; scanf(\"%d%d%d\", &amp;s, &amp;t, &amp;k); printf(\"%d\\n\", b[query(1, uni_num, rt[t], rt[s - 1], k)]); &#125; &#125; return 0;&#125;","categories":[],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://proverbs.github.io/tags/algorithm/"},{"name":"数据结构","slug":"数据结构","permalink":"https://proverbs.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}]},{"title":"Algorithm-RMQ","slug":"Algorithm-RMQ","date":"2017-06-03T02:59:33.000Z","updated":"2021-05-30T16:25:43.046Z","comments":true,"path":"2017/06/02/Algorithm-RMQ/","link":"","permalink":"https://proverbs.github.io/2017/06/02/Algorithm-RMQ/","excerpt":"【数据结构】RMQ 引言 RMQ是对静态区间的一种查询结构，一般用于求区间最大或最小值。 RMQ需要nlogn时间预处理，查询O(1)。 空间复杂度较高，为nlogn，所以有些题可能没法开下这么大的数组，这时候就可以考虑写线段树了。 RMQ 思想 RMQ思想很简单，就是倍增思想。 设f[i][j]表示[i,..,i+2^j-1]区间中的最大值，那么f[i][j]就等于max(f[i][j-1],f[i+2^(j-1)][j-1])。","text":"【数据结构】RMQ 引言 RMQ是对静态区间的一种查询结构，一般用于求区间最大或最小值。 RMQ需要nlogn时间预处理，查询O(1)。 空间复杂度较高，为nlogn，所以有些题可能没法开下这么大的数组，这时候就可以考虑写线段树了。 RMQ 思想 RMQ思想很简单，就是倍增思想。 设f[i][j]表示[i,..,i+2^j-1]区间中的最大值，那么f[i][j]就等于max(f[i][j-1],f[i+2^(j-1)][j-1])。 实现 求log，直接用对数函数计算太慢，这里有一种简单有效的方法： 123for (int i = 1; i &lt; N; i++) &#123; lg[i] = i &gt;&gt; lg[i - 1] + 1 ? lg[i - 1] + 1 : lg[i - 1]; &#125; 预处理： 12345for (int i=1; i&lt;=n; i++) pmax[i][0] = a[i];for (int j = 1; (1 &lt;&lt; j) &lt;= n; j++) for(int i = 1; i + (1 &lt;&lt; j) - 1 &lt;= n; i++) pmax[i][j] = max(pmax[i][j-1], pmax[i + (1 &lt;&lt; (j - 1))][j - 1]); 查询： 1234int maxrmq(int l, int r) &#123; int k = lg[r - l + 1]; return max(pmax[l][k], pmax[r - (1 &lt;&lt; k) + 1][k]);&#125; 应用 POJ2019，二维RMQ，和一维原理一样，只是多两层循环罢了～ 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859#include &lt;iostream&gt;#include &lt;cstring&gt;#include &lt;cstdio&gt;#include &lt;cstdlib&gt;#include &lt;algorithm&gt;using namespace std;#define N 260#define LN 9int rmax[N][LN][N][LN], rmin[N][LN][N][LN];int lg[N];int n, b, q;int a[N][N];void init_rmq() &#123; for (int i = 1; i &lt;= n; i++) for (int j = 1; j &lt;= n; j++) rmax[i][0][j][0] = rmin[i][0][j][0] = a[i][j]; for (int k = 1; (1 &lt;&lt; k) &lt;= n; k++) for (int p = 1; (1 &lt;&lt; p) &lt;= n; p++) for (int i = 1; i + (1 &lt;&lt; k) - 1 &lt;= n; i++) for (int j = 1; j + (1 &lt;&lt; p) - 1 &lt;= n; j++) &#123; rmax[i][k][j][p] = max(max(rmax[i][k - 1][j][p - 1], rmax[i][k - 1][j + (1 &lt;&lt; (p - 1))][p - 1]), max(rmax[i + (1 &lt;&lt; (k - 1))][k - 1][j][p - 1], rmax[i + (1 &lt;&lt; (k - 1))][k - 1][j + (1 &lt;&lt; (p - 1))][p - 1])); rmin[i][k][j][p] = min(min(rmin[i][k - 1][j][p - 1], rmin[i][k - 1][j + (1 &lt;&lt; (p - 1))][p - 1]), min(rmin[i + (1 &lt;&lt; (k - 1))][k - 1][j][p - 1], rmin[i + (1 &lt;&lt; (k - 1))][k - 1][j + (1 &lt;&lt; (p - 1))][p - 1])); &#125;&#125;int ask_rmq_max(int lx, int ly, int rx, int ry) &#123; int dx = lg[rx - lx + 1]; int dy = lg[ry - ly + 1]; return max(max(rmax[lx][dx][ly][dy], rmax[lx][dx][ry - (1 &lt;&lt; dy) + 1][dy]), max(rmax[rx - (1 &lt;&lt; dx) + 1][dx][ly][dy], rmax[rx - (1 &lt;&lt; dx) + 1][dx][ry - (1 &lt;&lt; dy) + 1][dy]));&#125;int ask_rmq_min(int lx, int ly, int rx, int ry) &#123; int dx = lg[rx - lx + 1]; int dy = lg[ry - ly + 1]; return min(min(rmin[lx][dx][ly][dy], rmin[lx][dx][ry - (1 &lt;&lt; dy) + 1][dy]), min(rmin[rx - (1 &lt;&lt; dx) + 1][dx][ly][dy], rmin[rx - (1 &lt;&lt; dx) + 1][dx][ry - (1 &lt;&lt; dy) + 1][dy]));&#125;int main() &#123; for (int i = 1; i &lt; N; i++) &#123; lg[i] = i &gt;&gt; lg[i - 1] + 1 ? lg[i - 1] + 1 : lg[i - 1]; &#125; while (scanf(\"%d%d%d\", &amp;n, &amp;b, &amp;q) != EOF) &#123; for (int i = 1; i &lt;= n; i++) for (int j = 1; j &lt;= n; j++) scanf(\"%d\", &amp;a[i][j]); init_rmq(); int x, y; while (q--) &#123; scanf(\"%d%d\", &amp;x, &amp;y); printf(\"%d\\n\", ask_rmq_max(x, y, x + b - 1, y + b - 1) - ask_rmq_min(x, y, x + b - 1, y + b - 1)); &#125; &#125; return 0;&#125; （待更新…）","categories":[],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://proverbs.github.io/tags/algorithm/"},{"name":"数据结构","slug":"数据结构","permalink":"https://proverbs.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}]},{"title":"Algorithm-Splay","slug":"Algorithm-Splay","date":"2017-06-02T06:37:57.000Z","updated":"2021-05-30T16:25:43.046Z","comments":true,"path":"2017/06/01/Algorithm-Splay/","link":"","permalink":"https://proverbs.github.io/2017/06/01/Algorithm-Splay/","excerpt":"【数据结构】splay伸展树 引言 splay树并不是严格意义上的平衡树，但是他可以做到平衡树可以做到的一切。 而且，相比与RBT和AVL，splay简直不能更好写了～ 所以，用来解决一般的算法问题，基本上splay已经是够用了。 splay 操作 关于splay的基本操作就是旋转，将一个子树向左或向右旋转。 关于两种旋转，可以参考这篇博客。 但是，从我个人理解，无论是左旋还是右旋，本质都是将一个节点上提（降低节点的深度）。 而旋转操作有用在区间操作上：我们可以通过旋转将一个区间旋转到一棵子树上，这样就可以直接对树根打上lazy标记。","text":"【数据结构】splay伸展树 引言 splay树并不是严格意义上的平衡树，但是他可以做到平衡树可以做到的一切。 而且，相比与RBT和AVL，splay简直不能更好写了～ 所以，用来解决一般的算法问题，基本上splay已经是够用了。 splay 操作 关于splay的基本操作就是旋转，将一个子树向左或向右旋转。 关于两种旋转，可以参考这篇博客。 但是，从我个人理解，无论是左旋还是右旋，本质都是将一个节点上提（降低节点的深度）。 而旋转操作有用在区间操作上：我们可以通过旋转将一个区间旋转到一棵子树上，这样就可以直接对树根打上lazy标记。 实现 理解起来真的很简单，动手画图很好画，但是当要将这么多种情况都写成代码的时候，就十分痛苦了：有那么多种情况，每一种情况分类讨论其实挺简单的，但是…那也太丑了，不忍直视。 所以，只好找别的写好的模板自己改写一下，瞬间美观、简洁100倍！ splay经常会写出bug，所以直接找个题应用一下～ 所以，模板就直接看应用吧～ 应用 HDU1890，splay模板题～ 自恋的吹一波，真心觉得这种风格的splay真的简洁～ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157#include &lt;iostream&gt;#include &lt;cstring&gt;#include &lt;cstdio&gt;#include &lt;cstdlib&gt;#include &lt;algorithm&gt;using namespace std;#define N 100010struct PX &#123; int va, id;&#125;px[N];int rk[N], pos[N];int son[N][2], fa[N], rev[N], sz[N];int cnt, root, n;bool cmp(const PX &amp;a, const PX &amp;b) &#123; if (a.va == b.va) return a.id &lt; b.id; return a.va &lt; b.va;&#125;bool cmp1(const PX &amp;a, const PX &amp;b) &#123; return a.id &lt; b.id;&#125;void newnode(int y, int &amp;x) &#123; x = ++cnt; fa[x] = y; sz[x] = 1; rev[x] = false; son[x][0] = son[x][1] = 0;&#125;void init() &#123; cnt = 0; // 加入首尾节点方便提取区间 newnode(0, root);// 1为首节点 newnode(root, son[root][1]);// 2为末节点 sz[root] = 2;&#125;void reverse(int x) &#123; if (!x) return; rev[x] ^= 1;// lazy&#125;void pushup(int x) &#123; sz[x] = sz[son[x][0]] + sz[son[x][1]] + 1;&#125;void pushdown(int x) &#123; if (!x || !rev[x]) return; rev[x] = false; reverse(son[x][0]); reverse(son[x][1]); swap(son[x][0], son[x][1]);&#125;void build(int &amp;x, int l, int r, int g) &#123; if (l &gt; r) return; int mid = (l + r) &gt;&gt; 1; newnode(g, x); pos[rk[mid]] = x; // pos[i]排名为i的数字对应splay中的节点号 build(son[x][0], l, mid - 1, x); build(son[x][1], mid + 1, r, x); pushup(x);&#125;void link(int x, int y, int c) &#123; fa[x] = y; son[y][c] = x;&#125;void rotate(int x, int c) &#123; int y = fa[x]; pushdown(y); pushdown(x); link(x, fa[y], son[fa[y]][1] == y); link(son[x][!c], y, c); link(y, x, !c); pushup(y);&#125;void splay(int x, int g) &#123; pushdown(x); int y, cy, cx; while (fa[x] != g) &#123; y = fa[x]; pushdown(fa[y]); pushdown(y); pushdown(x); cy = son[fa[y]][1] == y; cx = son[y][1] == x; if (fa[y] == g) rotate(x, cx); else &#123; if (cx == cy) rotate(y, cy); else rotate(x, cx); rotate(x, cy); &#125; &#125; pushup(x); if (!g) root = x;&#125;int getmax(int x) &#123; // 从上向下必须pushdown pushdown(x); while (son[x][1]) &#123; x = son[x][1]; pushdown(x); &#125; return x;&#125;void del() &#123; int x = root; if (son[x][0] &amp;&amp; son[x][1]) &#123; int y = getmax(son[x][0]); splay(y, x); fa[y] = 0; root = y; fa[son[x][1]] = y; son[y][1] = son[x][1]; pushup(y); &#125; else if (son[x][0]) fa[son[x][0]] = x, root = son[x][0]; else fa[son[x][1]] = x, root = son[x][1];&#125;int main() &#123; while (scanf(\"%d\", &amp;n), n) &#123; for (int i = 1; i &lt;= n; i++) &#123; scanf(\"%d\", &amp;px[i].va); px[i].id = i; &#125; sort(px + 1, px + 1 + n, cmp); for (int i = 1; i &lt;= n; i++) rk[px[i].id] = i;// rk[x]表示原数组中索引为x的数的排名 sort(px + 1, px + 1 + n, cmp1); init(); build(son[son[root][1]][0], 1, n, son[root][1]); pushup(son[root][1]); pushup(root); for (int i = 1; i &lt;= n; i++) &#123; splay(pos[i], 0); splay(1, pos[i]);// root == pos[i] printf(\"%d\", i + sz[son[1][1]]); if (i &lt; n) printf(\" \"); rev[son[1][1]] ^= 1; del();// 对root操作不需要向上pushup &#125; puts(\"\"); &#125; return 0;&#125; （待更新…）","categories":[],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://proverbs.github.io/tags/algorithm/"},{"name":"数据结构","slug":"数据结构","permalink":"https://proverbs.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}]},{"title":"Algorithm-Segment-Tree","slug":"Algorithm-Segment-Tree","date":"2017-05-31T22:12:15.000Z","updated":"2021-05-30T16:25:43.046Z","comments":true,"path":"2017/05/31/Algorithm-Segment-Tree/","link":"","permalink":"https://proverbs.github.io/2017/05/31/Algorithm-Segment-Tree/","excerpt":"【数据结构】线段树 引言 线段树虽然写起来没有树状数组那么简洁，时间效率也没有树状数组那么好，但是他的功能更加强大。 线段树 主要功能： 单点更新、区间更新（lazy） 单点查询、区间查询 剩下的不想多说了，太容易理解了，找个图一看就明白了～ 只有一点要注意的： 区间边界有没有包含在两棵相邻的子树内 线段树根据不同的题目变化很丰富，所以没有模板，只有大致的框架。 看应用中的例子吧～","text":"【数据结构】线段树 引言 线段树虽然写起来没有树状数组那么简洁，时间效率也没有树状数组那么好，但是他的功能更加强大。 线段树 主要功能： 单点更新、区间更新（lazy） 单点查询、区间查询 剩下的不想多说了，太容易理解了，找个图一看就明白了～ 只有一点要注意的： 区间边界有没有包含在两棵相邻的子树内 线段树根据不同的题目变化很丰富，所以没有模板，只有大致的框架。 看应用中的例子吧～ 应用 POJ 2828，建议自己思考一下这个题，挺有意思的一个小题～ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364#include &lt;iostream&gt;#include &lt;cstring&gt;#include &lt;cstdio&gt;#include &lt;cstdlib&gt;using namespace std;#define N 200010int n;int sum[N * 4];int val[N], pos[N];int ans[N];void pack(int u) &#123; sum[u] = sum[u &lt;&lt; 1] + sum[u &lt;&lt; 1 | 1];&#125;void build(int u, int l, int r) &#123; if (l == r) &#123; sum[u] = 1; return; &#125; int mid = (l + r) &gt;&gt; 1; build(u &lt;&lt; 1, l, mid); build(u &lt;&lt; 1 | 1, mid + 1, r); pack(u);&#125;int query(int u, int L, int R, int x) &#123; if (L == R) return L; int MID = (L + R) &gt;&gt; 1; if (sum[u &lt;&lt; 1] &lt; x) return query(u &lt;&lt; 1 | 1, MID + 1, R, x - sum[u &lt;&lt; 1]); else return query(u &lt;&lt; 1, L, MID, x);&#125;void update(int u, int L, int R, int x) &#123; // 此处的update可以和query写在一起，但是为了保留线段树的结构，此处保留update函数 if (L == R) &#123; sum[u] = 0; return; &#125; int MID = (L + R) &gt;&gt; 1; if (MID &lt; x) update(u &lt;&lt; 1 | 1, MID + 1, R, x); else update(u &lt;&lt; 1, L, MID, x); pack(u);&#125;int main() &#123; while (scanf(\"%d\", &amp;n) != EOF) &#123; for (int i = 0; i &lt; n; i++) &#123; scanf(\"%d%d\", &amp;pos[i], &amp;val[i]); &#125; build(1, 1, n); for (int i = n - 1, res; i &gt;= 0; i--) &#123; res = query(1, 1, n, pos[i] + 1); ans[res] = val[i]; update(1, 1, n, res); &#125; for (int i = 1; i &lt; n; i++) printf(\"%d \", ans[i]); printf(\"%d\\n\", ans[n]); &#125; return 0;&#125; （待更新…）","categories":[],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://proverbs.github.io/tags/algorithm/"},{"name":"数据结构","slug":"数据结构","permalink":"https://proverbs.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"线段树","slug":"线段树","permalink":"https://proverbs.github.io/tags/%E7%BA%BF%E6%AE%B5%E6%A0%91/"}]},{"title":"Algorithm-Bit","slug":"Algorithm-Bit","date":"2017-05-31T06:43:08.000Z","updated":"2021-05-30T16:25:43.046Z","comments":true,"path":"2017/05/30/Algorithm-Bit/","link":"","permalink":"https://proverbs.github.io/2017/05/30/Algorithm-Bit/","excerpt":"【数据结构】树状数组 引言 树状数组可以说是最好写，也是最好用的一种数据结构了～ 树状数组 概览 树状数组是用数组存储的，它并没有显式的树形结构，而是用数组下表的二进制表示中最低位1的位置构建的一个隐式的树形结构。 这里不盗图了，要有版权意识～所以，更形象的展示可以参考这个博客中的AB图。 关于lowbit lowbit当然不是low逼的意思啦～ lowbit(x)=x&amp;-x，要理解这个，首先要知道计算机中补码的概念。如+8，因为正数的补码为其本身，所以其的二级制表示为01000（最高位是符号位）。而-8的补码将+8的所有位（包括符号位）取反，然后加1的结果，也就是11000。 所以，这个函数的作用就是求x最低位1所对应的数字，lowbit(8)=1000=8。","text":"【数据结构】树状数组 引言 树状数组可以说是最好写，也是最好用的一种数据结构了～ 树状数组 概览 树状数组是用数组存储的，它并没有显式的树形结构，而是用数组下表的二进制表示中最低位1的位置构建的一个隐式的树形结构。 这里不盗图了，要有版权意识～所以，更形象的展示可以参考这个博客中的AB图。 关于lowbit lowbit当然不是low逼的意思啦～ lowbit(x)=x&amp;-x，要理解这个，首先要知道计算机中补码的概念。如+8，因为正数的补码为其本身，所以其的二级制表示为01000（最高位是符号位）。而-8的补码将+8的所有位（包括符号位）取反，然后加1的结果，也就是11000。 所以，这个函数的作用就是求x最低位1所对应的数字，lowbit(8)=1000=8。 操作 树状数组支持单点修改，区间查询操作。 其中单点修改是增量修改，区间查询支持具有区间可合并性质的属性。 当然，经过改造也可以进行区间修改，大致思想就是引入一个delta数组，delta[i]表示区间 [i, n] 的共同增量，然后剩下的就不多说了，可以自行推导了～ 代码 单点修改+区间查询 123456789void update(int x, int ad) &#123; for (; x &lt;= n; x += lowbit(x)) c[x] += ad;&#125;int getsum(int x) &#123; int sum = 0; for (; x ;x -= lowbit(x)) sum += c[x]; return sum;&#125; 应用 找个比较水的题，poj3321，用树的先序遍历构建成数组，然后在上面跑裸的树状数组就好了～ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869#include &lt;iostream&gt;#include &lt;cstdio&gt;#include &lt;cstdlib&gt;#include &lt;cstring&gt;using namespace std;#define N 100010#define lowbit(x) x&amp;-xint head[N], nxt[N], to[N];int c[N];int cnt, num;int n, m;int in[N], out[N];void update(int x, int ad) &#123; for (; x &lt;= n; x += lowbit(x)) c[x] += ad;&#125;int getsum(int x) &#123; int sum = 0; for (; x ;x -= lowbit(x)) sum += c[x]; return sum;&#125;void add(int u, int v) &#123; to[cnt] = v; nxt[cnt] = head[u]; head[u] = cnt++;&#125;void dfs(int x) &#123; in[x] = num; for (int i = head[x]; ~i; i = nxt[i]) &#123; update(++num, 1); dfs(to[i]); &#125; out[x] = num;&#125;int main() &#123; memset(head, -1, sizeof head); memset(nxt, -1, sizeof nxt); cnt = num = 0; scanf(\"%d\", &amp;n); for (int i = 1, a, b; i &lt; n; i++) &#123; scanf(\"%d%d\", &amp;a, &amp;b); add(a, b); &#125; update(++num, 1); dfs(1); scanf(\"%d\", &amp;m); char str[5]; int x; getchar(); while (m--) &#123; scanf(\"%s%d\", str, &amp;x); if (str[0] == 'Q') &#123; printf(\"%d\\n\", getsum(out[x]) - getsum(in[x] - 1)); &#125; else &#123; if (getsum(in[x]) - getsum(in[x] - 1) == 1) update(in[x], -1); else update(in[x], 1); &#125; &#125; return 0;&#125; （待更新…）","categories":[],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://proverbs.github.io/tags/algorithm/"},{"name":"树状数组","slug":"树状数组","permalink":"https://proverbs.github.io/tags/%E6%A0%91%E7%8A%B6%E6%95%B0%E7%BB%84/"},{"name":"数据结构","slug":"数据结构","permalink":"https://proverbs.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}]},{"title":"Algorithm-Trie","slug":"Algorithm-Trie","date":"2017-05-29T18:37:05.000Z","updated":"2021-05-30T16:25:43.046Z","comments":true,"path":"2017/05/29/Algorithm-Trie/","link":"","permalink":"https://proverbs.github.io/2017/05/29/Algorithm-Trie/","excerpt":"【算法】Trie图 引言 Trie图是Trie树的变种，结合了ac自动机中的思想。 而ac自动机的根本思想是基于kmp的next数组构建的fail指针。 所以，在学习Trie图前，请先搞清楚kmp算法。 关于AC自动机 我太久没写过AC自动机了，只知道AC自动机可以自动ac了。 所以，我还真的说不出AC自动机和我写的trie图有什么区别，可能我写的就叫ac自动机吧。 或者说，可能AC自动机和Trie图本来就是几乎一样的。 Trie图 关于Trie图，只要找到有图（那种非常好看的图）的那种博文，一般讲的都比较清楚。 因为，根本不用看字，看看图就明白了。 这里推荐一个博客：http://www.cnblogs.com/gtarcoder/p/4820560.html Trie图写起来非常短，我这种邋遢的代码风格也就10行。","text":"【算法】Trie图 引言 Trie图是Trie树的变种，结合了ac自动机中的思想。 而ac自动机的根本思想是基于kmp的next数组构建的fail指针。 所以，在学习Trie图前，请先搞清楚kmp算法。 关于AC自动机 我太久没写过AC自动机了，只知道AC自动机可以自动ac了。 所以，我还真的说不出AC自动机和我写的trie图有什么区别，可能我写的就叫ac自动机吧。 或者说，可能AC自动机和Trie图本来就是几乎一样的。 Trie图 关于Trie图，只要找到有图（那种非常好看的图）的那种博文，一般讲的都比较清楚。 因为，根本不用看字，看看图就明白了。 这里推荐一个博客：http://www.cnblogs.com/gtarcoder/p/4820560.html Trie图写起来非常短，我这种邋遢的代码风格也就10行。 先上代码： 1234567891011121314151617181920212223242526272829303132333435struct TR &#123; int son[26]; int f; bool fg;&#125;tr[M];void insert(char *str) &#123; int len = strlen(str); int now = 1; // root for (int i = 0, x; i &lt; len; i++) &#123; x = str[i] - 'a'; if (!tr[now].son[x]) tr[now].son[x] = ++cnt; now = tr[now].son[x]; &#125; tr[now].fg = true;&#125;void build_trie() &#123; int h = 1, t = 2, sta, ch, fl; q[1] = 1; // root while (h &lt; t) &#123; sta = q[h++]; for (int i = 0; i &lt; 26; i++) &#123; ch = tr[sta].son[i]; if (sta == 1) fl = 1; else fl = tr[tr[sta].f].son[i]; if (!ch) tr[sta].son[i] = fl; else &#123; tr[ch].f = fl; tr[ch].fg |= tr[fl].fg; q[t++] = ch; &#125; &#125; &#125;&#125; trie图中同样有失败指针，即以上代码中的f trie图中和trie树一样，用fg标记单词的结束字符 trie图比较好的地方在于，对于trie树中为空的孩子节点，它将这个孩子节点直接指向了失败指针的孩子节点，这个节点必然不会是空节点（除了是根节点的情况）。这里非常值得注意的是，这个孩子节点其实跨越了很多失败指针的，也就相当于将失败指针类似于并查集那样压缩。之所以会这样，是因为，当前节点的失败指针指向的节点可能也没有这个孩子，所以就要不停的调用失败指针，直到有找到有这个孩子的失败指针为止（或者到根节点为止）。 应用 字符串匹配 HDU 2222，多么好的题号～ 字符串匹配模板题： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798#include &lt;iostream&gt;#include &lt;cstring&gt;#include &lt;cstdlib&gt;#include &lt;cstdio&gt;using namespace std;#define N 10010#define M 1000010struct TR &#123; int son[26]; int f; bool fg;// 为了保留Trie的原始形态，此处保留了fg，否则可以删除 int ct;&#125;tr[M];char a[M * 100];int cnt;int ans, n, cas;int q[M * 4];void insert(char *str) &#123; int len = strlen(str); int now = 1; // root for (int i = 0, x; i &lt; len; i++) &#123; x = str[i] - 'a'; if (!tr[now].son[x]) tr[now].son[x] = ++cnt; now = tr[now].son[x]; &#125; tr[now].fg = true; tr[now].ct++; //相同单词算两个&#125;void build_trie() &#123; int h = 1, t = 2, sta, ch, fl; q[1] = 1; // root while (h &lt; t) &#123; sta = q[h++]; for (int i = 0; i &lt; 26; i++) &#123; ch = tr[sta].son[i]; if (sta == 1) fl = 1; else fl = tr[tr[sta].f].son[i]; if (!ch) tr[sta].son[i] = fl; else &#123; tr[ch].f = fl; tr[ch].fg |= tr[fl].fg; q[t++] = ch; &#125; &#125; &#125;&#125;void match() &#123; int now = 1; int len = strlen(a); for (int i = 0, x, ch; i &lt; len; i++) &#123; x = a[i] - 'a'; now = tr[now].son[x]; if (tr[now].fg) &#123; int up = now; while (tr[up].fg) &#123; ans += tr[up].ct; tr[up].ct = 0;// 重复出现算一次 up = tr[up].f; &#125; &#125; &#125;&#125;void clear() &#123; for (int i = 0; i &lt;= cnt; i++) &#123; for (int j = 0; j &lt; 26; j++) tr[i].son[j] = 0; tr[i].ct = tr[i].f = 0; tr[i].fg = false; &#125; ans = 0;&#125;int main() &#123; scanf(\"%d\", &amp;cas); while (cas--) &#123; cnt = 1; scanf(\"%d\", &amp;n); char str[55]; for (int i = 0; i &lt; n; i++) &#123; scanf(\"%s\", str); insert(str); &#125; build_trie(); scanf(\"%s\", a); match(); printf(\"%d\\n\", ans); clear(); &#125; return 0;&#125; Trie树上的DP 待补充…","categories":[],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://proverbs.github.io/tags/algorithm/"},{"name":"字符串","slug":"字符串","permalink":"https://proverbs.github.io/tags/%E5%AD%97%E7%AC%A6%E4%B8%B2/"}]},{"title":"Algorithm-Suffix-Array","slug":"Algorithm-Suffix-Array","date":"2017-05-27T07:45:42.000Z","updated":"2021-05-30T16:25:43.046Z","comments":true,"path":"2017/05/27/Algorithm-Suffix-Array/","link":"","permalink":"https://proverbs.github.io/2017/05/27/Algorithm-Suffix-Array/","excerpt":"【算法】后缀数组（SA） 引言 关于后缀数组的原理，集训队论文中已经将的非常详细了。 但是，其中的代码对于第一接触这个东西的人来说可能就觉得有些恶心了。 所以，我这篇文章主要是讲怎么理解倍增方法的SA的构建过程。 SA的实现 基数排序 很多人理解不了这个是因为不知道基数排序。 所以，在学习后缀数组之前请先动手写一个双关键字的基数排序程序：求sa[i]表示第i大的元组在数组中的下标。 然后就可以正式进入SA部分了～","text":"【算法】后缀数组（SA） 引言 关于后缀数组的原理，集训队论文中已经将的非常详细了。 但是，其中的代码对于第一接触这个东西的人来说可能就觉得有些恶心了。 所以，我这篇文章主要是讲怎么理解倍增方法的SA的构建过程。 SA的实现 基数排序 很多人理解不了这个是因为不知道基数排序。 所以，在学习后缀数组之前请先动手写一个双关键字的基数排序程序：求sa[i]表示第i大的元组在数组中的下标。 然后就可以正式进入SA部分了～ SA 先上代码，然后结合代码讲～ 123456789101112131415161718192021222324252627282930313233343536373839404142void radix_sort() &#123; // 原理是双关键字的基数排序 // sk为第一关键字，sb为第二关键字排序 // 其中，sb相当于上一轮的sa int i; for (i = 0; i &lt; m; i++) acc[i] = 0; for (i = 0; i &lt; n; i++) acc[sk[i]]++; for (i = 1; i &lt; m; i++) acc[i] += acc[i - 1]; for (i = n - 1; i &gt;= 0; i--) sa[--acc[sk[sb[i]]]] = sb[i];&#125;bool cmp(int *f, int x, int y, int w) &#123; // 比较字符串的大小，可以直接利用sk数组比较 return f[x] == f[y] &amp;&amp; f[x + w] == f[y + w];&#125;void suffix_array(int *a) &#123; for (int i = 0; i &lt; n; i++) &#123; sk[i] = a[i]; // 为了一般性，最初设置一个基于位置的第二关键字 sb[i] = i; &#125; radix_sort(); // 倍增 // p=n时说明已经能够将n个后缀全部区分了 for (int w = 1, p = 1, i; p &lt; n; w &lt;&lt;= 1, m = p) &#123; // 基数排序，求新的sa for (p = 0, i = n - w; i &lt; n; i++) sb[p++] = i; for (i = 0; i &lt; n; i++) if (sa[i] &gt;= w) sb[p++] = sa[i] - w; radix_sort(); // sb存放sk的一份拷贝，因为之后要利用当前sk更新之后的sk for (i = 0; i &lt; n; i++) sb[i] = sk[i]; // 更新sk p = 0; sk[sa[0]] = p++; // sa[0]永远都是n-1，即最后补上的0；而sk[sa[0]]即sk[n-1]=0 for (i = 1; i &lt; n; i++) // 此处的sb实际意义相当于sk sk[sa[i]] = cmp(sb, sa[i], sa[i - 1], w) ? p - 1 : p++; &#125;&#125; 这个我写的SA的代码，虽然比论文中的长很多，但是更好理解，时间效率也和论文中一样～ 大部分代码可以看注释去理解，我只强调几个非常重要的部分： sk的意义类似于rk（rank），但是不同的是，sk中使用的是对应元素的值作为排名，所以经常会出现sk中两个元素（甚至多个元素）值相同的情况；而根据rk的定义，rk是和sa互为逆运算，所以，必然是一对一映射 sb的意义相当于sa，sb中任意两个元素不相同 因为，我按照论文中的方法，在字符串后面添加了一个0，这样会导致sa[0]永远都是n-1，sk[sa[0]]即sk[n-1]=0 双关键字的基数排序理论上需要进行两次排序过程，但是实际上，代码中只进行了一次。之所以只进行了一次，是因为第二关键字已经排好顺序了，按照i从小到大的顺序访问sb[i]（即上一轮的sk[i]），即可满足第二关键字由小到大排列的要求 p&lt;n为结束条件是因为，p代表sk中不同数字的个数，所以，当p=n时，相当于没有并列的情况出现，即n个后缀已经全部区分开了～ 应用 上面求sa和rk还无法体现SA的强大之处。因为，SA还有一个很强大的辅助数组：height。 关于hight数组，可以参考上面提到的论文，这部分无论是原理还是代码都还是比较好理解的。 应用方面主要也是关于各种各样的匹配问题的，还是参看论文吧～ 这里给出poj1743中应用SA的代码： 因为我是用Jetbrain家的CLion写的，为了方便，就只能用名字空间了，对于单个代码其实没什么用，所以请忽略啦… 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118#include &lt;iostream&gt;#include &lt;cstdio&gt;#include &lt;cstring&gt;#include &lt;cstdlib&gt;namespace POJ1743 &#123; using namespace std;# define N 20020// sk中的两个元素可以相同，但是sa，sb中的不可以相同// 所以，实际上sk和sa并不是互逆的 int sk[N], rk[N], sa[N], sb[N], ht[N]; int acc[N]; int n, m, nn; int a[N]; int b[N]; void radix_sort() &#123; // 原理是双关键字的基数排序 // sk为第一关键字，sb为第二关键字排序 // 其中，sb相当于上一轮的sa int i; for (i = 0; i &lt; m; i++) acc[i] = 0; for (i = 0; i &lt; n; i++) acc[sk[i]]++; for (i = 1; i &lt; m; i++) acc[i] += acc[i - 1]; for (i = n - 1; i &gt;= 0; i--) sa[--acc[sk[sb[i]]]] = sb[i]; &#125; bool cmp(int *f, int x, int y, int w) &#123; // 比较字符串的大小，可以直接利用sk数组比较 return f[x] == f[y] &amp;&amp; f[x + w] == f[y + w]; &#125; void suffix_array(int *a) &#123; for (int i = 0; i &lt; n; i++) &#123; sk[i] = a[i]; // 为了一般性，最初设置一个基于位置的第二关键字 sb[i] = i; &#125; radix_sort(); // 倍增 // p=n时说明已经能够将n个后缀全部区分了 for (int w = 1, p = 1, i; p &lt; n; w &lt;&lt;= 1, m = p) &#123; // 基数排序，求新的sa for (p = 0, i = n - w; i &lt; n; i++) sb[p++] = i; for (i = 0; i &lt; n; i++) if (sa[i] &gt;= w) sb[p++] = sa[i] - w; radix_sort(); // sb存放sk的一份拷贝，因为之后要利用当前sk更新之后的sk // 而且，在下一轮循环中，sb利用sk的值可以直接排序 for (i = 0; i &lt; n; i++) sb[i] = sk[i]; // 更新sk p = 0; sk[sa[0]] = p++; // sa[0]永远都是n-1，即最后补上的0；而sk[sa[0]]即sk[n-1]=0 for (i = 1; i &lt; n; i++) // 此处的sb实际意义相当于sk sk[sa[i]] = cmp(sb, sa[i], sa[i - 1], w) ? p - 1 : p++; &#125; &#125; void get_ht() &#123; int i, j, k = 0; // sk和sa是互逆的(rk[sa[0]]=0) for (i = 1; i &lt;= nn; i++) rk[sa[i]] = i; // h[i] &gt;= h[i-1]-1，其中h[i]=ht[rk[i]] for (i = 0; i &lt; nn; ht[rk[i++]] = k) for (k ? k-- : 0, j = sa[rk[i] - 1]; b[i + k] == b[j + k]; k++); &#125; bool check(int x) &#123; int mx = sa[1], mn = sa[1]; for (int i = 2; i &lt; nn; i++) &#123; if (ht[i] &lt; x) mx = mn = sa[i]; else &#123; mx = max(mx, sa[i]); mn = min(mn, sa[i]); if (mx - mn &gt;= x) return true; &#125; &#125; return false; &#125; void solve() &#123; while (scanf(\"%d\", &amp;nn), nn) &#123; for (int i = 0; i &lt; nn; i++) &#123; scanf(\"%d\", &amp;a[i]); &#125; nn -= 1; for (int i = 0; i &lt; nn; i++) &#123; b[i] = a[i] - a[i + 1] + 88; &#125; m = 190; // 将字符串拓展一位，保证cmp函数中不会越界 n = nn + 1; b[n - 1] = 0; suffix_array(b); get_ht(); int ans = 0; int l = 4, r = nn / 2 + 1, mid; while (l &lt;= r) &#123; mid = (l + r) &gt;&gt; 1; if (check(mid)) ans = mid, l = mid + 1; else r = mid - 1; &#125; if (ans &lt; 4) puts(\"0\"); else printf(\"%d\\n\", ans + 1); &#125; &#125;&#125;int main() &#123; POJ1743::solve(); return 0;&#125;","categories":[],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://proverbs.github.io/tags/algorithm/"},{"name":"字符串","slug":"字符串","permalink":"https://proverbs.github.io/tags/%E5%AD%97%E7%AC%A6%E4%B8%B2/"}]},{"title":"Algorithm-Suffix-Tree","slug":"Algorithm-Suffix-Tree","date":"2017-05-27T07:45:27.000Z","updated":"2021-05-30T16:25:43.046Z","comments":true,"path":"2017/05/27/Algorithm-Suffix-Tree/","link":"","permalink":"https://proverbs.github.io/2017/05/27/Algorithm-Suffix-Tree/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"Algorithm-KMP","slug":"Algorithm-KMP","date":"2017-05-27T07:36:16.000Z","updated":"2021-05-30T16:25:43.046Z","comments":true,"path":"2017/05/27/Algorithm-KMP/","link":"","permalink":"https://proverbs.github.io/2017/05/27/Algorithm-KMP/","excerpt":"【算法】字符串：KMP算法 引言 kmp算法是字符串算法中最简单的一种算法，可以用于一下问题解决（待补充）： 字符串匹配 字符串循环节 但是，我发现有很多人都像我以前一样，其实并不是很懂这个算法。于是，就采用背代码的方式试图理解，但总是徒劳。而我个人认为，唯一可以通过背代码加深理解的只有复杂的数据结构。而这种巧妙的算法不是能通过背来理解的。 关于KMP算法 关于kmp算法的讲解网上有很多，找那种图多的博客看看，基本上讲的都差不多，也都非常明了。 所以，这里我只想讲讲我自己的体会。不画图，纯想： kmp算法的核心是一个next数组（我的代码中为p数组），当我们处于字符串（设为a）的第i个字符处时，求出的next[i]满足数组的前next[i]个字符和以a[i-next[i]+1]～a[i]这next[i]个字符是完全一样的，且next[i]最大，但又不能等于i 上面说的还是有点抽象，那么我们从字符串匹配的角度思考： 现在我们要从a串中找到一个子串和b串完全匹配，假设已经匹配了前i个，但是第（i+1）个不匹配，那么我么就要将字符串b向后移动再次寻求匹配。 既然我们向后移动了b串，那么，如果a中与b串匹配的串的首个字符的位置在i之前，那么这个匹配的子串一定跨越了i这个位置。 那么，我们自然而然就像知道，以a中以i位置结尾的子串最多能与b中的前几个匹配呢？ 要回答这个问题，就是取求next数组了。","text":"【算法】字符串：KMP算法 引言 kmp算法是字符串算法中最简单的一种算法，可以用于一下问题解决（待补充）： 字符串匹配 字符串循环节 但是，我发现有很多人都像我以前一样，其实并不是很懂这个算法。于是，就采用背代码的方式试图理解，但总是徒劳。而我个人认为，唯一可以通过背代码加深理解的只有复杂的数据结构。而这种巧妙的算法不是能通过背来理解的。 关于KMP算法 关于kmp算法的讲解网上有很多，找那种图多的博客看看，基本上讲的都差不多，也都非常明了。 所以，这里我只想讲讲我自己的体会。不画图，纯想： kmp算法的核心是一个next数组（我的代码中为p数组），当我们处于字符串（设为a）的第i个字符处时，求出的next[i]满足数组的前next[i]个字符和以a[i-next[i]+1]～a[i]这next[i]个字符是完全一样的，且next[i]最大，但又不能等于i 上面说的还是有点抽象，那么我们从字符串匹配的角度思考： 现在我们要从a串中找到一个子串和b串完全匹配，假设已经匹配了前i个，但是第（i+1）个不匹配，那么我么就要将字符串b向后移动再次寻求匹配。 既然我们向后移动了b串，那么，如果a中与b串匹配的串的首个字符的位置在i之前，那么这个匹配的子串一定跨越了i这个位置。 那么，我们自然而然就像知道，以a中以i位置结尾的子串最多能与b中的前几个匹配呢？ 要回答这个问题，就是取求next数组了。 个人认为，这就是kmp的核心思想了～ 而关于next数组的求法，是通过len维护的，看代码很容易理解。这里，强烈推荐我写的kmp算法，个人认为比网上的代码简洁、明了不少。 以下是求next数组（p数组）的代码，关于匹配的代码我后面会给出。 12345678void get_p() &#123; p[0] = 0; for (int i = 1, len = 0; i &lt; n; i++) &#123; while (len &amp;&amp; a[i] != a[len]) len = p[len - 1]; if (a[i] == a[len]) len++; p[i] = len; &#125;&#125; 应用 字符串匹配 前面将原理的时候就是用这个举得例子，直接看代码，和求next数组几乎一样～ 1234567891011121314151617181920212223242526272829303132333435363738#include &lt;iostream&gt;#include &lt;cstring&gt;#include &lt;cstdio&gt;using namespace std;char a[20], b[20];int p[20];int n, m;void get_p() &#123; p[0] = 0; for (int i = 1, len = 0; i &lt; m; i++) &#123; while (len &amp;&amp; b[i] != b[len]) len = p[len - 1]; if (b[i] == b[len]) len++; p[i] = len; &#125;&#125;void match() &#123; for (int i = 0, len = 0; i &lt; n; i++) &#123; while (len &amp;&amp; a[i] != b[len]) len = p[len - 1]; if (a[i] == b[len]) len++; if (len == m) &#123; cout &lt;&lt; \"match at \" &lt;&lt; i - len + 1 &lt;&lt; endl; len = p[len]; &#125; &#125;&#125;int main() &#123; cin &gt;&gt; a &gt;&gt; b; n = strlen(a); m = strlen(b); get_p(); match(); return 0;&#125; 循环节 设字符串长度为n。既然字符串的前p[n-1]个字符和后p[n-1]个字符完全相同，且p[n-1]最大了，那么最大循环节的长度就是（n-p[n-1]）了～","categories":[],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://proverbs.github.io/tags/algorithm/"},{"name":"字符串","slug":"字符串","permalink":"https://proverbs.github.io/tags/%E5%AD%97%E7%AC%A6%E4%B8%B2/"}]},{"title":"selenium_phantomjs","slug":"selenium-phantomjs","date":"2017-05-24T17:59:56.000Z","updated":"2021-05-30T16:25:43.056Z","comments":true,"path":"2017/05/24/selenium-phantomjs/","link":"","permalink":"https://proverbs.github.io/2017/05/24/selenium-phantomjs/","excerpt":"python爬虫实战（四）：selenium+phantomJS使用 引言 phantomJS是一个没有界面的浏览器；selenium则是一个web测试工具，可以模拟用户操作。 在对phantomJS使用不熟练的时候，可以用firefox和selenium一起使用。 配置 phantomJS直接从官网下载二进制包，解压，然后用软链接的方式添加到/usr/bin/ 使用firefox必须添加到环境变量，同时还要下载驱动","text":"python爬虫实战（四）：selenium+phantomJS使用 引言 phantomJS是一个没有界面的浏览器；selenium则是一个web测试工具，可以模拟用户操作。 在对phantomJS使用不熟练的时候，可以用firefox和selenium一起使用。 配置 phantomJS直接从官网下载二进制包，解压，然后用软链接的方式添加到/usr/bin/ 使用firefox必须添加到环境变量，同时还要下载驱动 使用 我也是刚刚开始使用，也不是很熟练。 简单了解可以参考： phantomJS selenium 具体的可以参考官方文档。 实战 登录考研论坛～ 这个论坛长期有验证码，而且有时候验证码正确也登陆不进去，所以如果使用phantomJS，然后将验证码截图，从终端输入的话，经常进不去。所以我使用的是firefox，直接在窗口输入验证码输入。 登陆后，可以获取cookie，之后可以直接使用requests，带着cookie一起访问需要登录的网页了～ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546# 利用selenium模拟登录考研论坛from selenium import webdriverfrom selenium.webdriver.common.keys import Keysurl_yd = 'https://note.youdao.com/signIn/index.html?&amp;callback=http%3A%2F%2Fnote.youdao.com%2Foldweb' # 旧版界面url_ky = 'https://i.kaoyan.com/login?url=http://bbs.kaoyan.com/forum.php'driver = webdriver.Firefox() # 可替为phantomJSdriver.get(url_ky)assert '考研' in driver.titleelem_usr = driver.find_element_by_name('uname')elem_pas = driver.find_element_by_name('passwd')elem_code = driver.find_element_by_name('seccode')elem_usr.send_keys('379548839@qq.com')elem_pas.send_keys('xxxxxx') # 保密# elem_code.screenshot('code.png')x = input() # 等待手工输入验证码# 由于验证码有bug，必须多次刷新才能使用，必须手工输入print('验证码为：', x)elem_pas.send_keys(Keys.RETURN)cookie = [item[\"name\"] + \"=\" + item[\"value\"] for item in driver.get_cookies()]cookiestr = ';'.join(item for item in cookie)print(cookiestr)import requestsurl_hm = 'https://i.kaoyan.com/set/profile'headers = &#123;&#125;headers['Host'] = 'i.kaoyan.com'headers['User-Agent'] = 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:53.0) Gecko/20100101 Firefox/53.0'headers['cookie'] = cookiestrheaders['Referer'] = 'http://bbs.kaoyan.com/forum.php'resp = requests.get(url_hm, headers=headers)print(resp.text)","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://proverbs.github.io/tags/python/"},{"name":"爬虫","slug":"爬虫","permalink":"https://proverbs.github.io/tags/%E7%88%AC%E8%99%AB/"}]},{"title":"taomm","slug":"taomm","date":"2017-05-24T17:03:26.000Z","updated":"2021-05-30T16:25:43.056Z","comments":true,"path":"2017/05/24/taomm/","link":"","permalink":"https://proverbs.github.io/2017/05/24/taomm/","excerpt":"python爬虫实战（三）：爬取淘女郎图片 引言 爬取淘女郎图片是为了给一个朋友找找穿衣的搭配，但是期间遇到了很多问题，所以就写了这篇文章记录一下解决方案。 分析 我们要爬取的网页是：淘女郎，通过分析可以看到每个淘女郎的主页： ) 随便找一个淘女郎的个人主页，有大量的图片，而且几乎没有多余的无关图片，所以直接用正则表达式可以轻易提取出图片的原始链接 那么我们爬完第一页，就要翻页了，尝试点击了一下“第二页”，网址竟然没变？！看来有麻烦了：翻页操作使用的是ajax异步加载的！那么我们的主要问题就是取解决如何获取ajax异步加载的内容了","text":"python爬虫实战（三）：爬取淘女郎图片 引言 爬取淘女郎图片是为了给一个朋友找找穿衣的搭配，但是期间遇到了很多问题，所以就写了这篇文章记录一下解决方案。 分析 我们要爬取的网页是：淘女郎，通过分析可以看到每个淘女郎的主页： ) 随便找一个淘女郎的个人主页，有大量的图片，而且几乎没有多余的无关图片，所以直接用正则表达式可以轻易提取出图片的原始链接 那么我们爬完第一页，就要翻页了，尝试点击了一下“第二页”，网址竟然没变？！看来有麻烦了：翻页操作使用的是ajax异步加载的！那么我们的主要问题就是取解决如何获取ajax异步加载的内容了 爬取异步加载内容 方法一 使用selenium+phantomjs模拟点击操作，然后异步内容加载完成后直接从html中提取内容。 这个方法比较简单，主要涉及的就是两个程序的使用。 这里不详细讲了，之后会再涉及到的～ 方法二 直接获取ajax返回的内容，从中分析出淘女郎的个人主页地址。 首先我们要获取ajax请求的地址。我们尝试点击“下一页”，很容易就找到了这个请求： 其中，form data中是筛选器中填写的内容，这里我没有调整筛选器，所以大部分都是默认，或者为空。currentPage就很明显了，代表请求的页数，这样根据地址，就可以直接获取异步加载的内容了。 查看一下Response的内容： 资料还挺全的～ 那么搜索一下，看看从哪里可以找到“宴宴gy”这个人的个人主页地址： 先到浏览器点看“宴宴gy”的个人主页，把地址复制下来，再到Response中搜索 但是，，，竟然没有搜索到！ 因为既然我们可以跳转到某个人的个人主页（https://mm.taobao.com/self/aiShow.htm?spm=719.7763510.1998643336.36.Mbfu09&amp;userId=143534224 ），她个人主页的信息必然在异步返回的内容中，不可能会凭空产生。 通过简单观察，我们发现，这个网址后面有一个userId，而Response中也有userId，而且是一样的！ 于是，产生一个假设，userId会决定我们进入哪个淘女郎的个人主页。 很幸运，我尝试将userId替换成其他人的userId之后，证实了我的设想，那么这个问题就圆满解决了～ 这里，暂时不要考虑网址中的spm，这个东西只是淘宝用来定位的代号 爬虫实现 感觉爬虫分析过程才是最复杂的，都分析好了以后，代码还是很简单的，就不多说了～ 本程序会在当前目录根据淘女郎的名字建立文件夹，存放对应图片。 由于每个淘女郎的照片太多了，笔记本硬盘空间不太够了，所以只好指定了页数爬取照片。如果想要爬取多页，只要在外层套一个关于页数的循环就好了～ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869# https://mm.taobao.com/search_tstar_model.htm# ajax:https://mm.taobao.com/tstar/search/tstar_model.do?_input_charset=utf-8# 个人主页：https://mm.taobao.com/self/aiShow.htm?spm=719.7763510.1998643336.71.Yx0DbQ&amp;userId=import osimport requestsimport reurl_ajax = 'https://mm.taobao.com/tstar/search/tstar_model.do?_input_charset=utf-8'url_base = 'https://mm.taobao.com/self/aiShow.htm?spm=719.7763510.1998643336.71.Yx0DbQ&amp;userId='params = &#123;&#125;params['q'] = ''params['viewFlag'] = 'A'params['searchStyle'] = ''params['searchRegion'] = 'city:'params['searchFansNum'] = ''params['currentPage'] = 2 # 页数params['pageSize'] = 100headers = &#123;&#125;headers['User-Agent'] = 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:53.0) Gecko/20100101 Firefox/53.0'resp = requests.get(url_ajax, params=params, headers=headers)uni_str = resp.content.decode(resp.encoding) # unicodepattern = re.compile('\"city\":\"(.*?)\".*?' + '\"height\":\"(.*?)\".*?,' + '\"realName\":\"(.*?)\".*?' + '\"userId\":(.*?),')# mm的个人信息items = re.findall(pattern, uni_str)base_dir = os.getcwd()for item in items: city, height, name, id = item[0], item[1], item[2], item[3] if (os.path.exists(name) == False): os.mkdir(name) path = os.path.join(base_dir, name) url = url_base + id mm_page = requests.get(url) mm_str = mm_page.content.decode(resp.encoding) # unicode mm_pattern = re.compile('img.*?src=\"(.*?)\"') images = re.findall(mm_pattern, mm_str) num = 1 for image in images: f_url = 'https:' + image.strip() if f_url[-3:].lower() != 'jpg' and f_url[-4:].lower() != 'jpeg': continue print(f_url) try: di = requests.get(f_url) f_path = os.path.join(path, str(num) + '.jpg') # 图片下载，单线程，很慢 # 有些其他格式的图片也会变成jpg，可能无法打开 with open(f_path, 'wb') as si: si.write(di.content) num += 1 except: print('Failed:' + f_url) 多进程 运行的时候，我发现速度太慢了，所以就增加了多进程运行～ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475# https://mm.taobao.com/search_tstar_model.htm# ajax:https://mm.taobao.com/tstar/search/tstar_model.do?_input_charset=utf-8# 个人主页：https://mm.taobao.com/self/aiShow.htm?spm=719.7763510.1998643336.71.Yx0DbQ&amp;userId=# 多进程版本import osimport requestsimport reimport multiprocessingurl_ajax = 'https://mm.taobao.com/tstar/search/tstar_model.do?_input_charset=utf-8'url_base = 'https://mm.taobao.com/self/aiShow.htm?spm=719.7763510.1998643336.71.Yx0DbQ&amp;userId='params = &#123;&#125;params['q'] = ''params['viewFlag'] = 'A'params['searchStyle'] = ''params['searchRegion'] = 'city:'params['searchFansNum'] = ''params['currentPage'] = 4 # 页数params['pageSize'] = 100headers = &#123;&#125;headers['User-Agent'] = 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:53.0) Gecko/20100101 Firefox/53.0'resp = requests.get(url_ajax, params=params, headers=headers)uni_str = resp.content.decode(resp.encoding) # unicodepattern = re.compile('\"city\":\"(.*?)\".*?' + '\"height\":\"(.*?)\".*?,' + '\"realName\":\"(.*?)\".*?' + '\"userId\":(.*?),')# mm的个人信息items = re.findall(pattern, uni_str)base_dir = os.getcwd()def download(item): city, height, name, id = item[0], item[1], item[2], item[3] if (os.path.exists(name) == False): os.mkdir(name) path = os.path.join(base_dir, name) url = url_base + id mm_page = requests.get(url) mm_str = mm_page.content.decode(resp.encoding) # unicode mm_pattern = re.compile('img.*?src=\"(.*?)\"') images = re.findall(mm_pattern, mm_str) num = 1 for image in images: f_url = 'https:' + image.strip() if f_url[-3:].lower() != 'jpg' and f_url[-4:].lower() != 'jpeg': continue print(f_url) try: di = requests.get(f_url) f_path = os.path.join(path, str(num) + '.jpg') # 图片下载，单线程，很慢 # 有些其他格式的图片也会变成jpg，可能无法打开 with open(f_path, 'wb') as si: si.write(di.content) num += 1 except: print('Failed:' + f_url)for item in items: p = multiprocessing.Process(target=download, args=(item, )) p.start()","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://proverbs.github.io/tags/python/"},{"name":"爬虫","slug":"爬虫","permalink":"https://proverbs.github.io/tags/%E7%88%AC%E8%99%AB/"}]},{"title":"symbolic_link","slug":"symbolic-link","date":"2017-05-24T07:00:47.000Z","updated":"2021-05-30T16:25:43.056Z","comments":true,"path":"2017/05/24/symbolic-link/","link":"","permalink":"https://proverbs.github.io/2017/05/24/symbolic-link/","excerpt":"[Linux]软链接 引言 我们经常会从网上下载一些程序，有些可以直接安装，像windows中的exe一样；有些则是源码安装，也是最麻烦的；而有些则是已经编译好的二进制文件，可以直接运行，就像windows中的“绿色软件”～ 而面对这种绿色软件，如果想在任意目录下随意的运行，且不去修改系统的环境变量，软链接就派上用场了～ 软链接vs硬链接 软链接 相当于windows中的快捷方式，不会占用多余的空间 使用方式：ln -s 源文件 目标文件，其中源文件必须使用绝对路径 软链接和源文件是两个不同的文件，对应不同的节点 使用ls -l时可以看到软链接有特殊的箭头符号表示","text":"[Linux]软链接 引言 我们经常会从网上下载一些程序，有些可以直接安装，像windows中的exe一样；有些则是源码安装，也是最麻烦的；而有些则是已经编译好的二进制文件，可以直接运行，就像windows中的“绿色软件”～ 而面对这种绿色软件，如果想在任意目录下随意的运行，且不去修改系统的环境变量，软链接就派上用场了～ 软链接vs硬链接 软链接 相当于windows中的快捷方式，不会占用多余的空间 使用方式：ln -s 源文件 目标文件，其中源文件必须使用绝对路径 软链接和源文件是两个不同的文件，对应不同的节点 使用ls -l时可以看到软链接有特殊的箭头符号表示 硬链接 相当于产生一个副本，这个副本的大小和源文件相同 使用方式：ln 源文件 目标文件 副本与源文件保持同步：修改其中一个，另一个会同步变化 同步的原因：两个文件本质上是一个文件，对应相同的节点。用ls -l可以看到文件的副本个数（包括自身）：其中xx是xuhao_CV_zh.md的副本，它们的节点编号都是3123，副本个数显示都是2 软链接添加到/usr/bin/ 将软链接创建到/usr/bin/之后将立刻生效，我们可以直接在任意目录运行程序。 比起添加环境变量，再source的方法简单多了有木有～","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://proverbs.github.io/tags/linux/"}]},{"title":"hexo-abstract-length","slug":"hexo-abstract-length","date":"2017-05-20T06:21:10.000Z","updated":"2021-05-30T16:25:43.056Z","comments":true,"path":"2017/05/19/hexo-abstract-length/","link":"","permalink":"https://proverbs.github.io/2017/05/19/hexo-abstract-length/","excerpt":"控制hexo文章摘要长度 方法很简单，不用安装任何插件，不用配置任何文件，只需要： 在期望显示的摘要后加上&lt;!--more--&gt;就可以了～","text":"控制hexo文章摘要长度 方法很简单，不用安装任何插件，不用配置任何文件，只需要： 在期望显示的摘要后加上&lt;!--more--&gt;就可以了～ 举个栗子： 12345678910111213141516171819202122232425262728293031323334---title: hexo-index-topdate: 2017-05-19 23:07:15tags: - hexo---# hexo文章置顶由于我经常非常自恋的点开自己的博客，所以想到将自己的计划放在自己的首页提示自己。同时，也是激励自己。所以就搜索了一些资料，总结了hexo博客文章置顶的方法，备忘。&lt;!--more--&gt;## 安装hexo-generator-index这个好像是默认安装的，具体记不太清了。## 修改js文件修改`node_modules/hexo-generator-index/lib`目录下的`generator.js`文件：添加如下代码：```javascriptposts.data = posts.data.sort(function(a, b) &#123;if(a.top &amp;&amp; b.top) &#123; // 两篇文章top都有定义 if(a.top == b.top) return b.date - a.date; // 若top值一样则按照文章日期降序排 else return b.top - a.top; // 否则按照top值降序排&#125;else if(a.top &amp;&amp; !b.top) &#123; // 以下是只有一篇文章top有定义，那么将有top的排在前面（这里用异或操作居然不行233） return -1;&#125;else if(!a.top &amp;&amp; b.top) &#123; return 1;&#125;else return b.date - a.date; // 都没定义按照文章日期降序排&#125;); 最终，整个js文件代码如下： 12345678910111213141516171819202122232425262728293031323334'use strict';var pagination = require('hexo-pagination');module.exports = function(locals) &#123; var config = this.config; var posts = locals.posts.sort(config.index_generator.order_by); var paginationDir = config.pagination_dir || 'page'; var path = config.index_generator.path || ''; posts.data = posts.data.sort(function(a, b) &#123; if(a.top &amp;&amp; b.top) &#123; // 两篇文章top都有定义 if(a.top == b.top) return b.date - a.date; // 若top值一样则按照文章日期降序排 else return b.top - a.top; // 否则按照top值降序排 &#125; else if(a.top &amp;&amp; !b.top) &#123; // 以下是只有一篇文章top有定义，那么将有top的排在前面（这里用异或操作居然不行233） return -1; &#125; else if(!a.top &amp;&amp; b.top) &#123; return 1; &#125; else return b.date - a.date; // 都没定义按照文章日期降序排 &#125;); return pagination(path, posts, &#123; perPage: config.index_generator.per_page, layout: ['index', 'archive'], format: paginationDir + '/%d/', data: &#123; __index: true &#125; &#125;);&#125;; 添加top标签 在文章中增加top标签，文章会按照top值从大到小排序。 12345title: my-scheduledate: 2017-05-19 22:58:20top: 100tags: - life 其中，只会显示： &gt; 由于我经常非常自恋的点开自己的博客，所以想到将自己的计划放在自己的首页提示自己。同时，也是激励自己。 &gt; 所以就搜索了一些资料，总结了hexo博客文章置顶的方法，备忘。","categories":[],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://proverbs.github.io/tags/hexo/"}]},{"title":"hexo-index-top","slug":"hexo-index-top","date":"2017-05-20T06:07:15.000Z","updated":"2021-05-30T16:25:43.056Z","comments":true,"path":"2017/05/19/hexo-index-top/","link":"","permalink":"https://proverbs.github.io/2017/05/19/hexo-index-top/","excerpt":"hexo文章置顶 由于我经常非常自恋的点开自己的博客，所以想到将自己的计划放在自己的首页提示自己。同时，也是激励自己。 所以就搜索了一些资料，总结了hexo博客文章置顶的方法，备忘。","text":"hexo文章置顶 由于我经常非常自恋的点开自己的博客，所以想到将自己的计划放在自己的首页提示自己。同时，也是激励自己。 所以就搜索了一些资料，总结了hexo博客文章置顶的方法，备忘。 安装hexo-generator-index 这个好像是默认安装的，具体记不太清了。 修改js文件 修改node_modules/hexo-generator-index/lib目录下的generator.js文件： 添加如下代码： 12345678910111213posts.data = posts.data.sort(function(a, b) &#123;if(a.top &amp;&amp; b.top) &#123; // 两篇文章top都有定义 if(a.top == b.top) return b.date - a.date; // 若top值一样则按照文章日期降序排 else return b.top - a.top; // 否则按照top值降序排&#125;else if(a.top &amp;&amp; !b.top) &#123; // 以下是只有一篇文章top有定义，那么将有top的排在前面（这里用异或操作居然不行233） return -1;&#125;else if(!a.top &amp;&amp; b.top) &#123; return 1;&#125;else return b.date - a.date; // 都没定义按照文章日期降序排&#125;); 最终，整个js文件代码如下： 12345678910111213141516171819202122232425262728293031323334'use strict';var pagination = require('hexo-pagination');module.exports = function(locals) &#123; var config = this.config; var posts = locals.posts.sort(config.index_generator.order_by); var paginationDir = config.pagination_dir || 'page'; var path = config.index_generator.path || ''; posts.data = posts.data.sort(function(a, b) &#123; if(a.top &amp;&amp; b.top) &#123; // 两篇文章top都有定义 if(a.top == b.top) return b.date - a.date; // 若top值一样则按照文章日期降序排 else return b.top - a.top; // 否则按照top值降序排 &#125; else if(a.top &amp;&amp; !b.top) &#123; // 以下是只有一篇文章top有定义，那么将有top的排在前面（这里用异或操作居然不行233） return -1; &#125; else if(!a.top &amp;&amp; b.top) &#123; return 1; &#125; else return b.date - a.date; // 都没定义按照文章日期降序排 &#125;); return pagination(path, posts, &#123; perPage: config.index_generator.per_page, layout: ['index', 'archive'], format: paginationDir + '/%d/', data: &#123; __index: true &#125; &#125;);&#125;; 添加top标签 在文章中增加top标签，文章会按照top值从大到小排序。 12345title: my-scheduledate: 2017-05-19 22:58:20top: 100tags: - life","categories":[],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://proverbs.github.io/tags/hexo/"}]},{"title":"python-crawler-requests","slug":"python-crawler-requests","date":"2017-05-15T05:58:41.000Z","updated":"2021-05-30T16:25:43.056Z","comments":true,"path":"2017/05/14/python-crawler-requests/","link":"","permalink":"https://proverbs.github.io/2017/05/14/python-crawler-requests/","excerpt":"requests模块学习 基础 基本请求 requests支持http的6种基本请求（get，post，put，delete，head，options），请求名即为函数名 get方法：res = requests.get(url)，返回的是Response实例，主要包含如下属性 res.status_code res.url res.encoding res.cookies：如果response中包含cookie，则可通过cookies属性获取 res.text res.content get get添加参数： 123payload = &#123;'key1': 'value1', 'key2': 'value2'&#125;res = requests.get(\"http://httpbin.org/get\", params=payload)print(res.url) # http://httpbin.org/get?key2=value2&amp;key1=value1","text":"requests模块学习 基础 基本请求 requests支持http的6种基本请求（get，post，put，delete，head，options），请求名即为函数名 get方法：res = requests.get(url)，返回的是Response实例，主要包含如下属性 res.status_code res.url res.encoding res.cookies：如果response中包含cookie，则可通过cookies属性获取 res.text res.content get get添加参数： 123payload = &#123;'key1': 'value1', 'key2': 'value2'&#125;res = requests.get(\"http://httpbin.org/get\", params=payload)print(res.url) # http://httpbin.org/get?key2=value2&amp;key1=value1 get添加headers： 12345678910111213141516171819202122payload = &#123;'key1': 'value1', 'key2': 'value2'&#125;headers = &#123;&#125;headers['User-Agent'] = 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:53.0) Gecko/20100101 Firefox/53.0'res = requests.get(\"http://httpbin.org/get\", params=payload, headers=headers)print(res.text)'''&#123; \"args\": &#123; \"key1\": \"value1\", \"key2\": \"value2\" &#125;, \"headers\": &#123; \"Accept\": \"*/*\", \"Accept-Encoding\": \"gzip, deflate\", \"Connection\": \"close\", \"Host\": \"httpbin.org\", \"User-Agent\": \"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:53.0) Gecko/20100101 Firefox/53.0\" &#125;, \"origin\": \"120.236.174.143\", \"url\": \"http://httpbin.org/get?key2=value2&amp;key1=value1\"&#125;''' post post请求：表单格式，数据时存储在form域中的 12345678910111213141516171819202122232425262728payload = &#123;'key1': 'value1', 'key2': 'value2'&#125;headers = &#123;&#125;headers['User-Agent'] = 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:53.0) Gecko/20100101 Firefox/53.0'res = requests.post(\"http://httpbin.org/post\", data=payload)print(res.text)'''&#123; \"args\": &#123;&#125;, \"data\": \"\", \"files\": &#123;&#125;, \"form\": &#123; \"key1\": \"value1\", \"key2\": \"value2\" &#125;, \"headers\": &#123; \"Accept\": \"*/*\", \"Accept-Encoding\": \"gzip, deflate\", \"Connection\": \"close\", \"Content-Length\": \"23\", \"Content-Type\": \"application/x-www-form-urlencoded\", \"Host\": \"httpbin.org\", \"User-Agent\": \"python-requests/2.9.1\" &#125;, \"json\": null, \"origin\": \"120.236.174.143\", \"url\": \"http://httpbin.org/post\"&#125;''' post请求：json格式，数据时存储在data域和json域中的 123456789101112131415161718192021222324252627payload = &#123;'key1': 'value1', 'key2': 'value2'&#125;headers = &#123;&#125;headers['User-Agent'] = 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:53.0) Gecko/20100101 Firefox/53.0'res = requests.post(\"http://httpbin.org/post\", data=json.dumps(payload))print(res.text)'''&#123; \"args\": &#123;&#125;, \"data\": \"&#123;\\\"key1\\\": \\\"value1\\\", \\\"key2\\\": \\\"value2\\\"&#125;\", \"files\": &#123;&#125;, \"form\": &#123;&#125;, \"headers\": &#123; \"Accept\": \"*/*\", \"Accept-Encoding\": \"gzip, deflate\", \"Connection\": \"close\", \"Content-Length\": \"36\", \"Host\": \"httpbin.org\", \"User-Agent\": \"python-requests/2.9.1\" &#125;, \"json\": &#123; \"key1\": \"value1\", \"key2\": \"value2\" &#125;, \"origin\": \"120.236.174.143\", \"url\": \"http://httpbin.org/post\"&#125;''' post上传文件 12345678910111213141516171819202122232425files = &#123;'file': open('cookie.txt', 'rb')&#125;res = requests.post(\"http://httpbin.org/post\", files=files)print(res.text)'''&#123; \"args\": &#123;&#125;, \"data\": \"\", \"files\": &#123; \"file\": \"# Netscape HTTP Cookie File\\n# http://curl.haxx.se/rfc/cookie_spec.html\\n# This is a generated file! Do not edit.\\n\\n222.200.182.10\\tFALSE\\t/\\tFALSE\\t\\tPHPSESSID\\ta3p2qqe0fq4ct59ajdatdtdsd2\\n\" &#125;, \"form\": &#123;&#125;, \"headers\": &#123; \"Accept\": \"*/*\", \"Accept-Encoding\": \"gzip, deflate\", \"Connection\": \"close\", \"Content-Length\": \"327\", \"Content-Type\": \"multipart/form-data; boundary=5f160535f3d44a8ca29a65bee7cd33fb\", \"Host\": \"httpbin.org\", \"User-Agent\": \"python-requests/2.9.1\" &#125;, \"json\": null, \"origin\": \"120.236.174.143\", \"url\": \"http://httpbin.org/post\"&#125;''' cookie 带cookie的get请求 12345678910cookies = &#123;'cookies_are': 'working'&#125;res = requests.get(\"http://httpbin.org/cookies\", cookies=cookies)print(res.text)'''&#123; \"cookies\": &#123; \"cookies_are\": \"working\" &#125;&#125;''' 超时配置：requests.get('https://github.com', timeout=0.01)，其中timeout只对请求时间有效，对下载时间无效 高级 会话Session 会话session：直接使用get之类的每个请求都相当于用不同浏览器发出的请求，是独立的；普遍地，网站登陆后，在同一个网站的不同网页中切换时，cookie是不变的，也就是一个持久的会话 session实践： 其中，res1这个Respone已经包含了网站返回的cookie，此时，s中就也已经包含了cookie。所以，res2对应的get请求也包含了cookie。 12345s = requests.Session()res1 = s.get('http://httpbin.org/cookies/set/sessioncookie/123456789')res2 = s.get('http://httpbin.org/cookies')print(res1.text)print(res2.text) session的headers配置： 全局配置：s.headers.update({'x-test': 'true'}) 局部配置（可覆盖全局配置）：res = s.get('http://httpbin.org/headers', headers={'x-test1': 'false'}) SSL证书验证 https 开头的网站，requests可以为HTTPS请求验证网站的SSL证书 实践： res = requests.get('https://kyfw.12306.cn/otn/', verify=True) 12306证书是无效的，会抛出异常requests.exceptions.SSLError 代理 可以按照不同的协议设置不同的代理 实践： 123456789101112131415161718192021proxies = &#123; 'http': 'http://183.128.180.240:808', 'https': 'http://101.23.150.109:9999'&#125;s = requests.Session()res = s.get('http://httpbin.org/get', proxies=proxies)print(res.text)'''&#123; \"args\": &#123;&#125;, \"headers\": &#123; \"Accept\": \"*/*\", \"Accept-Encoding\": \"gzip, deflate\", \"Connection\": \"close\", \"Host\": \"httpbin.org\", \"User-Agent\": \"python-requests/2.9.1\" &#125;, \"origin\": \"183.128.180.240\", \"url\": \"http://httpbin.org/get\"&#125;'''","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://proverbs.github.io/tags/python/"},{"name":"爬虫","slug":"爬虫","permalink":"https://proverbs.github.io/tags/%E7%88%AC%E8%99%AB/"}]},{"title":"python-crawler-urllib","slug":"python-crawler-urllib","date":"2017-05-15T05:56:02.000Z","updated":"2021-05-30T16:25:43.056Z","comments":true,"path":"2017/05/14/python-crawler-urllib/","link":"","permalink":"https://proverbs.github.io/2017/05/14/python-crawler-urllib/","excerpt":"python爬虫（一）：urllib urllib urllib.request urllib.request.urlopen 原型：request.urlopen(url, data, timeout) 返回：Request类实例 实践：response = request.urlopen('http://blog.proverbs.top') urllib.request.read 返回：Request实例的文本 实践：request.read() urllib.request.Request 推荐使用构建Request实例作为urlopen的参数 构建：req = request.Request('http://blog.proverbs.top') 实践：res = request.urlopen(req) urllib.request.ProxyHandler urllib默认使用环境变量http_proxy作为代理 手动设置代理：使用Handler可以构建opener，而opener代替urlopen 123proxy_handler = request.ProxyHandler(&#123;\"http\" : 'http://some-proxy.com:8080'&#125;)opener = request.build_opener(proxy_handler)request.install_opener(opener)","text":"python爬虫（一）：urllib urllib urllib.request urllib.request.urlopen 原型：request.urlopen(url, data, timeout) 返回：Request类实例 实践：response = request.urlopen('http://blog.proverbs.top') urllib.request.read 返回：Request实例的文本 实践：request.read() urllib.request.Request 推荐使用构建Request实例作为urlopen的参数 构建：req = request.Request('http://blog.proverbs.top') 实践：res = request.urlopen(req) urllib.request.ProxyHandler urllib默认使用环境变量http_proxy作为代理 手动设置代理：使用Handler可以构建opener，而opener代替urlopen 123proxy_handler = request.ProxyHandler(&#123;\"http\" : 'http://some-proxy.com:8080'&#125;)opener = request.build_opener(proxy_handler)request.install_opener(opener) opener urlopen是特殊的一种opener，可以理解为opener的一个实例 http.cookiejar可提供存储cookie的对象，其中：CookieJar —-派生—-&gt;FileCookieJar —-派生—–&gt;MozillaCookieJar和LWPCookieJar 示例： 12345678910111213141516from urllib import request, errorfrom http import cookiejar#声明一个CookieJar对象实例来保存cookiecookie = cookiejar.MozillaCookieJar()#利用request库的HTTPCookieProcessor对象来创建cookie处理器handler = request.HTTPCookieProcessor(cookie)#通过handler来构建openeropener = request.build_opener(handler)#此处的open方法同request的urlopen方法，也可以传入Requestresponse = opener.open('https://www.baidu.com')for item in cookie: print('Name = ' + item.name) print('Value = ' + item.value)# cookie保存到文件，使用load可将cookie加载，参数与save相同cookie.save('cookie.txt', ignore_discard=True, ignore_expires=True) 实践：模拟登录sysu在线课程系统 12345678910111213141516171819202122232425262728from urllib import request, error, parsefrom http import cookiejarfile_name = 'cookie.txt'# 使用firefox的tamperdata插件获取post地址，注意还要补充headerurl = 'http://222.200.182.10/docs/studentLogin.php?db=CompilersOnline'values = &#123;'username': 'xxxxxx', 'password': '*****'&#125; # 填写账号、密码values['User-Agent'] = 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:53.0) Gecko/20100101 Firefox/53.0'values['Referer'] = 'http://222.200.182.10/compilersindex.htm'data = parse.urlencode(values)b_data = data.encode('utf8')cookie = cookiejar.MozillaCookieJar()handler = request.HTTPCookieProcessor(cookie)opener = request.build_opener(handler)response = opener.open(url, b_data)print(response.read())cookie.save(file_name, ignore_discard=True, ignore_expires=True)# 利用有cookie的opener访问个人信息页t_url = 'http://222.200.182.10/docs/showSelfInformation.php'res = opener.open(t_url)print(res.read()) urllib.parse urllib.parse.urlencode 用于通过dict构造urlopen中的data域，实现POST方法 实践： 1234values = &#123;\"username\":\"379548839@qq.com\",\"password\":\"password\"&#125;data = parse.urlencode(values) url = \"https://passport.csdn.net/account/login?from=http://my.csdn.net/my/mycsdn\"request = urllib2.Request(url, data) GET方法：很POST方法一样，唯一不同的是网址需要带参数的url urllib.error urllib.error.URLError 产生原因：无法联网；无法连接服务器 实践： 12345req = request.Request('http://www.provb.top')try: request.urlopen(req)except error.URLError as e: print('fuck:', e.reason) Web Headers 浏览器访问网页是发送请求会包含headers User-Agent表示请求设备描述，Referer表示从请求来源（防盗链） Header是需要加入data中构造的 cookies Cookie，指某些网站为了辨别用户身份、进行session跟踪而储存在用户本地终端上的数据（通常经过加密） 正则表达式 cqc的博客","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://proverbs.github.io/tags/python/"},{"name":"爬虫","slug":"爬虫","permalink":"https://proverbs.github.io/tags/%E7%88%AC%E8%99%AB/"}]},{"title":"linux-learning","slug":"linux-learning","date":"2017-05-12T15:59:51.000Z","updated":"2021-05-30T16:25:43.056Z","comments":true,"path":"2017/05/12/linux-learning/","link":"","permalink":"https://proverbs.github.io/2017/05/12/linux-learning/","excerpt":"《鸟哥的Linux私房菜》学习笔记（未完） linux内置工具 man info：需要以info格式书写说明文档 nano：简单的文本编辑器 linux命令 维护 who：查看当前在线用户 ps -aux：查看进程 netstat -a：查询网络状态 shutdown，reboot：在执行前会自动执行sync init：切换运行级别（0：关机，3：纯文本，5：图形接口模式，6：重新启动） 权限 身份类别：owner, group, others 权限类别：read, write, execute chgrp (-R，递归) 所属组名 文件名：改变group chown (-R，递归) 所有者名 文件名：改变owner chmod (-R，递归) 文件名：改变权限 chmod 777 文件名：r=4，w=2，x=1 chmod [u/g/o/a] [+/-/=][r/w/x] 文件名：chmod u=rwx,g=rx,o=r 文件名","text":"《鸟哥的Linux私房菜》学习笔记（未完） linux内置工具 man info：需要以info格式书写说明文档 nano：简单的文本编辑器 linux命令 维护 who：查看当前在线用户 ps -aux：查看进程 netstat -a：查询网络状态 shutdown，reboot：在执行前会自动执行sync init：切换运行级别（0：关机，3：纯文本，5：图形接口模式，6：重新启动） 权限 身份类别：owner, group, others 权限类别：read, write, execute chgrp (-R，递归) 所属组名 文件名：改变group chown (-R，递归) 所有者名 文件名：改变owner chmod (-R，递归) 文件名：改变权限 chmod 777 文件名：r=4，w=2，x=1 chmod [u/g/o/a] [+/-/=][r/w/x] 文件名：chmod u=rwx,g=rx,o=r 文件名 档案与目录管理 cd：变换目录（-：上一个目录） pwd：显示当前目录 mkdir：创建目录 ls，ll：列出目录下的文件 cp 源文件 目标文件：复制（不同权限用户复制结果不同） -a：等价于-pdr，d表示复制链接文档属性 -p：保留属性复制 -r：递归，应用于目录 rm：删除 -r：递归，应用于目录（危险） -f：忽略警告信息（危险） mv：移动，可用来重命名 档案内容查看 cat：显示档案内容 nl：带行号显示 head：显示前几行 head -n 100：指定前n行 tail：显示后几行 tail -n 100：指定后n行 more：按页显示，对管线不可回看 space：下一页 enter：下一行 b：上一页 q：退出 less：按页显示，可回看 space：下一页 [pageup]：上一页 [pagedown]：下一页 /字符串+n：向后搜索 档案修改 touch：创建文件，修改档案时间 搜索 which：搜索脚本位置 type：检测内置命令，检测脚本别名 whereis：利用数据库搜索，只能搜索PATH locate：利用数据库搜索，输入部分文件名即可 find：硬盘搜索 磁盘与文件系统 待学习… 归档与压缩 gzip：生成.gz文件 gzip a.txt：默认会删除源文件 gzip -c a.txt &gt; a.txt.gz：可以保留源文件 gzip -d a.txt.gz：-d为解压缩命令，默认删除源文件 gzip -cd a.txt.gz &gt; a.txt：保留源文件 bzip2：生成.bz2文件，压缩率比gzip高 -d：解压命令 -z：压缩命令 -k：保留源文件 tar：归档命令 -c：打包 -t：查询归档内容，相当于打开 -x：解打包 -j：通过bzip2压缩 -z：通过gzip严肃哦 -v：压缩/解压缩过程中显示文件名 -f：打包/解打包文件名（建议单独写） tar -jcv -f filename.tar.bz2 源目录：压缩 tar -jxv -f filename.tar.bz2：解压 tar -jtv -f filename.tar.bz2：查询 vim 模式 一般模式：光标移动，删除，复制粘贴 移动光标： hjkl或箭头 ctrl+f或[pagedown]：下一页 ctrl+b或[pageup]：上一页 0或[home]：当行最前字符前 $或[end]：当行最后字符后 gg：回到首行 n[enter]：下移n行 查找替换 /word：从光标向后搜索 n：正向执行上一个搜索动作 N：反向执行上一个搜索动作 :n1,n2s/word1/word2/g：在n1到n2行之间将word1替换为word2，其中可用$代替n2作为最后一行 :n1,n2s/word1/word2/gc：在替换前询问 删除、复制、粘贴 x：向前删除，X：向前删除 dd：删除整行 yy：复制整行，nyy：复制以下n行 p：在下一行粘贴 u：撤销一步 .：重复上一个动作 选择 v：选择字符，变为反色 ctrl+v：选择矩形区域，变为反色 y：复制，d：删除 编辑模式：i进入，esc退出 命令模式：在一般模式下：、/、?进入，esc退出 w：保存 q：退出 !：强制执行 多文档与多窗口切换 bash shell 变量： 设置变量：name=xuhao,echo $name 删除变量：unset name 环境变量：env 所有变量（环境变量+普通变量）：set export：自定义变量转环境变量 shell编程： 待学习… 环境配置文件 /etc/profile：系统整体设定（不建议修改） /etc/profile.d/*.sh：其中的脚本会被/etc/profile引入 source：使环境变量立刻生效 数据重定向 标准输入：代码0，使用&lt;或&lt;&lt;，&lt;为覆盖方式，&lt;&lt;为累加方式 标准输出：代码1，使用&gt;或&gt;&gt; 标准错误输出：代码2，使用2&gt;或2&gt;&gt; /dev/null：垃圾桶黑洞装置 tee 文件名：双向重定向，既能重定向的同时，也能输出到屏幕 截取命令 cut： grep '字符串'：从文本中截取包含搜索字符串的行 -n：输出行号 -v：输出不包含搜索字符串的行 排序命令 sort ：按照行排序 -r：反向 -f：忽略大小写 uniq：在排序后去重 wc：依次输出行、词数、字符数 字符串处理 tr：删除，替换 col join paste expand：tab转space split：分割 正则表达式 待学习… 解决方案 忘记root密码 使用单用户模式修改（单用户模式是root权限） r/w/x对目录的作用： r：可以用ls列出内容 w：可以修改目录名称，内部新建、删除文件 x：可以cd进入 档案种类 -：正规文档 d：目录 l：链接 b/c/s/p：设备文件，数据文件 $PATH环境变量 可用echo $PATH输出环境变量 不同用户有不同的环境变量 .目录并不是环境变量中的目录，所以执行当前目录的文件需要用./filename umask 与新建目录或文件时的默认权限有关 文件预设权限：666 目录预设权限：777 创建权限 = 预设权限 - umask 不同权限用户的umask不同，使用umask查看当前用户的umask 文件默认 特殊权限 SUID： SGID： SBIT：","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://proverbs.github.io/tags/linux/"},{"name":"shell","slug":"shell","permalink":"https://proverbs.github.io/tags/shell/"}]},{"title":"face_color","slug":"face-color","date":"2017-05-08T21:24:38.000Z","updated":"2021-05-30T16:25:43.056Z","comments":true,"path":"2017/05/08/face-color/","link":"","permalink":"https://proverbs.github.io/2017/05/08/face-color/","excerpt":"颜色空间人脸检测 实验目的 使用颜色空间的方法检测人脸，并用二值化的方法进行显示。 实验内容 选定图像色彩模型 如果使用RGB颜色模型，当光照、肤色稍微变化时，对RGB各分量的灰度值有较大的影响。所以通过查阅资料，最终选定了YCbCr颜色空间作为人脸检测的颜色模型，并选定Cr分量的灰度作为判定标准。","text":"颜色空间人脸检测 实验目的 使用颜色空间的方法检测人脸，并用二值化的方法进行显示。 实验内容 选定图像色彩模型 如果使用RGB颜色模型，当光照、肤色稍微变化时，对RGB各分量的灰度值有较大的影响。所以通过查阅资料，最终选定了YCbCr颜色空间作为人脸检测的颜色模型，并选定Cr分量的灰度作为判定标准。 YCbCr颜色模型 YCbCr空间是一种常见的色彩模型，其中Y表示亮度信息，Cb和Cr表示色度信息。其中Cb表示蓝色的浓度偏移成分，Cr表示红色的浓度偏移成分。而人脸主要是红色成分，所以主要考虑Cr分量的灰度值。 RGB颜色模型转YCbCr颜色模型公式如下： 确定人脸灰度区间 我找了两张黄种人的图片，将其中的人脸区域截出，观察Cr分量的灰度直方图如下： 根据观察，然后结合查阅的资料，黄种人的肤色对应的Cr分量在140-160范围内。 根据上面两张图的对比，光照对于Cr分量影响不大，所以图片几乎可以不用预处理就可以直接提取Cr分量判断。 人脸检测 人脸检测主要分为以下三个步骤： 提取图片的Cr分量，并二值化 使用5*5的中值滤波器去出噪声 对连通区域标号，并统计每个连通区域的面积，面积小于图片总面积的0.25%时认为是噪声 其中，第3步我们曾经使用闭操作，尝试修补孔洞。但是有些对于背景复杂的照片，有些空洞是较大的，这就需要提高结构元素的大小。但是，当结构元素过大的时候，执行闭操作之后人脸的边界形状会被严重破坏。所以，我们最终使用了现在的统计连通块面积占比的方法。 结果与反思 实验结果 实验中，对6张图片进行颜色空间人脸检测结果如下。 每张图片包含4张图片依次为： 原始图像 提取原始图像Cr分量，并二值化后的结果 对二值化图像使用5*5中值滤波器平滑后的结果 对平滑后的图像进行连通块标号，并填补孔洞后的结果 结果反思 在一些背景较为复杂的照片中，有一定的概率会存在某个较大区域的Cr分量和人脸的Cr分量相符，都在140到160之间。这种情况暂时还没有想出办法解决。 程序中需要确定一个连通块面积占总图片总面积的占比，这个占比根据不同的图片会有一些差别。以人为照片主体的时候，0.25%的占比较为合适；但如果人很小，图片主要是背景的时候，则人脸会被当做噪声处理掉。 人脸检测主要是提取人脸部分，但是由于很多照片有人体其他部位裸露，且裸露区域较大，也会被当做人脸区域。我们曾经考虑利用形状判断——人脸更偏向于正方形或长方形，但是很多时候，手或小臂的形状也是正方向或长方形，因此仍然无法排除这一部分。 程序实现 统计人脸Cr灰度区间：show.py 12345678910111213141516171819202122232425262728293031323334# -*- coding:utf-8 -*-from PIL import Imagefrom pylab import *import numpy as npimg1 = Image.open('./ss1.png')figure(1)subplot(221)title('image1')axis('off')imshow(img1)subplot(222)title('Cr_hist1')img1_cr = np.array(img1.convert('YCbCr'))[:, :, 2]hist(img1_cr.ravel(), 50, normed=1, facecolor='g')img2 = Image.open('./ss2.png')subplot(223)title('image2')axis('off')imshow(img2)subplot(224)title('Cr_hist2')img2_cr = np.array(img2.convert('YCbCr'))[:, :, 2]hist(img2_cr.ravel(), 50, normed=1, facecolor='g')show() 人脸检测：face.py 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130# -*- coding:utf-8 -*-from PIL import Imagefrom pylab import *import numpy as npimport mathfrom collections import defaultdict, dequeim = Image.open('./s6.jpg')subplot(221)title('original')axis('off')imshow(im)ycbcr = np.array(im.convert('YCbCr'))n, m = ycbcr.shape[0], ycbcr.shape[1]cb = ycbcr[:, :, 1]cr = ycbcr[:, :, 2]for i in range(n): for j in range(m): if cr[i, j] &gt; 140 and cr[i, j] &lt; 160: cr[i, j] = 255 else: cr[i, j] = 0subplot(222)title('Cr binarization')axis('off')gray()imshow(cr)# 平滑，中值滤波器for i in range(2, n - 2): for j in range(2, m - 2): z = cr[i - 2: i + 3, j - 2: j + 3].reshape(25) z = sort(z) cr[i, j] = z[13]subplot(223)title('median filter, smooth')axis('off')gray()imshow(cr)'''# 闭操作，补孔洞## 腐蚀sz = 1cr1 = np.zeros((n, m))def erode(x, y): for ii in range(-sz, sz + 1): for jj in range(-sz, sz + 1): if cr[x + ii, y + jj] != 255: return 0 return 255for i in range(sz, n - sz): for j in range(sz, m - sz): if cr[i, j] == 255: cr1[i, j] = erode(i, j)## 膨胀cr2 = np.zeros((n, m))def dilate(x, y): for ii in range(-sz, sz + 1): for jj in range(-sz, sz + 1): if cr1[x + ii, y + jj] == 255: return 255 return 0for i in range(sz, n - sz): for j in range(sz, m - sz): if cr1[i, j] == 255: cr2[i, j] = erode(i, j)'''# 连通区域标号label = np.zeros((n, m))cr2 = np.zeros((n, m))num = [0, ]def bfs(x, y, col): label[x, y] = col num[col] += 1 q = deque([(x, y), ]) while len(q) != 0: z = q.popleft() x, y = z[0], z[1] # print(x, y) for i in [-1, 0, 1]: for j in [-1, 0, 1]: if x + i &lt; 0 or x + i &gt;= n or y + j &lt; 0 or y + j &gt;= m: continue if cr[x + i, y + j] == 255 and label[x + i, y + j] == 0: label[x + i, y + j] = col num[col] += 1 q.append((x + i, y + j))cnt = 0for i in range(n): for j in range(m): if label[i, j] == 0 and cr[i, j] == 255: cnt += 1 num.append(0) bfs(i, j, cnt)# print(cnt)mx = 400 # 不同图像占比不同for i in range(n): for j in range(m): if num[int(label[i, j])] * mx &lt; n * m: cr2[i, j] = 0 else: cr2[i, j] = 255subplot(224)title('without small component')axis('off')gray()imshow(cr2)show()","categories":[],"tags":[{"name":"人脸检测","slug":"人脸检测","permalink":"https://proverbs.github.io/tags/%E4%BA%BA%E8%84%B8%E6%A3%80%E6%B5%8B/"},{"name":"数字图像处理","slug":"数字图像处理","permalink":"https://proverbs.github.io/tags/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"}]},{"title":"Hello World","slug":"hello-world","date":"2017-05-01T15:00:51.000Z","updated":"2021-05-30T16:25:43.056Z","comments":true,"path":"2017/05/01/hello-world/","link":"","permalink":"https://proverbs.github.io/2017/05/01/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick Start Create a new post 1$ hexo new \"My New Post\" More info: Writing Run server 1$ hexo server More info: Server Generate static files 1$ hexo generate More info: Generating Deploy to remote sites 1$ hexo deploy More info: Deployment","categories":[],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://proverbs.github.io/tags/hexo/"}]}],"categories":[],"tags":[{"name":"reading","slug":"reading","permalink":"https://proverbs.github.io/tags/reading/"},{"name":"novel","slug":"novel","permalink":"https://proverbs.github.io/tags/novel/"},{"name":"life","slug":"life","permalink":"https://proverbs.github.io/tags/life/"},{"name":"reflection","slug":"reflection","permalink":"https://proverbs.github.io/tags/reflection/"},{"name":"design pattern","slug":"design-pattern","permalink":"https://proverbs.github.io/tags/design-pattern/"},{"name":"tech","slug":"tech","permalink":"https://proverbs.github.io/tags/tech/"},{"name":"Agatha Christie","slug":"Agatha-Christie","permalink":"https://proverbs.github.io/tags/Agatha-Christie/"},{"name":"game","slug":"game","permalink":"https://proverbs.github.io/tags/game/"},{"name":"English","slug":"English","permalink":"https://proverbs.github.io/tags/English/"},{"name":"algorithm","slug":"algorithm","permalink":"https://proverbs.github.io/tags/algorithm/"},{"name":"LeetCode","slug":"LeetCode","permalink":"https://proverbs.github.io/tags/LeetCode/"},{"name":"hexo","slug":"hexo","permalink":"https://proverbs.github.io/tags/hexo/"},{"name":"Deep Learning - FER","slug":"Deep-Learning-FER","permalink":"https://proverbs.github.io/tags/Deep-Learning-FER/"},{"name":"Deep Learning","slug":"Deep-Learning","permalink":"https://proverbs.github.io/tags/Deep-Learning/"},{"name":"FER","slug":"FER","permalink":"https://proverbs.github.io/tags/FER/"},{"name":"字符串","slug":"字符串","permalink":"https://proverbs.github.io/tags/%E5%AD%97%E7%AC%A6%E4%B8%B2/"},{"name":"数据结构","slug":"数据结构","permalink":"https://proverbs.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"线段树","slug":"线段树","permalink":"https://proverbs.github.io/tags/%E7%BA%BF%E6%AE%B5%E6%A0%91/"},{"name":"树状数组","slug":"树状数组","permalink":"https://proverbs.github.io/tags/%E6%A0%91%E7%8A%B6%E6%95%B0%E7%BB%84/"},{"name":"python","slug":"python","permalink":"https://proverbs.github.io/tags/python/"},{"name":"爬虫","slug":"爬虫","permalink":"https://proverbs.github.io/tags/%E7%88%AC%E8%99%AB/"},{"name":"linux","slug":"linux","permalink":"https://proverbs.github.io/tags/linux/"},{"name":"shell","slug":"shell","permalink":"https://proverbs.github.io/tags/shell/"},{"name":"人脸检测","slug":"人脸检测","permalink":"https://proverbs.github.io/tags/%E4%BA%BA%E8%84%B8%E6%A3%80%E6%B5%8B/"},{"name":"数字图像处理","slug":"数字图像处理","permalink":"https://proverbs.github.io/tags/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"}]}